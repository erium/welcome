{
 "cells": [
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "7e86f7e1-fb2c-44ca-ad1f-36a47073625d"
   },
   "outputs": [],
   "source": [
    "# Regression\r\n",
    "\r\n",
    "This is a template notebook for regression modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "e07566af-5b5e-419f-9d1b-e750b0b099c7"
   },
   "outputs": [],
   "source": [
    "## How to use the notebook\r\n",
    "\r\n",
    "The following cells:\r\n",
    "- specify objective, variables, and variable types,\r\n",
    "- set up the regression models,\r\n",
    "- read dataset,\r\n",
    "- present results from the model,\r\n",
    "- provide the model with the best performance.\r\n",
    "\r\n",
    "To just see how it works for a toy example, simply run the whole notebook as is.\r\n",
    "\r\n",
    "For your own project, adjust the details about objectives, variables, dataset etc. and then execute all cells in order.\r\n",
    "The board \"regression.board\" will help you with detailed instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "147efc98-4275-4004-826c-908764515e86"
   },
   "outputs": [],
   "source": [
    "# Imports and general setup"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "bd100bba-e36e-4f97-addd-afd231b5354f"
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import shutil\r\n",
    "from distutils.dir_util import copy_tree\r\n",
    "\r\n",
    "import time\r\n",
    "from datetime import datetime\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.cm as cm\r\n",
    "\r\n",
    "from sklearn import datasets, metrics\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "from sklearn.preprocessing import PolynomialFeatures\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.linear_model import Lasso\r\n",
    "from sklearn.linear_model import Ridge\r\n",
    "\r\n",
    "from sklearn.tree import DecisionTreeRegressor\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "\r\n",
    "from sklearn.neural_network import MLPRegressor\r\n",
    "\r\n",
    "from warnings import simplefilter\r\n",
    "from sklearn.exceptions import ConvergenceWarning\r\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\r\n",
    "\r\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "810f9099-3fe8-411a-ab7e-cdbb7bde3ee4"
   },
   "outputs": [],
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 2,
     "id": "a0f118de-52a7-4e07-ade7-9facdf21a7ef",
     "path": "/Personal/zihan/regression.ipynb",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "30cfffd5-5bf9-45bd-b5bd-2f87fa7ff783"
   },
   "outputs": [],
   "source": [
    "experiment_name = \"project\"  # please provide a name for the regression experiment\n",
    "data_dir = \"./\"           # please provide a name for saving the data for the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "2cd9e0e1-8b9f-4248-babe-b43086aa8d24"
   },
   "outputs": [],
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 3,
     "id": "3e63b530-c960-4745-853e-1127de78bc51",
     "path": "/Personal/zihan/regression.ipynb",
     "startLine": 3
    },
    {
     "endLine": 17,
     "id": "3e63b530-c960-4745-853e-1127de78bc51",
     "path": "/Personal/zihan/regression.ipynb",
     "startLine": 17
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "413a2a94-f6ce-4e98-ac95-9f7163e1dc7f"
   },
   "outputs": [],
   "source": [
    "example_df = datasets.load_diabetes(return_X_y=False, as_frame=True)['frame']\r\n",
    "\r\n",
    "df = example_df # You may import your own data here eg pd.read_csv(\"File.csv\")\r\n",
    "test_size = 0.25 # You may adjust this value to change the train/test split ratio\r\n",
    "\r\n",
    "path = './out'\r\n",
    "isExist = os.path.exists(path)\r\n",
    "if isExist:\r\n",
    "  for root, dirs, files in os.walk(path):\r\n",
    "      for f in files:\r\n",
    "          os.unlink(os.path.join(root, f))\r\n",
    "      for d in dirs:\r\n",
    "          shutil.rmtree(os.path.join(root, d))\r\n",
    "else:\r\n",
    "  os.makedirs(path)\r\n",
    "\r\n",
    "df.to_csv(path + '/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "8b9dfab8-6f7f-4e3e-b84a-1c6ca79ae5cb"
   },
   "outputs": [],
   "source": [
    "## Visualising the dataset"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "787b617d-8094-43a7-b976-c193b92aec61"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "90d05037-0e7c-43a2-ac72-ca119db04ba6"
   },
   "outputs": [],
   "source": [
    "corr = df.corr()\r\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "3412e9ac-769a-45be-944e-956319e432e6"
   },
   "outputs": [],
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 2,
     "id": "e817a3ec-f7d8-4f19-8879-4682614ca975",
     "path": "/Personal/zihan/regression.ipynb",
     "startLine": 2
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "f372f433-4012-48fb-a452-97b81ecd93dc"
   },
   "outputs": [],
   "source": [
    "# Specify exactly the name(s) of the dependent variable(s)\r\n",
    "target = ['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "283152b8-1aef-4430-847e-9aa7c129bd14"
   },
   "outputs": [],
   "source": [
    "Extracting the data from the target"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "3292c46e-13d5-4acc-9f0d-27973a19cd13"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=target)\r\n",
    "y = df[target]\r\n",
    "\r\n",
    "labels = list(X.columns)\r\n",
    "num_labels = len(labels)\r\n",
    "target_labels = list(y.columns)\r\n",
    "num_target_labels = len(target_labels)\r\n",
    "print(labels, target_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "29d50587-1cb8-467f-b856-df6533b06cb0"
   },
   "outputs": [],
   "source": [
    "Splitting the data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "bbc53823-e2c0-4e2b-9f1d-5fb2b890a4a3"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\r\n",
    "X_train_half, X_train_discard, y_train_half, y_train_discard = train_test_split(X_train, y_train, test_size = 0.5)\r\n",
    "# if num_target_labels == 1:\r\n",
    "#     y_train_half = y_train_half.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "0d0a21aa-e617-4802-811d-d0f76775ac99"
   },
   "outputs": [],
   "source": [
    "# Normalising the data"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "d370f731-3cbd-4d35-891d-54dc3b53494a",
     "path": "/Personal/zihan/regression.ipynb",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "e6e73b5e-9969-42f4-add3-3b94fe00ea09"
   },
   "outputs": [],
   "source": [
    "normalisation_method = 'standard' # 'none', 'standard', 'minmax'"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "b637baf5-cb79-437a-b5fc-f33936bc9167"
   },
   "outputs": [],
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "a1be128b-f0ed-4088-9825-70dce59a0a22",
     "path": "/Personal/zihan/regression.ipynb",
     "startLine": 1
    },
    {
     "endLine": 4,
     "id": "a1be128b-f0ed-4088-9825-70dce59a0a22",
     "path": "/Personal/zihan/regression.ipynb",
     "startLine": 4
    },
    {
     "endLine": 7,
     "id": "a1be128b-f0ed-4088-9825-70dce59a0a22",
     "path": "/Personal/zihan/regression.ipynb",
     "startLine": 7
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "dc9b038a-fb52-4351-af70-24acd52efc91"
   },
   "outputs": [],
   "source": [
    "reduction_method = 'pca' # 'none', 'manual', or 'pca'\n",
    "\n",
    "# For manual reduction\n",
    "variables_to_remove = ['age']\n",
    "\n",
    "# For Principle Component Reduction\n",
    "n_pca_components = 'auto' # In range 1 to number of independent variables\n",
    "pca_model_data = {}\n",
    "\n",
    "if (n_pca_components != 'auto' and (n_pca_components < 1 or n_pca_components > len(labels))):\n",
    "    raise ValueError('n_pca_components must be in range 1 to no independent variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "21a7176f-3266-4aaa-a734-3c6ee28845a7"
   },
   "outputs": [],
   "source": [
    "## Manual Reduction"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "f66d14df-daff-4a50-81c8-16e2e05602a5"
   },
   "outputs": [],
   "source": [
    "corr_target = abs(corr[target])\r\n",
    "print(corr_target)"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "70f49b4d-78f4-43f2-afbf-c98f915da22e"
   },
   "outputs": [],
   "source": [
    "if reduction_method == 'manual':\r\n",
    "    X_train = X_train.drop(columns=variables_to_remove)\r\n",
    "    X_test = X_test.drop(columns=variables_to_remove)\r\n",
    "    X_train_half = X_train_half.drop(columns=variables_to_remove)\r\n",
    "    for x in variables_to_remove:\r\n",
    "        labels.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "daed6a92-9287-4ebe-ae74-f08a7aef2e78"
   },
   "outputs": [],
   "source": [
    "if normalisation_method in ['standard', 'minmax']:\r\n",
    "    scaler_x = StandardScaler() if normalisation_method == 'standard' else MinMaxScaler()\r\n",
    "    scaler_y = StandardScaler() if normalisation_method == 'standard' else MinMaxScaler()\r\n",
    "\r\n",
    "    scaler_x.fit(X_train)\r\n",
    "    X_train = pd.DataFrame(scaler_x.transform(X_train), columns = X_train.columns)\r\n",
    "    X_test = pd.DataFrame(scaler_x.transform(X_test), columns = X_test.columns)\r\n",
    "\r\n",
    "    scaler_y.fit(y_train)\r\n",
    "    y_train = pd.DataFrame(scaler_y.transform(y_train)).squeeze()\r\n",
    "    y_test = pd.DataFrame(scaler_y.transform(y_test)).squeeze()\r\n",
    "\r\n",
    "    dump(scaler_x, path + '/scaler_x.joblib')\r\n",
    "    dump(scaler_y, path + '/scaler_y.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "58bbc954-90c7-480b-bf0e-c547c6a8eb9c"
   },
   "outputs": [],
   "source": [
    "## Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "0c5f6169-acce-42e3-9636-84e2a04d25d9"
   },
   "outputs": [],
   "source": [
    "def run_pca(X_train_data, X_train_data_half, X_test_data, pca_components, show_plot=False):\r\n",
    "    pca = PCA(n_components = pca_components)\r\n",
    "    pca.fit(X_train_data)\r\n",
    "    pca_data = pca.transform(X_train_data)\r\n",
    "    per_var = pca.explained_variance_ratio_ * 100\r\n",
    "    pca_labels = ['PC' + str(x) for x in range (1, len(per_var) + 1)]\r\n",
    "\r\n",
    "    X_train_data = pca.transform(X_train_data)\r\n",
    "    X_train_data_half = pca.transform(X_train_data_half)\r\n",
    "    X_test_data = pca.transform(X_test_data)\r\n",
    "    \r\n",
    "    X_concat = pd.concat([pd.DataFrame(X_train_data), pd.DataFrame(X_test_data)])\r\n",
    "    X_concat.columns = pca_labels\r\n",
    "    \r\n",
    "    if show_plot:\r\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\r\n",
    "        fig.suptitle('PCA Visualisation')\r\n",
    "        ax1.bar(range(1, len(per_var)+1), per_var, tick_label=pca_labels)\r\n",
    "        ax1.set_title('Scree Plot')\r\n",
    "        ax1.set_ylabel('% of Explained Variance')\r\n",
    "        ax1.set_xlabel('Principle Compenent')\r\n",
    "\r\n",
    "        if (n_pca_components >= 2):\r\n",
    "            pca_df = pd.DataFrame(pca_data, columns = pca_labels)\r\n",
    "\r\n",
    "            ax2.scatter(pca_df.PC1, pca_df.PC2)\r\n",
    "            ax2.set_title('PCA Graph')\r\n",
    "            ax2.set_xlabel('PC1 - {0}%'.format(per_var[0]))\r\n",
    "            ax2.set_ylabel('PC2 - {0}%'.format(per_var[1]))\r\n",
    "        plt.show()\r\n",
    "\r\n",
    "    \r\n",
    "    return [X_train_data, X_train_data_half, X_test_data, pca_labels, X_concat, pca]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "eca9f041-0227-4eb7-87c0-83cc4e7f7c8e"
   },
   "outputs": [],
   "source": [
    "# Regularisation\r\n",
    "You may set your own regularisation constant or let the notebook find the most optimal constant"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "22495cd1-cb70-461b-a4c6-0b596106a9cd",
     "path": "/Personal/zihan/regression.ipynb",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "6c21f4e7-5b59-4ee8-b870-37406b4819fa"
   },
   "outputs": [],
   "source": [
    "regularisation_constant = 'auto' # Float or 'auto' for automatic search for optimal constant (may be slow on large dataset)"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "c7f4e3bd-cc5c-4b47-87ab-d89ee28cb3c3"
   },
   "outputs": [],
   "source": [
    "# Code for auto regularisation\r\n",
    "# You may call auto_regularise with show_graph=True to see the graph of regularisation against training and test scores\r\n",
    "def auto_regularise(X_train_data, X_test_data, y_train_data, y_test_data, method, show_graph=False):\r\n",
    "    model_train = {}\r\n",
    "    model_test = {}\r\n",
    "    model_time = {}\r\n",
    "    output = {}\r\n",
    "    alpha = 0.001\r\n",
    "    while (alpha <= 100):\r\n",
    "        model = method(alpha = alpha)\r\n",
    "        start = time.time()\r\n",
    "        model.fit(X_train_data, y_train_data) # Train the model\r\n",
    "        end = time.time()\r\n",
    "        y_pred = model.predict(X_test_data)\r\n",
    "\r\n",
    "        testing_score = model.score(X_test_data, y_test_data)\r\n",
    "        model_test[alpha] = testing_score\r\n",
    "        \r\n",
    "        alpha *= 10\r\n",
    "\r\n",
    "    best_alpha = max(model_test, key=model_test.get)\r\n",
    "    alpha = best_alpha/10\r\n",
    "    model_test = {}\r\n",
    "    while (alpha <= best_alpha * 10):\r\n",
    "        model = method(alpha = alpha)\r\n",
    "        model.fit(X_train_data, y_train_data) # Train the model\r\n",
    "        y_pred = model.predict(X_test_data)\r\n",
    "\r\n",
    "        training_score = model.score(X_train_data, y_train_data)\r\n",
    "        testing_score = model.score(X_test_data, y_test_data)\r\n",
    "\r\n",
    "        model_train[alpha] = training_score\r\n",
    "        model_test[alpha]= testing_score\r\n",
    "        model_time[alpha]= end - start\r\n",
    "        \r\n",
    "        alpha += best_alpha/10\r\n",
    "\r\n",
    "    best_alpha = max(model_test, key=model_test.get)\r\n",
    "    model = method(alpha = best_alpha)\r\n",
    "    start = time.time()\r\n",
    "    model.fit(X_train_data, y_train_data)\r\n",
    "    end = time.time()\r\n",
    "    y_pred = model.predict(X_test_data)\r\n",
    "    print(\"Best regularisation constant: \", best_alpha)\r\n",
    "    print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\r\n",
    "    print(\"Training Score: \", model_train[best_alpha])\r\n",
    "    print(\"Testing Score: \", model_test[best_alpha])\r\n",
    "    print(\"Time Taken: \", model_time[best_alpha])\r\n",
    "\r\n",
    "    if show_graph:\r\n",
    "        plt.plot(list(model_train.keys()), list(model_train.values()), label = 'Training score')\r\n",
    "        plt.plot(list(model_test.keys()), list(model_test.values()), label = 'Testing score')\r\n",
    "        plt.title(\"Score vs Regularisation constant\")\r\n",
    "        plt.xlabel(\"Regularisation\")\r\n",
    "        plt.ylabel(\"Score\")\r\n",
    "        plt.legend()\r\n",
    "    \r\n",
    "    output['model'] = model\r\n",
    "    output['best alpha'] = best_alpha\r\n",
    "    output['training'] = model_train[best_alpha]\r\n",
    "    output['testing'] = model_test[best_alpha]\r\n",
    "    output['time'] = model_time[best_alpha]\r\n",
    "    \r\n",
    "    return output\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "3a2ae5e4-c48d-4699-aa99-510e1a2e568f"
   },
   "outputs": [],
   "source": [
    "## Model Parameters\r\n",
    "You may set your own model parameters or let the notebook find the most optimal parameter"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "12986a72-2d7c-4961-8c1b-7aa394394d9f"
   },
   "outputs": [],
   "source": [
    "# For polynomial regression\r\n",
    "poly_degree = 'auto' # Put 'auto' to run multiple degrees\r\n",
    "\r\n",
    "# For decision tree regression\r\n",
    "tree_depth = 'auto' # Put 'auto' to run multiple depths\r\n",
    "\r\n",
    "# For MLP Regression\r\n",
    "hidden_layer_size = 'auto' # Put 'auto' to run default layer size"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "6ceb4603-36eb-4d85-89bd-0df93463aa1f"
   },
   "outputs": [],
   "source": [
    "## Limits"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 3,
     "id": "c8551555-d614-4c78-8e69-7d3afdcaed9c",
     "path": "/Personal/zihan/regression.ipynb",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "5f5c462e-afa7-4587-a9db-e1bcbf13cfd8"
   },
   "outputs": [],
   "source": [
    "poly_limit = 4 # Limit for polynomial degree\r\n",
    "max_depth = 5 # Limit for decision tree depth\r\n",
    "max_layer_size = 200 # Limit for MLP layer size"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "753023fd-e7a3-4993-ba44-783ed39a12b5"
   },
   "outputs": [],
   "source": [
    "# Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "97e208b8-86f6-4505-9656-0bfc503bef41",
     "path": "/Personal/zihan/regression.ipynb",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "47d10076-0ebb-4584-aee9-fa41338cd81b"
   },
   "outputs": [],
   "source": [
    "run_models = ['linear', 'l1_linear', 'l2_linear', 'poly', 'tree'] # Specify the models you would like to run in the list\r\n",
    "# Possible models: ['linear', 'l1_linear', 'l2_linear', 'poly', 'tree', 'forest', 'mlp']\r\n",
    "\r\n",
    "if not run_models:\r\n",
    "    raise ValueError('You must pick at least 1 model to run')"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "bb2b63cb-de52-40ad-8692-2eb79d098c93"
   },
   "outputs": [],
   "source": [
    "linear_index = [\"Training Score\", \"Testing Score\", \"Regularisation\"]\r\n",
    "poly_index = [\"Training Score\", \"Testing Score\", \"Regularisation\"]\r\n",
    "tree_index = [\"Training Score\", \"Testing Score\"]\r\n",
    "forest_index = [\"Training Score\", \"Testing Score\"]\r\n",
    "mlp_index = [\"Training Score\", \"Testing Score\"]\r\n",
    "\r\n",
    "divider = '____________________________________________________________________'"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "bafc70f1-a64f-4139-b9a3-d3698e1edc54"
   },
   "outputs": [],
   "source": [
    "## Linear Regression\r\n",
    "Ordinary Least Squares Regression"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "c7f407be-2925-4a0a-a39d-6d9d02837818"
   },
   "outputs": [],
   "source": [
    "def run_linear(X_train_data, y_train_data, X_test_data, y_test_data, show_graph=False, show_params=True):\r\n",
    "    print(\"Linear Regression\")\r\n",
    "    linear = LinearRegression()\r\n",
    "    start = time.time()\r\n",
    "    linear.fit(X_train_data, y_train_data) # Train the model\r\n",
    "    end = time.time()\r\n",
    "    y_pred = linear.predict(X_test_data)\r\n",
    "\r\n",
    "    if show_params:\r\n",
    "        # The coefficients and intercept\r\n",
    "        linear_coef = pd.DataFrame(linear.coef_)\r\n",
    "        if num_target_labels == 1:\r\n",
    "            linear_coef.index = labels\r\n",
    "        else:\r\n",
    "            linear_coef.columns = labels\r\n",
    "            linear_coef.index = target_labels\r\n",
    "        print(\"Coefficients: \\n\", linear_coef)\r\n",
    "        print(\"Intercept: \", linear.intercept_)\r\n",
    "        \r\n",
    "    # The mean squared error\r\n",
    "    print(\"Mean squared error: %.2f\" % mean_squared_error(y_test_data, y_pred))\r\n",
    "    # Training and testing scores\r\n",
    "    training = linear.score(X_train_data, y_train_data)\r\n",
    "    testing = linear.score(X_test_data, y_test_data)\r\n",
    "    print(\"Training score: %.2f\" % training)\r\n",
    "    print(\"Testing score: %.2f\" % testing)\r\n",
    "\r\n",
    "    # Time taken\r\n",
    "    time_taken = end - start\r\n",
    "    print(\"Time Taken: \", time_taken)\r\n",
    "\r\n",
    "    # Show the plot for the model if in 2D\r\n",
    "    if show_graph:\r\n",
    "        if (num_labels == 1):\r\n",
    "            plt.scatter(X_test_data, y_test_data, color=\"red\")\r\n",
    "            plt.plot(X_test_data, y_pred, color=\"blue\", linewidth=3)\r\n",
    "\r\n",
    "            plt.title(\"Linear Regression of \" + labels[0] + \" and \" + target)\r\n",
    "            plt.xlabel(labels[0])\r\n",
    "            plt.ylabel(target)\r\n",
    "            plt.show()\r\n",
    "        else:\r\n",
    "            print(\"No visualisation available for models in higher dimensions\")\r\n",
    "\r\n",
    "    print(divider)\r\n",
    "\r\n",
    "\r\n",
    "    return [linear, training, testing, time_taken]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "b612d1cb-3444-4cc8-b546-c5e03139edde"
   },
   "outputs": [],
   "source": [
    "## L1 Regularised Linear Regression\r\n",
    "Linear Model trained with L1 prior as regulariser (aka the Lasso)."
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "9b292f66-ba29-4b82-af9b-4f1209f54a34"
   },
   "outputs": [],
   "source": [
    "def run_l1_linear(X_train_data, y_train_data, X_test_data, y_test_data, show_graph=False, show_params=True):\r\n",
    "    print(\"L1 (Lasso) Linear Regression\")\r\n",
    "    l1_linear_train = {}\r\n",
    "    l1_linear_test = {}\r\n",
    "    l1_linear_time = {}\r\n",
    "    if regularisation_constant != 'auto':\r\n",
    "        alpha = regularisation_constant\r\n",
    "        l1_linear = Lasso(alpha = alpha)\r\n",
    "        start = time.time()\r\n",
    "        l1_linear.fit(X_train_data, y_train_data) # Train the model\r\n",
    "        end = time.time()\r\n",
    "        y_pred = l1_linear.predict(X_test_data)\r\n",
    "\r\n",
    "        if show_params:\r\n",
    "            # The coefficients and intercept\r\n",
    "            l1_linear_coef = pd.DataFrame(l1_linear.coef_)\r\n",
    "            if num_target_labels == 1:\r\n",
    "                l1_linear_coef.index = labels\r\n",
    "            else:\r\n",
    "                l1_linear_coef.columns = labels\r\n",
    "                l1_linear_coef.index = target_labels\r\n",
    "            print(\"Coefficients: \\n\", l1_linear_coef)\r\n",
    "            print(\"Intercept: \", l1_linear.intercept_)\r\n",
    "\r\n",
    "        # The mean squared error\r\n",
    "        print(\"Mean squared error: %.2f\" % mean_squared_error(y_test_data, y_pred))\r\n",
    "        # Training and testing scores\r\n",
    "        print(\"Training score: %.2f\" % l1_linear.score(X_train_data, y_train))\r\n",
    "        print(\"Testing score: %.2f\" % l1_linear.score(X_test_data, y_test))\r\n",
    "\r\n",
    "        #Time taken\r\n",
    "        train_time = end - start\r\n",
    "        print(\"Time Taken: \", train_time)\r\n",
    "    else:\r\n",
    "        regularise_output = auto_regularise(X_train_data, X_test_data, y_train_data, y_test_data, Lasso)\r\n",
    "        l1_linear = regularise_output['model']\r\n",
    "        best_alpha = regularise_output['best alpha']\r\n",
    "        train_time = regularise_output['time']\r\n",
    "\r\n",
    "        if show_params:\r\n",
    "        # The coefficients and intercept\r\n",
    "            l1_linear_coef = pd.DataFrame(l1_linear.coef_)\r\n",
    "            if num_target_labels == 1:\r\n",
    "                l1_linear_coef.index = labels\r\n",
    "            else:\r\n",
    "                l1_linear_coef.columns = labels\r\n",
    "                l1_linear_coef.index = target_labels\r\n",
    "            print(\"Coefficients: \\n\", l1_linear_coef)\r\n",
    "            print(\"Intercept: \", l1_linear.intercept_)\r\n",
    "    \r\n",
    "    training = l1_linear.score(X_train_data, y_train_data)\r\n",
    "    testing = l1_linear.score(X_test_data, y_test_data)\r\n",
    "    regularisation = best_alpha if regularisation_constant == 'auto' else regularisation_constant\r\n",
    "\r\n",
    "    if show_graph:\r\n",
    "        if (num_labels == 1):\r\n",
    "            plt.scatter(X_test_data, y_test_data, color=\"red\")\r\n",
    "            plt.plot(X_test_data, y_pred, color=\"blue\", linewidth=3)\r\n",
    "\r\n",
    "            plt.title(\"L1 Regularised Linear Regression of \" + labels[0] + \" and \" + target)\r\n",
    "            plt.xlabel(labels[0])\r\n",
    "            plt.ylabel(target)\r\n",
    "            plt.show()\r\n",
    "        else:\r\n",
    "            print(\"No visualisation available for models in higher dimensions\")\r\n",
    "\r\n",
    "    print(divider)\r\n",
    "\r\n",
    "    return [l1_linear, training, testing, regularisation, train_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "5b50006d-6bc7-4575-9d1c-c9483381b7fc"
   },
   "outputs": [],
   "source": [
    "## L2 Regularised Linear Regression\r\n",
    "Linear Model trained with L2 prior as regulariser (aka the Ridge)."
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "5580861d-cf8a-4384-9587-9c8c3f8d6541"
   },
   "outputs": [],
   "source": [
    "def run_l2_linear(X_train_data, y_train_data, X_test_data, y_test_data, show_graph=False, show_params=True):\r\n",
    "    print('L2 (Ridge) Linear Regression')\r\n",
    "    l2_linear_train = {}\r\n",
    "    l2_linear_test = {}\r\n",
    "    l2_linear_time = {}\r\n",
    "    if regularisation_constant != 'auto':\r\n",
    "        alpha = regularisation_constant\r\n",
    "        l2_linear = Ridge(alpha = alpha)\r\n",
    "        start = time.time()\r\n",
    "        l2_linear.fit(X_train_data, y_train_data) # Train the model\r\n",
    "        end = time.time()\r\n",
    "        y_pred = l2_linear.predict(X_test_data)\r\n",
    "\r\n",
    "        if show_params:\r\n",
    "            # The coefficients and intercept\r\n",
    "            l2_linear_coef = pd.DataFrame(l2_linear.coef_)\r\n",
    "            if num_target_labels == 1:\r\n",
    "                l2_linear_coef.index = labels\r\n",
    "            else:\r\n",
    "                l2_linear_coef.columns = labels\r\n",
    "                l2_linear_coef.index = target_labels\r\n",
    "            print(\"Coefficients: \\n\", l2_linear_coef)\r\n",
    "            print(\"Intercept: \", l2_linear.intercept_)\r\n",
    "\r\n",
    "        # The mean squared error\r\n",
    "        print(\"Mean squared error: %.2f\" % mean_squared_error(y_test_data, y_pred))\r\n",
    "        # Training and testing scores\r\n",
    "        print(\"Training score: %.2f\" % l2_linear.score(X_train_data, y_train_data))\r\n",
    "        print(\"Testing score: %.2f\" % l2_linear.score(X_test_data, y_test_data))\r\n",
    "\r\n",
    "        #Time taken\r\n",
    "        train_time = end - start\r\n",
    "        print(\"Time Taken: \", train_time)\r\n",
    "    else:\r\n",
    "        regularise_output = auto_regularise(X_train_data, X_test_data, y_train_data, y_test_data, Ridge)\r\n",
    "        l2_linear = regularise_output['model']\r\n",
    "        best_alpha = regularise_output['best alpha']\r\n",
    "        train_time = regularise_output['time']\r\n",
    "\r\n",
    "        if show_params:\r\n",
    "            # The coefficients and intercept\r\n",
    "            l2_linear_coef = pd.DataFrame(l2_linear.coef_)\r\n",
    "            if num_target_labels == 1:\r\n",
    "                l2_linear_coef.index = labels\r\n",
    "            else:\r\n",
    "                l2_linear_coef.columns = labels\r\n",
    "                l2_linear_coef.index = target_labels\r\n",
    "            print(\"Coefficients: \\n\", l2_linear_coef)\r\n",
    "            print(\"Intercept: \", l2_linear.intercept_)\r\n",
    "\r\n",
    "    training = l2_linear.score(X_train_data, y_train_data)\r\n",
    "    testing = l2_linear.score(X_test_data, y_test_data)\r\n",
    "    regularisation = best_alpha if regularisation_constant == 'auto' else regularisation_constant\r\n",
    "\r\n",
    "    if show_graph:\r\n",
    "        if (num_labels == 1):\r\n",
    "            plt.scatter(X_test_data, y_test_data, color=\"red\")\r\n",
    "            plt.plot(X_test_data, y_pred, color=\"blue\", linewidth=3)\r\n",
    "\r\n",
    "            plt.title(\"L2 Regularised Linear Regression of \" + labels[0] + \" and \" + target)\r\n",
    "            plt.xlabel(labels[0])\r\n",
    "            plt.ylabel(target)\r\n",
    "            plt.show()\r\n",
    "        else:\r\n",
    "            print(\"No visualisation available for models in higher dimensions\")\r\n",
    "\r\n",
    "    print(divider)\r\n",
    "    \r\n",
    "    return [l2_linear, training, testing, regularisation, train_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "f63e3345-08bb-4685-9d69-47cb720e1eb0"
   },
   "outputs": [],
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "f38aea8d-607b-4104-949f-0abeea11c502"
   },
   "outputs": [],
   "source": [
    "def run_poly(X_train_data, y_train_data, X_test_data, y_test_data, regularisation_method, poly_data, show_params=True):\r\n",
    "    print('Polynomial Regression')\r\n",
    "    degree = 2 if poly_degree == 'auto' else poly_degree\r\n",
    "    while degree <= poly_limit:\r\n",
    "        poly = PolynomialFeatures(degree=degree, include_bias=False)\r\n",
    "        poly_X_train = poly.fit_transform(X_train_data)\r\n",
    "        poly_X_test = poly.fit_transform(X_test_data)\r\n",
    "        poly_train = {}\r\n",
    "        poly_test = {}\r\n",
    "        poly_time = {}\r\n",
    "        if regularisation_constant != 'auto':\r\n",
    "            poly_reg = Ridge(alpha = regularisation_constant)\r\n",
    "            start = time.time()\r\n",
    "            poly_reg.fit(poly_X_train, y_train_data) # Train the model\r\n",
    "            end = time.time()\r\n",
    "            y_pred = poly_reg.predict(poly_X_test)\r\n",
    "\r\n",
    "            if show_params:\r\n",
    "                # The coefficients and intercept\r\n",
    "                poly_coef = pd.DataFrame(poly_reg.coef_)\r\n",
    "                print(\"Coefficients: \\n\", poly_coef)\r\n",
    "                print(\"Intercept: \", poly_reg.intercept_)\r\n",
    "\r\n",
    "            # The mean squared error\r\n",
    "            print(\"Mean squared error: %.2f\" % mean_squared_error(y_test_data, y_pred))\r\n",
    "            # Training and testing scores\r\n",
    "            print(\"Training score: %.2f\" % poly_reg.score(poly_X_train, y_train_data))\r\n",
    "            print(\"Testing score: %.2f\" % poly_reg.score(poly_X_test, y_test_data))\r\n",
    "\r\n",
    "            #Time taken\r\n",
    "            print(\"Time Taken: \", end - start)\r\n",
    "\r\n",
    "        else:\r\n",
    "            regularise_output = auto_regularise(poly_X_train, poly_X_test, y_train_data, y_test_data, regularisation_method)\r\n",
    "            poly_reg = regularise_output['model']\r\n",
    "            best_alpha = regularise_output['best alpha']\r\n",
    "            train_time = regularise_output['time']\r\n",
    "            # The coefficients and intercept\r\n",
    "            poly_coef = pd.DataFrame(poly_reg.coef_)\r\n",
    "            print(\"Coefficients: \\n\", poly_coef)\r\n",
    "            print(\"Intercept: \", poly_reg.intercept_)\r\n",
    "\r\n",
    "        poly_data[degree] = []\r\n",
    "        poly_data[degree].append(poly_reg.score(poly_X_train, y_train_data))\r\n",
    "        poly_data[degree].append(poly_reg.score(poly_X_test, y_test_data))\r\n",
    "        poly_data[degree].append(best_alpha if regularisation_constant == 'auto' else regularisation_constant)\r\n",
    "        if poly_degree != 'auto':\r\n",
    "            break\r\n",
    "        degree += 1\r\n",
    "    \r\n",
    "    poly_df = pd.DataFrame(poly_data)\r\n",
    "    poly_df.index = poly_index\r\n",
    "    best_degree = poly_df.loc[['Testing Score']].idxmax(axis=1)[0]\r\n",
    "    poly = PolynomialFeatures(degree=best_degree, include_bias=False)\r\n",
    "    poly_X_train = poly.fit_transform(X_train_data)\r\n",
    "    poly_X_test = poly.fit_transform(X_test_data)\r\n",
    "    poly_reg = regularisation_method(alpha = poly_df[best_degree][2])\r\n",
    "    start = time.time()\r\n",
    "    poly_reg.fit(poly_X_train, y_train_data) # Train the best model\r\n",
    "    end = time.time()\r\n",
    "\r\n",
    "    testing = poly_df[best_degree][1]\r\n",
    "    time_taken = end - start\r\n",
    "\r\n",
    "    print(divider)\r\n",
    "\r\n",
    "    return [poly_reg, testing, time_taken, poly]\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "b53a6c24-ea62-4348-be09-71ea354ec4ef"
   },
   "outputs": [],
   "source": [
    "## Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "519ee261-dcaa-4267-83d5-d09243a33855"
   },
   "outputs": [],
   "source": [
    "def run_tree(X_train_data, y_train_data, X_test_data, y_test_data, tree_data):\r\n",
    "    print(\"Decision Tree Regression\")\r\n",
    "    depth = 1 if tree_depth == 'auto' else tree_depth\r\n",
    "    while depth <= max_depth:\r\n",
    "        tree = DecisionTreeRegressor(max_depth=depth)\r\n",
    "        start = time.time()\r\n",
    "        tree.fit(X_train_data, y_train_data)\r\n",
    "        end = time.time()\r\n",
    "        y_pred = tree.predict(X_test_data)\r\n",
    "\r\n",
    "        # The depth and leaves\r\n",
    "        print(\"Depth: \\n\", tree.get_depth())\r\n",
    "        print(\"Leaves: \", tree.get_n_leaves())\r\n",
    "\r\n",
    "        # The mean squared error\r\n",
    "        print(\"Mean squared error: %.2f\" % mean_squared_error(y_test_data, y_pred))\r\n",
    "        # Training and testing scores\r\n",
    "        training = tree.score(X_train_data, y_train_data)\r\n",
    "        testing = tree.score(X_test_data, y_test_data)\r\n",
    "        print(\"Training score: %.2f\" % training)\r\n",
    "        print(\"Testing score: %.2f\" % testing)\r\n",
    "\r\n",
    "        #Time taken\r\n",
    "        print(\"Time Taken: \", end - start)\r\n",
    "\r\n",
    "        tree_data[depth] = []\r\n",
    "        tree_data[depth].append(training)\r\n",
    "        tree_data[depth].append(testing)\r\n",
    "\r\n",
    "        if tree_depth != 'auto':\r\n",
    "            break\r\n",
    "        depth += 1\r\n",
    "\r\n",
    "    tree_df = pd.DataFrame(tree_data)\r\n",
    "    tree_df.index = tree_index\r\n",
    "\r\n",
    "    best_depth = tree_df.loc[['Testing Score']].idxmax(axis=1)[0]\r\n",
    "    tree = DecisionTreeRegressor(max_depth=best_depth)\r\n",
    "    start = time.time()\r\n",
    "    tree.fit(X_train_data, y_train_data) # Train the best model\r\n",
    "    end = time.time()\r\n",
    "\r\n",
    "    testing = tree_df[best_depth][1]\r\n",
    "    time_taken = end - start\r\n",
    "\r\n",
    "    print(divider)\r\n",
    "\r\n",
    "    return [tree, testing, time_taken]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "7d153c52-dba3-4f8a-8126-4416f91ec89d"
   },
   "outputs": [],
   "source": [
    "## Random Forests Regression"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "dde0e383-d77e-402b-9e31-d97369bdaa0e"
   },
   "outputs": [],
   "source": [
    "def run_forest(X_train_data, y_train_data, X_test_data, y_test_data, forest_data):\r\n",
    "    print(\"Random Forests Regression\")\r\n",
    "    depth = 1 if tree_depth == 'auto' else tree_depth\r\n",
    "    while depth <= max_depth:\r\n",
    "        forest = RandomForestRegressor(max_depth=depth)\r\n",
    "        start = time.time()\r\n",
    "        forest.fit(X_train_data, y_train_data)\r\n",
    "        end = time.time()\r\n",
    "        y_pred = forest.predict(X_test_data)\r\n",
    "\r\n",
    "        # The mean squared error\r\n",
    "        print(\"Mean squared error: %.2f\" % mean_squared_error(y_test_data, y_pred))\r\n",
    "        # Training and testing scores\r\n",
    "        training = forest.score(X_train_data, y_train_data)\r\n",
    "        testing = forest.score(X_test_data, y_test_data)\r\n",
    "        print(\"Training score: %.2f\" % training)\r\n",
    "        print(\"Testing score: %.2f\" % testing)\r\n",
    "\r\n",
    "        #Time taken\r\n",
    "        print(\"Time Taken: \", end - start)\r\n",
    "\r\n",
    "        forest_data[depth] = []\r\n",
    "        forest_data[depth].append(training)\r\n",
    "        forest_data[depth].append(testing)\r\n",
    "\r\n",
    "        if tree_depth != 'auto':\r\n",
    "            break\r\n",
    "        depth += 1\r\n",
    "\r\n",
    "    forest_df = pd.DataFrame(forest_data)\r\n",
    "    forest_df.index = forest_index\r\n",
    "\r\n",
    "    best_depth = forest_df.loc[['Testing Score']].idxmax(axis=1)[0]\r\n",
    "    forest = RandomForestRegressor(max_depth=best_depth)\r\n",
    "    start = time.time()\r\n",
    "    forest.fit(X_train, y_train) # Train the best model\r\n",
    "    end = time.time()\r\n",
    "\r\n",
    "    training = forest_df[best_depth][1]\r\n",
    "    time_taken = end - start\r\n",
    "\r\n",
    "    print(divider)\r\n",
    "\r\n",
    "    return [forest, training, time_taken]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "6e4d5774-3e14-47a0-acdc-fc93bb18eac3"
   },
   "outputs": [],
   "source": [
    "## Neural Networks/Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "2001da44-61ab-45aa-9cbc-3ee6e798c386"
   },
   "outputs": [],
   "source": [
    "def run_mlp(X_train_data, y_train_data, X_test_data, y_test_data, mlp_data):\r\n",
    "    print(\"MLP Regression\")\r\n",
    "    layer_size = 100 if hidden_layer_size == 'auto' else hidden_layer_size\r\n",
    "    alpha = 0.0001 if regularisation_constant == 'auto' else regularisation_constant\r\n",
    "    mlp_train = {}\r\n",
    "    mlp_test = {}\r\n",
    "    mlp_time = {}\r\n",
    "    if regularisation_constant != 'auto':\r\n",
    "        mlp = MLPRegressor(alpha = alpha)\r\n",
    "        start = time.time()\r\n",
    "        mlp.fit(X_train_data, y_train_data) # Train the model\r\n",
    "        end = time.time()\r\n",
    "        y_pred = mlp.predict(X_test_data)\r\n",
    "        train_time = end - start\r\n",
    "\r\n",
    "        print(\"Hidden Layer Size: \", layer_size)\r\n",
    "        print(\"Mean squared error: %.2f\" % mean_squared_error(y_test_data, y_pred))\r\n",
    "        print(\"Training Score: \", mlp.score(X_train_data, y_train_data))\r\n",
    "        print(\"Testing Score: \", mlp.score(X_test_data, y_test_data))\r\n",
    "        print(\"Time Taken: \", train_time)\r\n",
    "    else:\r\n",
    "        print(\"Hidden Layer Size: \", layer_size)\r\n",
    "        regularise_output = auto_regularise(X_train_data, X_test_data, y_train_data, y_test_data, MLPRegressor)\r\n",
    "        mlp = regularise_output['model']\r\n",
    "        best_alpha = regularise_output['best alpha']\r\n",
    "        train_time = regularise_output['time']\r\n",
    "\r\n",
    "    training = mlp.score(X_train_data, y_train_data)\r\n",
    "    testing = mlp.score(X_test_data, y_test_data)\r\n",
    "\r\n",
    "    mlp_data[layer_size] = []\r\n",
    "    mlp_data[layer_size].append(training)\r\n",
    "    mlp_data[layer_size].append(testing)\r\n",
    "\r\n",
    "    print(divider)\r\n",
    "\r\n",
    "    return [mlp, training, testing, train_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "771255b0-659b-451c-9ce9-071685746d2e"
   },
   "outputs": [],
   "source": [
    "## Running the models"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "768e4b66-503e-4666-b2ef-ab88d4bbe321"
   },
   "outputs": [],
   "source": [
    "def run_regression(X_train, y_train, X_test, y_test, X_train_half, y_train_half):\n",
    "    models = {}\n",
    "    model_score = {}\n",
    "    model_time = {}\n",
    "    model_score_half = {}\n",
    "    half = 'Training with half the data'\n",
    "\n",
    "    linear_data = {\"No Regularisation\": [], \"L1\": [], \"L2\": []}\n",
    "    poly_data = {}\n",
    "    half_poly_data = {}\n",
    "    tree_data = {}\n",
    "    half_tree_data = {}\n",
    "    forest_data = {}\n",
    "    half_forest_data = {}\n",
    "    mlp_data = {}\n",
    "    half_mlp_data = {}\n",
    "\n",
    "    if 'linear' in run_models:\n",
    "        model, training, testing, time_taken = run_linear(X_train, y_train, X_test, y_test)\n",
    "        linear_data[\"No Regularisation\"].append(training)\n",
    "        linear_data[\"No Regularisation\"].append(testing)\n",
    "        linear_data[\"No Regularisation\"].append(0)\n",
    "\n",
    "        models['linear'] = model\n",
    "        model_score['linear'] = []\n",
    "        model_score['linear'].append(testing)\n",
    "        model_score['linear'].append(time_taken)\n",
    "\n",
    "        print(half)\n",
    "        model, training, testing, time_taken = run_linear(X_train_half, y_train_half, X_test, y_test, show_params=False)\n",
    "        model_score_half['linear'] = []\n",
    "        model_score_half['linear'].append(testing)\n",
    "        model_score_half['linear'].append(time_taken)\n",
    "\n",
    "    if 'l1_linear' in run_models:\n",
    "        model, training, testing, regularisation, time_taken = run_l1_linear(X_train, y_train, X_test, y_test)\n",
    "        linear_data[\"L1\"].append(training)\n",
    "        linear_data[\"L1\"].append(testing)\n",
    "        linear_data[\"L1\"].append(regularisation)\n",
    "\n",
    "        models['l1_linear'] = model\n",
    "        model_score['l1_linear'] = []\n",
    "        model_score['l1_linear'].append(testing)\n",
    "        model_score['l1_linear'].append(time_taken)\n",
    "\n",
    "        print(half)\n",
    "        model, training, testing, regularisation, time_taken = run_l1_linear(X_train_half, y_train_half, X_test, y_test, show_params=False)\n",
    "        model_score_half['l1_linear'] = []\n",
    "        model_score_half['l1_linear'].append(testing)\n",
    "        model_score_half['l1_linear'].append(time_taken)\n",
    "\n",
    "    if 'l2_linear' in run_models:\n",
    "        model, training, testing, regularisation, time_taken = run_l2_linear(X_train, y_train, X_test, y_test)\n",
    "        linear_data[\"L2\"].append(training)\n",
    "        linear_data[\"L2\"].append(testing)\n",
    "        linear_data[\"L2\"].append(regularisation)\n",
    "\n",
    "        models['l2_linear'] = model\n",
    "        model_score['l2_linear'] = []\n",
    "        model_score['l2_linear'].append(testing)\n",
    "        model_score['l2_linear'].append(time_taken)\n",
    "\n",
    "        print(half)\n",
    "        model, training, testing, regularisation, time_taken = run_l2_linear(X_train_half, y_train_half, X_test, y_test, show_params=False)\n",
    "        model_score_half['l2_linear'] = []\n",
    "        model_score_half['l2_linear'].append(testing)\n",
    "        model_score_half['l2_linear'].append(time_taken)\n",
    "\n",
    "    if 'poly' in run_models:\n",
    "        model, testing, time_taken, poly = run_poly(X_train, y_train, X_test, y_test, Ridge, poly_data)\n",
    "\n",
    "        models['poly'] = model\n",
    "        model_score['poly'] = []\n",
    "        model_score['poly'].append(testing)\n",
    "        model_score['poly'].append(time_taken)\n",
    "        model_score['poly'].append(poly)\n",
    "        \n",
    "        print(half)\n",
    "        model, testing, time_taken, poly = run_poly(X_train_half, y_train_half, X_test, y_test, Ridge, half_poly_data, show_params=False)\n",
    "        model_score_half['poly'] = []\n",
    "        model_score_half['poly'].append(testing)\n",
    "        model_score_half['poly'].append(time_taken)\n",
    "\n",
    "    if 'tree' in run_models:\n",
    "        model, testing, time_taken = run_tree(X_train, y_train, X_test, y_test, tree_data)\n",
    "\n",
    "        models['tree'] = model\n",
    "        model_score['tree'] = []\n",
    "        model_score['tree'].append(testing)\n",
    "        model_score['tree'].append(time_taken)\n",
    "\n",
    "        print(half)\n",
    "        model, testing, time_taken = run_tree(X_train_half, y_train_half, X_test, y_test, half_tree_data)\n",
    "        model_score_half['tree'] = []\n",
    "        model_score_half['tree'].append(testing)\n",
    "        model_score_half['tree'].append(time_taken)\n",
    "\n",
    "    if 'forest' in run_models:\n",
    "        model, testing, time_taken = run_forest(X_train, y_train, X_test, y_test, forest_data)\n",
    "\n",
    "        models['forest'] = model\n",
    "        model_score['forest'] = []\n",
    "        model_score['forest'].append(testing)\n",
    "        model_score['forest'].append(time_taken)\n",
    "\n",
    "        print(half)\n",
    "        model, testing, time_taken = run_forest(X_train_half, y_train_half, X_test, y_test, half_forest_data)\n",
    "        model_score_half['forest'] = []\n",
    "        model_score_half['forest'].append(testing)\n",
    "        model_score_half['forest'].append(time_taken)\n",
    "\n",
    "\n",
    "    if 'mlp' in run_models:\n",
    "        model, training, testing, time_taken = run_mlp(X_train, y_train, X_test, y_test, mlp_data)\n",
    "\n",
    "        models['mlp'] = model\n",
    "        model_score['mlp'] = []\n",
    "        model_score['mlp'].append(testing)\n",
    "        model_score['mlp'].append(time_taken)\n",
    "\n",
    "        print(half)\n",
    "        model, training, testing, time_taken = run_mlp(X_train_half, y_train_half, X_test, y_test, half_mlp_data)\n",
    "        model_score_half['mlp'] = []\n",
    "        model_score_half['mlp'].append(testing)\n",
    "        model_score_half['mlp'].append(time_taken)\n",
    "\n",
    "    return [models, model_score, model_time, model_score_half, linear_data, poly_data, tree_data, forest_data, mlp_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "66e829ee-2eab-4785-b76c-a2e8bc8bf437"
   },
   "outputs": [],
   "source": [
    "if reduction_method == 'pca':\r\n",
    "    pca_components = n_pca_components if n_pca_components != 'auto' else len(labels)\r\n",
    "    while pca_components >= 1:\r\n",
    "        print('---------- Training with ' + str(pca_components) + ' components ----------')\r\n",
    "        X_train_data, X_train_data_half, X_test_data, labels, X_concat, pca_model = run_pca(X_train, X_train_half, X_test, pca_components)\r\n",
    "        pca_model_data[pca_components] = run_regression(X_train_data, y_train, X_test_data, y_test, X_train_data_half, y_train_half) + [X_concat, pca_model]\r\n",
    "        \r\n",
    "        if n_pca_components != 'auto':\r\n",
    "            break\r\n",
    "        pca_components -= 1\r\n",
    "    best_component_scores = {k:[v[1][max(v[1],key=v[1].get)][0], max(v[1],key=v[1].get)] for k,v in pca_model_data.items()}\r\n",
    "    print(best_component_scores)\r\n",
    "    best_n_components = max(best_component_scores, key=best_component_scores.get)\r\n",
    "    models, model_score, model_time, model_score_half, linear_data, poly_data, tree_data, forest_data, mlp_data, X_concat_pca, pca_model = pca_model_data[best_n_components]\r\n",
    "    \r\n",
    "else:\r\n",
    "    models, model_score, model_time, model_sy_dcore_half, linear_data, polata, tree_data, forest_data, mlp_data = run_regression(X_train, y_train, X_test, y_test, X_train_half, y_train_half)\r\n",
    "X_concat = pd.concat([pd.DataFrame(X_train), pd.DataFrame(X_test)])\r\n",
    "y_concat = pd.concat([pd.DataFrame(y_train), pd.DataFrame(y_test)])\r\n",
    "y_concat.columns = target_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "1b4943aa-5507-46e3-9541-9190f0b8cb95"
   },
   "outputs": [],
   "source": [
    "## Linear Regression Results\r\n",
    "Results will show for the PCA component with max score among all models"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "d831a555-4852-437c-8fe2-b4f50b16cabe"
   },
   "outputs": [],
   "source": [
    "linear_data = {k:v for k,v in linear_data.items() if v != []}\r\n",
    "if linear_data:\r\n",
    "    linear_df = pd.DataFrame(linear_data)\r\n",
    "    linear_df.index = linear_index\r\n",
    "    linear_df\r\n",
    "else:\r\n",
    "    print('No linear models run')"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "726f7a1d-73af-4d08-a9c5-e700f26df9ce"
   },
   "outputs": [],
   "source": [
    "if linear_data:\r\n",
    "    plt.title(\"Linear Regression Results\")\r\n",
    "    for index, reg in enumerate(linear_data):\r\n",
    "        if index == 0:\r\n",
    "            plt.bar([\"Training\", \"Testing\"], linear_data[reg][:-1], width = 0.1, label = reg)\r\n",
    "            continue\r\n",
    "        plt.bar(np.arange(len(linear_data[reg])-1) + 0.1 * index, linear_data[reg][:-1], width = 0.1, label = reg)\r\n",
    "\r\n",
    "    plt.legend(title='Regularisation')\r\n",
    "    plt.show()\r\n",
    "else:\r\n",
    "    print('No linear models run')"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "c381d25d-73dc-493a-a9d6-163b3054bc1d"
   },
   "outputs": [],
   "source": [
    "## Polynomial Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "704d439b-74fa-4557-b533-10c6ba261d69"
   },
   "outputs": [],
   "source": [
    "if poly_data:\r\n",
    "    poly_df = pd.DataFrame(poly_data)\r\n",
    "    poly_df.index = poly_index\r\n",
    "    poly_df\r\n",
    "else:\r\n",
    "    print('No polynomial models run')"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "e9c46355-95ae-4684-9a92-1f3eb4137495"
   },
   "outputs": [],
   "source": [
    "if poly_data:\r\n",
    "    plt.title(\"Polynomial Regression Results\")\r\n",
    "    for index, deg in enumerate(poly_data):\r\n",
    "        if index == 0:\r\n",
    "            plt.bar([\"Training\", \"Testing\"], poly_data[deg][:-1], width = 0.1, label = deg)\r\n",
    "            continue\r\n",
    "        plt.bar(np.arange(len(poly_data[deg])-1) + 0.1 * index, poly_data[deg][:-1], width = 0.1, label = deg)\r\n",
    "\r\n",
    "    plt.legend(title='Polynomial Degree')\r\n",
    "    plt.show()\r\n",
    "else:\r\n",
    "    print('No polynomial models run')"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "2dbbcc97-e6e8-4581-a419-74235e5bc260"
   },
   "outputs": [],
   "source": [
    "## Decision Tree Results"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "d1e23ced-868a-4102-848e-bee0d92c2b12"
   },
   "outputs": [],
   "source": [
    "if tree_data:\r\n",
    "    tree_df = pd.DataFrame(tree_data)\r\n",
    "    tree_df.index = tree_index\r\n",
    "    tree_df\r\n",
    "else:\r\n",
    "    print('No decision tree models run')"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "981e9abe-ff18-46a5-ad1d-df63c1e0c87c"
   },
   "outputs": [],
   "source": [
    "if tree_data:\r\n",
    "    plt.title(\"Decision Tree Regression Results\")\r\n",
    "    for index, depth in enumerate(tree_data):\r\n",
    "        if index == 0:\r\n",
    "            plt.bar([\"Training\", \"Testing\"], tree_data[depth], width = 0.1, label = depth)\r\n",
    "            continue\r\n",
    "        plt.bar(np.arange(len(tree_data[depth])) + 0.1 * index, tree_data[depth], width = 0.1, label = depth)\r\n",
    "\r\n",
    "    plt.legend(title='Tree Depth')\r\n",
    "    plt.show()\r\n",
    "else:\r\n",
    "    print('No decision tree models run')"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "2f8c2cd8-b099-4030-a947-c13a38f07aa5"
   },
   "outputs": [],
   "source": [
    "## Random Forests Result"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 6,
     "id": "97e208b8-86f6-4505-9656-0bfc503bef41",
     "path": "/Personal/zihan/regression.ipynb",
     "startLine": 6
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "e9fe867d-86bf-4fc7-b109-67012593e471"
   },
   "outputs": [],
   "source": [
    "if forest_data:\r\n",
    "    forest_df = pd.DataFrame(forest_data)\r\n",
    "    forest_df.index = forest_index\r\n",
    "    forest_df\r\n",
    "else:\r\n",
    "    print('No random forest models run')"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "202efa73-155c-4972-839e-d389a57746da"
   },
   "outputs": [],
   "source": [
    "if forest_data:\r\n",
    "    plt.title(\"Random Forests Regression Results\")\r\n",
    "    for index, depth in enumerate(forest_data):\r\n",
    "        if index == 0:\r\n",
    "            plt.bar([\"Training\", \"Testing\"], forest_data[depth], width = 0.1, label = depth)\r\n",
    "            continue\r\n",
    "        plt.bar(np.arange(len(forest_data[depth])) + 0.1 * index, forest_data[depth], width = 0.1, label = depth)\r\n",
    "\r\n",
    "    plt.legend(title='Tree Depth')\r\n",
    "    plt.show()\r\n",
    "else:\r\n",
    "    print('No random forest models run')"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "28d04cb0-ce6b-42f1-8191-4c07e673e81c"
   },
   "outputs": [],
   "source": [
    "## MLP Results"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "35094d00-2743-4e59-874f-c38a28df830a"
   },
   "outputs": [],
   "source": [
    "if mlp_data:\r\n",
    "    mlp_df = pd.DataFrame(mlp_data)\r\n",
    "    mlp_df.index = mlp_index\r\n",
    "    mlp_df\r\n",
    "else:\r\n",
    "    print('No MLP models run')"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "02dd7934-8103-44bc-89c3-c78259006521"
   },
   "outputs": [],
   "source": [
    "if mlp_data:\r\n",
    "    plt.title(\"MLP Regression Results\")\r\n",
    "    for index, size in enumerate(mlp_data):\r\n",
    "        if index == 0:\r\n",
    "            plt.bar([\"Training\", \"Testing\"], mlp_data[size], width = 0.1, label = size)\r\n",
    "            continue\r\n",
    "        plt.bar(np.arange(len(mlp_data[depth])) + 0.1 * index, mlp_data[size], width = 0.1, label = size)\r\n",
    "\r\n",
    "    plt.legend(title='Hidden Layer Size')\r\n",
    "    plt.show()\r\n",
    "else:\r\n",
    "    print('No MLP models run')"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "142a073e-d351-4763-b4ea-a29559d4d1b0"
   },
   "outputs": [],
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 3,
     "id": "a7938568-3e0c-45dc-8c2f-14a6604d5cda",
     "path": "/Personal/zihan/regression.ipynb",
     "startLine": 3
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "dd0d117c-b1c7-4976-9381-255bf63c25be"
   },
   "outputs": [],
   "source": [
    "if reduction_method == 'pca':\n",
    "    pca_df = pd.DataFrame(pca_model_data)\n",
    "    pca_df.index = ['models', 'model_score', 'model_time', 'model_score_half', 'linear_data', 'poly_data', 'tree_data', 'forest_data', 'mlp_data', 'X_concat', 'pca_model']\n",
    "    pca_df.to_csv(path + '/pcaresults.csv')\n",
    "    X_concat_pca.to_csv(path + '/X_concat_pca.csv')\n",
    "    dump(pca_model, path + '/pca_model.joblib')\n",
    "    pca_df"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 9,
     "id": "a7938568-3e0c-45dc-8c2f-14a6604d5cda",
     "path": "/Personal/zihan/regression.ipynb",
     "startLine": 4
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "ab8e40b9-be24-4d26-a756-040652febe55"
   },
   "outputs": [],
   "source": [
    "cleaned_model_score = model_score.copy()\r\n",
    "if cleaned_model_score['poly']:\r\n",
    "    cleaned_model_score['poly'] = cleaned_model_score['poly'][:2]\r\n",
    "score_df = pd.DataFrame(cleaned_model_score)\r\n",
    "score_df.index = ['Score', 'Time']\r\n",
    "score_df.to_csv(path + '/results.csv')\r\n",
    "X_concat.to_csv(path + '/X_concat.csv')\r\n",
    "y_concat.to_csv(path + '/y_concat.csv')\r\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "11c33ecd-ee97-4778-ac48-fc34aaf0dff9"
   },
   "outputs": [],
   "source": [
    "plt.title(\"Final Regression Results\")\r\n",
    "model = list(model_score.keys())\r\n",
    "score = [x[0] for x in list(model_score.values())]\r\n",
    "plt.bar(model, score)\r\n",
    "if 'linear' in run_models: # Shows baseline performance from linear regression if used\r\n",
    "    base_score = [score[0]] * len(score)\r\n",
    "    plt.plot(base_score, color='red')\r\n",
    "    print('Red line shows baseline performance from linear model')\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "71acc115-7ef0-441b-8b03-8483e222fdc3"
   },
   "outputs": [],
   "source": [
    "plt.title(\"Final Regression Times\")\r\n",
    "model = list(model_score.keys())\r\n",
    "final_time = [x[1] for x in list(model_score.values())]\r\n",
    "plt.bar(model, final_time)\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "2fa55d9b-fd56-4266-b8b1-6ff297e51ed1"
   },
   "outputs": [],
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "0cff78ef-f74e-4e55-95d2-26104ed3962a"
   },
   "outputs": [],
   "source": [
    "best_model = max(model_score, key=model_score.get)\r\n",
    "best_model_object = models[best_model] \r\n",
    "\r\n",
    "print(\"Best Model: \", best_model)\r\n",
    "print(\"Testing Score: \", model_score[best_model][0])\r\n",
    "print(\"Training Time: \", model_score[best_model][1])\r\n",
    "print(\"Parameters: \", best_model_object.get_params())\r\n",
    "print(\"Normalisation: \", normalisation_method)\r\n",
    "print(\"Principle Components: \", best_n_components if reduction_method == 'pca' else 'No PCR')\r\n",
    "\r\n",
    "best_model_object = models[best_model] # This is the trained best model\r\n",
    "dump(best_model_object, path + '/model.joblib')\r\n",
    "\r\n",
    "print(model_score[best_model])\r\n",
    "if best_model == 'poly':\r\n",
    "    dump(model_score[best_model][2], path + '/poly_transform.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "e65fc631-9aef-487b-acfe-fe974c2af8af"
   },
   "outputs": [],
   "source": [
    "## Results with half the training data\r\n",
    "Observe the difference in model performance with half the training data used"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 2,
     "id": "a7938568-3e0c-45dc-8c2f-14a6604d5cda",
     "path": "/Personal/zihan/regression.ipynb",
     "startLine": 2
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "9029601b-ce41-459f-b68a-c1bb71837e39"
   },
   "outputs": [],
   "source": [
    "score_half_df = pd.DataFrame(model_score_half)\n",
    "score_half_df.index = ['Half Score', 'Time']\n",
    "score_half_df"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 18,
     "id": "be770a2b-b380-42ae-9993-21f26568546d",
     "path": "/Personal/zihan/regression.ipynb",
     "startLine": 18
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "7a406b87-296e-49d8-a2f1-bec2eb04ab12"
   },
   "outputs": [],
   "source": [
    "barWidth = 0.25\r\n",
    "plt.title(\"Full vs Half Training Data Scores\")\r\n",
    "\r\n",
    "# Set position of bar on X axis\r\n",
    "br1 = np.arange(len(run_models))\r\n",
    "br2 = [x + barWidth for x in br1]\r\n",
    " \r\n",
    "# Make the plot\r\n",
    "plt.bar(br1, score_df.loc['Score'].values, width = barWidth, label ='Full Training')\r\n",
    "plt.bar(br2, score_half_df.loc['Half Score'].values, width = barWidth, label ='Half Training')\r\n",
    " \r\n",
    "# Adding Xticks\r\n",
    "plt.xlabel('Training Data')\r\n",
    "plt.ylabel('Scores')\r\n",
    "plt.xticks([r + barWidth for r in range(len(run_models))], run_models)\r\n",
    "\r\n",
    "plt.legend(title='Training Data')\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "b3c9b483-95ec-4781-becb-66eceb3c95cd"
   },
   "outputs": [],
   "source": [
    "def save_model(dirname):\r\n",
    "    isExist = os.path.exists('./' + dirname)\r\n",
    "    if isExist:\r\n",
    "        raise ValueError(\"Directory with name already exists\")\r\n",
    "        \r\n",
    "    copy_tree('./out', './' + dirname)\r\n",
    "\r\n",
    "# Uncomment this line and run this cell to save the most recent model\r\n",
    "# save_model('saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "7872c642-c9f3-4fd9-a279-cfafd1dce08c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
