{
 "cells": [
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "53e148ac-0cba-40d5-b545-1efb0a309fdd"
   },
   "outputs": [],
   "source": [
    "# Autoencoder Outlier Detection\r\n",
    "\r\n",
    "This is a template notebook for autoencoder outlier detection.\r\n",
    "\r\n",
    "Author: {{ cookiecutter.author_name }}\r\n",
    "Created: {{ cookiecutter.timestamp }}\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "38769bc5-32f5-41b0-ae74-310ac57c757e"
   },
   "outputs": [],
   "source": [
    "## How to use the notebook\r\n",
    "\r\n",
    "The following cells:\r\n",
    "- specify objective, variables, and data types,\r\n",
    "- set up the outlier detection models,\r\n",
    "- read dataset,\r\n",
    "- present results from the models.\r\n",
    "\r\n",
    "By default, the notebook is set up to run with an example (art daily small noise). To see how it works, run the notebook without changing the code.\r\n",
    "\r\n",
    "For your project, adjust the code in the linked cells with your objectives, variables, dataset etc. and then execute all cells in order.\r\n",
    "\r\n",
    "Please refer to autoencoder.board for detailed instructions."
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "01821558-8e1a-41ff-b0f4-714bd7253817"
   },
   "outputs": [],
   "source": [
    "# Link to experiments card (refresh and hit enter on this line to see the link)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "b7970e8a-e410-4c45-8612-70fd267a8929"
   },
   "outputs": [],
   "source": [
    "# Imports and General Setup"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "db486137-a6cd-4475-9ffd-e0714082bff2"
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import shutil\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from distutils.dir_util import copy_tree\r\n",
    "\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "0363ab2b-7907-496e-b80f-25862a8f608d"
   },
   "outputs": [],
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "bd35f439-4006-4c9f-8ba4-5da55adc1f35",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "95b4e037-3951-4f4a-bb39-2a04c12a8e83"
   },
   "outputs": [],
   "source": [
    "experiment_name = '{{cookiecutter.use_case_name}}'  # please provide a name for the outlier detection experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "f819e62a-7017-4323-9c47-61a6a8df733e"
   },
   "outputs": [],
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 2,
     "id": "91b472d3-82da-41e9-96e2-8389b64a2329",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "67f52528-f64e-4d9c-988d-f6767e5a6fc5"
   },
   "outputs": [],
   "source": [
    "time_series = True # Specify if the data is time series\n",
    "path = '{{cookiecutter.data_path}}' # Specify the path of the data, note that it should be 'clean' without anomalies.\n",
    "\n",
    "if path == 'default example':\n",
    "    path = 'https://raw.githubusercontent.com/erium/halerium-example-data/main/outlier_detection/art_daily_small_noise.csv'\n",
    "\n",
    "if time_series:\n",
    "    df = pd.read_csv(path, parse_dates=['date'], index_col = 'date')\n",
    "else:\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "num_col = len(df.columns)\n",
    "\n",
    "path = './../out'\n",
    "isExist = os.path.exists(path)\n",
    "if isExist:\n",
    "  for root, dirs, files in os.walk(path):\n",
    "      for f in files:\n",
    "          os.unlink(os.path.join(root, f))\n",
    "      for d in dirs:\n",
    "          shutil.rmtree(os.path.join(root, d))\n",
    "else:\n",
    "  os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "a323f682-a44f-4ac7-b501-b3cdfb5a2e01"
   },
   "outputs": [],
   "source": [
    "## Visualising the dataset"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "937d2596-060a-44da-9556-637597a3bb7f"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "e6d9c3ff-fff9-4af6-9b93-e3f0d61ef1ed"
   },
   "outputs": [],
   "source": [
    "n_bins = 50\r\n",
    "plt_v = 3\r\n",
    "plt_h = 6\r\n",
    "if time_series:\r\n",
    "    suptitle = 'Time Series, Frequency, and Box plots of features'\r\n",
    "    plt_row = 3\r\n",
    "    plt_v *= 3\r\n",
    "else:\r\n",
    "    suptitle = 'Frequency and Box plots of features'\r\n",
    "    plt_row = 2\r\n",
    "    plt_v *= 2\r\n",
    "\r\n",
    "\r\n",
    "if num_col == 1:\r\n",
    "    fig, axs = plt.subplots(plt_row, num_col, figsize=(plt_h*num_col, plt_v))\r\n",
    "    fig.suptitle(suptitle)\r\n",
    "    axs[0].hist(df[df.columns[0]], bins = n_bins)\r\n",
    "    axs[0].set_ylabel('Frequency')\r\n",
    "    axs[1].boxplot(df[df.columns[0]], vert=False)\r\n",
    "    axs[1].set_xlabel(df.columns[0])\r\n",
    "    if time_series:\r\n",
    "        axs[2].plot(df)\r\n",
    "        axs[2].set_xlabel('time')\r\n",
    "        axs[2].set_ylabel(df.columns[0])\r\n",
    "elif num_col > 1:\r\n",
    "    fig, axs = plt.subplots(plt_row, num_col, figsize=(plt_h*num_col, plt_v))\r\n",
    "    fig.suptitle(suptitle)\r\n",
    "    for i in range(num_col):\r\n",
    "        axs[0][i].hist(df[df.columns[i]], bins = n_bins)\r\n",
    "        axs[0][i].set_ylabel('Frequency')\r\n",
    "        axs[1][i].boxplot(df[df.columns[i]], vert=False)\r\n",
    "        axs[1][i].set_xlabel(df.columns[i])\r\n",
    "        if time_series:\r\n",
    "            axs[2][i].plot(df[df.columns[i]])\r\n",
    "            axs[2][i].set_xlabel('time')\r\n",
    "            axs[2][i].set_ylabel(df.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "d67915db-75e3-49b5-b9ce-a0a8a78df736"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "63ed0f66-d678-4b91-a208-b383536635ff"
   },
   "outputs": [],
   "source": [
    "# Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "aac239fc-4565-4c87-8f7a-18f0bdf7a723"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\r\n",
    "scaler.fit(df)\r\n",
    "df = pd.DataFrame(scaler.transform(df), index = df.index, columns = df.columns)\r\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "09e51add-4d5f-420a-adaf-5d9bdf9bbc07"
   },
   "outputs": [],
   "source": [
    "## Sequences\r\n",
    "The autoencoder model would expect sequences as input. These sequences are groups of data and may be grouped together by a common time period (eg. Samples in a day/week/month)."
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "ef57f692-1da9-4671-86c0-44c70439320a"
   },
   "outputs": [],
   "source": [
    "# Use an even factor/multiple of 32\r\n",
    "TIME_STEPS = 32 # In the example dataset, there is one data point every 5 minutes. 288 will be the timestamps in a day.\r\n",
    "\r\n",
    "# Generated training sequences for use in the model.\r\n",
    "def create_sequences(values, time_steps=TIME_STEPS):\r\n",
    "    output = []\r\n",
    "    for i in range(len(values) - time_steps + 1):\r\n",
    "        output.append(values[i : (i + time_steps)])\r\n",
    "    return np.stack(output)\r\n",
    "\r\n",
    "X_train = create_sequences(df.values)\r\n",
    "print('(Number of timestamps - time steps, time steps, num features)')\r\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 21,
     "id": "81b8c3ec-0282-4d4d-bd42-87dc83b06dd9",
     "startLine": 2
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "d5551051-fce0-46a7-a36b-dd3d133b817f"
   },
   "outputs": [],
   "source": [
    "# Convolutional Reconstruction Autoencoder\r\n",
    "model = keras.Sequential(\r\n",
    "    [\r\n",
    "        layers.Input(shape=(X_train.shape[1], X_train.shape[2])),\r\n",
    "        layers.Conv1D(\r\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\r\n",
    "        ),\r\n",
    "        layers.Dropout(rate=0.2),\r\n",
    "        layers.Conv1D(\r\n",
    "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\r\n",
    "        ),\r\n",
    "        layers.Conv1DTranspose(\r\n",
    "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\r\n",
    "        ),\r\n",
    "        layers.Dropout(rate=0.2),\r\n",
    "        layers.Conv1DTranspose(\r\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\r\n",
    "        ),\r\n",
    "        layers.Conv1DTranspose(filters=1, kernel_size=7, padding=\"same\"),\r\n",
    "    ]\r\n",
    ")\r\n",
    "\r\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\r\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 19,
     "id": "81b8c3ec-0282-4d4d-bd42-87dc83b06dd9",
     "startLine": 2
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "97a26f52-9270-480a-98c4-441715f1dacf"
   },
   "outputs": [],
   "source": [
    "# LSTM for time series\r\n",
    "if time_series:\r\n",
    "    lstm_model = keras.Sequential()\r\n",
    "    lstm_model.add(keras.layers.LSTM(\r\n",
    "        units = 64,\r\n",
    "        input_shape=(X_train.shape[1], X_train.shape[2])\r\n",
    "        ))\r\n",
    "    lstm_model.add(keras.layers.Dropout(rate=0.2))\r\n",
    "    lstm_model.add(keras.layers.RepeatVector(n=X_train.shape[1]))\r\n",
    "\r\n",
    "    lstm_model.add(keras.layers.LSTM(\r\n",
    "        units = 64,\r\n",
    "        return_sequences = True\r\n",
    "        ))\r\n",
    "    lstm_model.add(keras.layers.Dropout(rate=0.2))\r\n",
    "    lstm_model.add(keras.layers.TimeDistributed(keras.layers.Dense(units = X_train.shape[2])))\r\n",
    "\r\n",
    "    lstm_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\r\n",
    "    lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "82c01553-4023-47ac-9a32-3e102dafcd3d"
   },
   "outputs": [],
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "85dbe83c-1a7b-446e-bed3-91b2d542988c"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\r\n",
    "    X_train,\r\n",
    "    X_train,\r\n",
    "    epochs=50,\r\n",
    "    batch_size=128,\r\n",
    "    validation_split=0.1,\r\n",
    "    shuffle=False, # No assumption that data is independent\r\n",
    "    callbacks=[\r\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\r\n",
    "    ],\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "c9fe1c96-712a-4d2a-a233-28124f6768b5"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\r\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "8d571233-b43d-4f40-8662-1f82607cc8b1"
   },
   "outputs": [],
   "source": [
    "if time_series:\r\n",
    "    lstm_history = lstm_model.fit(\r\n",
    "        X_train,\r\n",
    "        X_train,\r\n",
    "        epochs=50,\r\n",
    "        batch_size=128,\r\n",
    "        validation_split=0.1,\r\n",
    "        shuffle=False, # No assumption that data is independent\r\n",
    "        callbacks=[\r\n",
    "            keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\r\n",
    "        ],\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "22426d46-d045-4c5e-989e-1dde8c692c0f"
   },
   "outputs": [],
   "source": [
    "if time_series:\r\n",
    "    plt.plot(lstm_history.history[\"loss\"], label=\"Training Loss\")\r\n",
    "    plt.plot(lstm_history.history[\"val_loss\"], label=\"Validation Loss\")\r\n",
    "    plt.legend()\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 13,
     "id": "93af5872-6fc8-4da2-8179-97cb52aac109",
     "startLine": 13
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "7660bb83-6c6e-4a08-8f8f-e0a33773982d"
   },
   "outputs": [],
   "source": [
    "# Get train MAE loss.\r\n",
    "X_train_pred = model.predict(X_train)\r\n",
    "train_mae_loss = np.mean(np.abs(X_train_pred - X_train), axis=1)\r\n",
    "\r\n",
    "plt.hist(train_mae_loss, bins=50)\r\n",
    "plt.xlabel(\"Train MAE loss\")\r\n",
    "plt.ylabel(\"No of samples\")\r\n",
    "plt.legend(labels = df.columns)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# Get reconstruction loss threshold.\r\n",
    "threshold = np.amax(train_mae_loss, axis=0)\r\n",
    "print(\"Reconstruction error threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "04149914-51f7-4647-98ad-b13a5685463c"
   },
   "outputs": [],
   "source": [
    "if time_series:\r\n",
    "    # Get train MAE loss from LSTM model.\r\n",
    "    lstm_X_train_pred = lstm_model.predict(X_train)\r\n",
    "    lstm_train_mae_loss = np.mean(np.abs(lstm_X_train_pred - X_train), axis=1)\r\n",
    "\r\n",
    "    plt.hist(lstm_train_mae_loss, bins=50)\r\n",
    "    plt.xlabel(\"Train MAE loss\")\r\n",
    "    plt.ylabel(\"No of samples\")\r\n",
    "    plt.legend(labels = df.columns)\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    # Get reconstruction loss threshold.\r\n",
    "    lstm_threshold = np.amax(lstm_train_mae_loss, axis=0)\r\n",
    "    print(\"Reconstruction error threshold: \", lstm_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 5,
     "id": "93af5872-6fc8-4da2-8179-97cb52aac109",
     "startLine": 5
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "2a273394-75d9-4d0a-919f-8e1a30721461"
   },
   "outputs": [],
   "source": [
    "# Check how the first sequence is learnt\r\n",
    "plt.plot(X_train[0], label=df.columns)\r\n",
    "plt.plot(X_train_pred[0], color='r', label='learnt')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "99bd40cf-e8db-4c46-95b5-2d474f6bc7b6"
   },
   "outputs": [],
   "source": [
    "if time_series:\r\n",
    "    plt.plot(X_train[0], label=df.columns)\r\n",
    "    plt.plot(lstm_X_train_pred[0], label=['learnt ' + col for col in df.columns])\r\n",
    "    plt.legend()\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "853bb230-85f9-4639-88ba-e45a09b0220d"
   },
   "outputs": [],
   "source": [
    "## Export the data\r\n",
    "Picking the model with the lower total mae loss"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "53df597e-798f-45e3-9007-4e37b50d9a80"
   },
   "outputs": [],
   "source": [
    "if time_series:\n",
    "    if len(df.columns) > 1:\n",
    "        sum_mae_loss = sum(sum(train_mae_loss))\n",
    "        lstm_sum_mae_loss = sum(sum(lstm_train_mae_loss))\n",
    "    else:\n",
    "        sum_mae_loss = sum(train_mae_loss)\n",
    "        lstm_sum_mae_loss = sum(lstm_train_mae_loss)\n",
    "    print(sum_mae_loss)\n",
    "    print(lstm_sum_mae_loss)\n",
    "else:\n",
    "    print(sum_mae_loss)\n",
    "if time_series and lstm_sum_mae_loss < sum_mae_loss:\n",
    "    lstm_model.save('./../out/autoencoder_model')\n",
    "    dump([[scaler, TIME_STEPS, lstm_threshold], scaler.inverse_transform(df), time_series], './../out/autoencoder_model_data.joblib')\n",
    "else:\n",
    "    model.save('./../out/autoencoder_model')\n",
    "    dump([[scaler, TIME_STEPS, threshold], scaler.inverse_transform(df), time_series], './../out/autoencoder_model_data.joblib')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
