{
 "cells": [
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "19edc84f-f55e-471a-a184-1d6f7bdc14da"
   },
   "outputs": [],
   "source": [
    "# Supervised outlier detection\r\n",
    "This is a template notebook for supervised outlier detection.\r\n",
    "\r\n",
    "Author: {{ cookiecutter.author_name }}\r\n",
    "Created: {{ cookiecutter.timestamp }}"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "78a9a205-1f35-4443-b938-d562d656ff99"
   },
   "outputs": [],
   "source": [
    "## How to use the notebook\r\n",
    "\r\n",
    "The following cells:\r\n",
    "- specify objective, variables, and data types,\r\n",
    "- set up the outlier detection models,\r\n",
    "- read dataset,\r\n",
    "- present results from the models.\r\n",
    "\r\n",
    "By default, the notebook is set up to run with an example (cpu4). To see how it works, run the notebook without changing the code.\r\n",
    "\r\n",
    "For your project, adjust the code in the linked cells with your objectives, variables, dataset etc. and then execute all cells in order.\r\n",
    "\r\n",
    "Please refer to supervised.board for detailed instructions."
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "d4d12f4a-4e64-4452-895b-1fe3be6bf428"
   },
   "outputs": [],
   "source": [
    "# Link to project experiments folder hypothesis_experiment_learnings.board (refresh and hit enter on this line to see the link)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "c6871ed6-0584-4c27-b60c-7634ef923017"
   },
   "outputs": [],
   "source": [
    "# Imports and General Setup\r\n",
    "Requires imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "969a9c3f-687b-481c-86fc-d167b3a4c0d1"
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import shutil\r\n",
    "from distutils.dir_util import copy_tree\r\n",
    "\r\n",
    "import time\r\n",
    "from datetime import datetime\r\n",
    "\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib.colors import ListedColormap\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "from imblearn.over_sampling import RandomOverSampler\r\n",
    "from imblearn.over_sampling import SMOTE \r\n",
    "\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\r\n",
    "from sklearn.gaussian_process.kernels import RBF\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\r\n",
    "\r\n",
    "from sklearn.metrics import classification_report, plot_roc_curve, roc_auc_score, confusion_matrix, precision_recall_fscore_support\r\n",
    "\r\n",
    "from warnings import simplefilter\r\n",
    "from sklearn.exceptions import ConvergenceWarning\r\n",
    "simplefilter(\"ignore\", category=FutureWarning)\r\n",
    "\r\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "9d01340d-d2eb-4d5a-9527-72a233967e5a"
   },
   "outputs": [],
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "54e9c88d-0430-41ba-aa5c-90ae12c28b32",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "0dc20a60-cd4c-44ba-9f98-74743d02e4a2"
   },
   "outputs": [],
   "source": [
    "experiment_name = '{{cookiecutter.use_case_name}}'  # please provide a name for the outlier detection experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "39648fbb-b72a-458b-9a6f-71690d72c102"
   },
   "outputs": [],
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 3,
     "id": "d895b4e6-ee6e-4117-8571-c76c2c0d28d7",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "aeab425b-579f-4d9f-892c-95e9d7406c72"
   },
   "outputs": [],
   "source": [
    "time_series = True # Specify if the data is time series\n",
    "path = '{{cookiecutter.data_path}}' # Specify the path of the data\n",
    "test_size = 0.25\n",
    "\n",
    "if path == 'default example':\n",
    "    path = 'https://raw.githubusercontent.com/erium/halerium-example-data/main/outlier_detection/cpu4.csv'\n",
    "\n",
    "if time_series:\n",
    "    df = pd.read_csv(path, parse_dates=['date'], index_col = 'date')\n",
    "else:\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "num_col = len(df.columns)\n",
    "\n",
    "path = './../out'\n",
    "isExist = os.path.exists(path)\n",
    "if isExist:\n",
    "  for root, dirs, files in os.walk(path):\n",
    "      for f in files:\n",
    "          os.unlink(os.path.join(root, f))\n",
    "      for d in dirs:\n",
    "          shutil.rmtree(os.path.join(root, d))\n",
    "else:\n",
    "  os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "c770e915-c920-4aa4-8532-f652f1c31645"
   },
   "outputs": [],
   "source": [
    "## Visualising the dataset"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "e39ecd04-bc3d-4dcb-a6c4-8f40629b7518"
   },
   "outputs": [],
   "source": [
    "print('Number of outliers: ', len(df[df['outlier'] == 1]))\r\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "19ed81de-6579-49bb-a255-3d0754499a68"
   },
   "outputs": [],
   "source": [
    "pairplot_hue = 'outlier'\r\n",
    "palette ={0: \"C0\", 1: \"C3\"}\r\n",
    "sns.pairplot(df, hue = pairplot_hue, palette=palette)"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "ecf0d99e-420b-4a17-b560-ae3b5183b8f1"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns='outlier')\r\n",
    "y = df['outlier']\r\n",
    "\r\n",
    "labels = list(X.columns)\r\n",
    "num_labels = len(labels)\r\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "9f8c5b49-eb10-44b1-979a-e51c524f4a70"
   },
   "outputs": [],
   "source": [
    "Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "b6061a37-d4f9-4d6f-8c4a-711cca97dc05"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "978d9613-b09e-4654-89c7-3f2c41b3510f"
   },
   "outputs": [],
   "source": [
    "# Dealing with imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "1ddf22f9-4e8e-4019-a142-fb58c9c037e5"
   },
   "outputs": [],
   "source": [
    "data_skew = pd.Series({'Non-outlier': len(y_train.loc[y_train == 0]), 'Outlier': len(y_train.loc[y_train == 1])})\r\n",
    "print(data_skew)"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "8d20a25e-822c-47d7-9e29-f869f723e99b",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "ac87d3c8-1eed-43d0-a283-4c59a696e268"
   },
   "outputs": [],
   "source": [
    " balance_data = 'smote' # 'smote', 'oversampling', or 'none'"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "b7074694-12a8-44e8-974d-f9c7e98c744a"
   },
   "outputs": [],
   "source": [
    "if balance_data == 'oversampling':\r\n",
    "    ros = RandomOverSampler()\r\n",
    "    X_train, y_train = ros.fit_resample(X_train, y_train)\r\n",
    "elif balance_data == 'smote':\r\n",
    "    sm = SMOTE()\r\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\r\n",
    "data_skew = pd.Series({'Non-outlier': len(y_train.loc[y_train == 0]), 'Outlier': len(y_train.loc[y_train == 1])})\r\n",
    "print(data_skew)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "81420844-2f1e-4987-a683-2af8f1a8e021"
   },
   "outputs": [],
   "source": [
    "# Normalising the data"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "fbc8de14-3a72-4573-a2bd-9cd3ecc848d8"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\r\n",
    "\r\n",
    "scaler.fit(X_train)\r\n",
    "X_train = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)\r\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\r\n",
    "\r\n",
    "dump(scaler, path + '/scaler.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "f0a835f3-18ed-4ddb-9878-49f1b4dfcfa3"
   },
   "outputs": [],
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "1be9a99e-2d58-4b4c-8a75-cfb22c13838b",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "6b6779aa-c9d6-4f0b-bfeb-5cd59b041068"
   },
   "outputs": [],
   "source": [
    "run_models = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\", \"Naive Bayes\", \"QDA\"]\n",
    "run_models_data = {}\n",
    "num_models = len(run_models)\n",
    "\n",
    "models = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\", # May be quite slow\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "094c7a0a-71b8-4b1b-84ff-c078edb162b4"
   },
   "outputs": [],
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "00d858dc-0ac3-406e-96b7-5ef5404767d5"
   },
   "outputs": [],
   "source": [
    "n_neighbors = 5\r\n",
    "\r\n",
    "def run_knn():\r\n",
    "    print(\"Running K Nearest Neighbors\")\r\n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    y_pred = model.predict(X_test)\r\n",
    "    accuracy = model.score(X_test, y_test)\r\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\r\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\r\n",
    "    report = classification_report(y_test, y_pred, target_names=['Non-outlier', 'Outlier'])\r\n",
    "    plot_roc_curve(model, X_test, y_test)\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\r\n",
    "    print(pd.Series([tn, fp, fn, tp], index = ['True Negatives (Non-outliers)', 'False Positives (Non-outliers predicted as outliers)', 'False Negatives (Outliers predicted as non-outliers', 'True Positives (Outliers)']))\r\n",
    "    print(report)\r\n",
    "    return [model, [n_neighbors], [accuracy, roc_auc, precision, recall, fscore], report] # model, parameters, metrics, report\r\n",
    "\r\n",
    "if \"Nearest Neighbors\" in run_models:\r\n",
    "    run_models_data['knn'] = run_knn()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "637442d6-6a4e-4960-9d08-c9d944def168"
   },
   "outputs": [],
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "e85df5a3-2466-403e-b526-be2918a363ca"
   },
   "outputs": [],
   "source": [
    "c = 0.025\r\n",
    "\r\n",
    "def run_linear_svm():\r\n",
    "    print(\"Running Linear SVM\")\r\n",
    "    model = SVC(kernel=\"linear\", C=c)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    y_pred = model.predict(X_test)\r\n",
    "    accuracy = model.score(X_test, y_test)\r\n",
    "    roc_auc = roc_auc_score(y_test, model.predict(X_test))\r\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\r\n",
    "    report = classification_report(y_test, y_pred, target_names=['Non-outlier', 'Outlier'])\r\n",
    "    plot_roc_curve(model, X_test, y_test)\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\r\n",
    "    print(pd.Series([tn, fp, fn, tp], index = ['True Negatives (Non-outliers)', 'False Positives (Non-outliers predicted as outliers)', 'False Negatives (Outliers predicted as non-outliers', 'True Positives (Outliers)']))\r\n",
    "    print(report)\r\n",
    "    return [model, [c], [accuracy, roc_auc, precision, recall, fscore], report] # model, parameters, metrics, report\r\n",
    "\r\n",
    "if \"Linear SVM\" in run_models:\r\n",
    "    run_models_data['linear_svm'] = run_linear_svm()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "ebd5f535-6b1c-402c-8ecb-10f61297514f"
   },
   "outputs": [],
   "source": [
    "## RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "39c6b1ad-bb5b-4ef4-869e-1f0bb0aa2985"
   },
   "outputs": [],
   "source": [
    "gamma=2\r\n",
    "c = 1\r\n",
    "\r\n",
    "def run_rbf_svm():\r\n",
    "    print(\"Running RBF SVM\")\r\n",
    "    model = SVC(gamma=gamma, C=c)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    y_pred = model.predict(X_test)\r\n",
    "    accuracy = model.score(X_test, y_test)\r\n",
    "    roc_auc = roc_auc_score(y_test, model.predict(X_test))\r\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\r\n",
    "    report = classification_report(y_test, y_pred, target_names=['Non-outlier', 'Outlier'])\r\n",
    "    plot_roc_curve(model, X_test, y_test)\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\r\n",
    "    print(pd.Series([tn, fp, fn, tp], index = ['True Negatives (Non-outliers)', 'False Positives (Non-outliers predicted as outliers)', 'False Negatives (Outliers predicted as non-outliers', 'True Positives (Outliers)']))\r\n",
    "    print(report)\r\n",
    "    return [model, [gamma, c], [accuracy, roc_auc, precision, recall, fscore], report] # model, parameters, metrics, report\r\n",
    "\r\n",
    "if \"RBF SVM\" in run_models:\r\n",
    "    run_models_data['rbf_svm'] = run_rbf_svm()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "821ee817-21d9-484f-86c8-dd009d1de6d9"
   },
   "outputs": [],
   "source": [
    "## Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "86dedb45-2d7f-411b-a1f6-de6ba97941a8"
   },
   "outputs": [],
   "source": [
    "factor = 1\r\n",
    "kernel_factor = 1\r\n",
    "\r\n",
    "def run_gaussian():\r\n",
    "    print(\"Running Gaussian Process\")\r\n",
    "    model = GaussianProcessClassifier(factor * RBF(kernel_factor))\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    y_pred = model.predict(X_test)\r\n",
    "    accuracy = model.score(X_test, y_test)\r\n",
    "    roc_auc = roc_auc_score(y_test, model.predict(X_test))\r\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\r\n",
    "    report = classification_report(y_test, y_pred, target_names=['Non-outlier', 'Outlier'])\r\n",
    "    plot_roc_curve(model, X_test, y_test)\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\r\n",
    "    print(pd.Series([tn, fp, fn, tp], index = ['True Negatives (Non-outliers)', 'False Positives (Non-outliers predicted as outliers)', 'False Negatives (Outliers predicted as non-outliers', 'True Positives (Outliers)']))\r\n",
    "    print(report)\r\n",
    "    return [model, [factor, kernel_factor], [accuracy, roc_auc, precision, recall, fscore], report] # model, parameters, metrics, report\r\n",
    "\r\n",
    "if \"Gaussian Process\" in run_models:\r\n",
    "    run_models_data['gaussian'] = run_gaussian()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "ec7b8b13-b7bc-45bb-bfe7-1de9fbf56e78"
   },
   "outputs": [],
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "65fc6994-0471-4a1a-8dbe-3627deb152c1"
   },
   "outputs": [],
   "source": [
    "max_depth = 5\r\n",
    "\r\n",
    "def run_tree():\r\n",
    "    print(\"Running Decision Tree\")\r\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    y_pred = model.predict(X_test)\r\n",
    "    accuracy = model.score(X_test, y_test)\r\n",
    "    roc_auc = roc_auc_score(y_test, model.predict(X_test))\r\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\r\n",
    "    report = classification_report(y_test, y_pred, target_names=['Non-outlier', 'Outlier'])\r\n",
    "    plot_roc_curve(model, X_test, y_test)\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\r\n",
    "    print(pd.Series([tn, fp, fn, tp], index = ['True Negatives (Non-outliers)', 'False Positives (Non-outliers predicted as outliers)', 'False Negatives (Outliers predicted as non-outliers', 'True Positives (Outliers)']))\r\n",
    "    print(report)\r\n",
    "    return [model, [max_depth], [accuracy, roc_auc, precision, recall, fscore], report] # model, parameters, metrics, report\r\n",
    "\r\n",
    "if \"Decision Tree\" in run_models:\r\n",
    "    run_models_data['tree'] = run_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "1f906e9c-57b0-467d-b6de-9305acedc49e"
   },
   "outputs": [],
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "444c6ecb-8d8a-48e0-aadf-a17e72275b38"
   },
   "outputs": [],
   "source": [
    "max_depth = 5\r\n",
    "n_estimators = 10\r\n",
    "max_features = 1\r\n",
    "\r\n",
    "def run_forest():\r\n",
    "    print(\"Running Random Forests\")\r\n",
    "    model = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    y_pred = model.predict(X_test)\r\n",
    "    accuracy = model.score(X_test, y_test)\r\n",
    "    roc_auc = roc_auc_score(y_test, model.predict(X_test))\r\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\r\n",
    "    report = classification_report(y_test, y_pred, target_names=['Non-outlier', 'Outlier'])\r\n",
    "    plot_roc_curve(model, X_test, y_test)\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\r\n",
    "    print(pd.Series([tn, fp, fn, tp], index = ['True Negatives (Non-outliers)', 'False Positives (Non-outliers predicted as outliers)', 'False Negatives (Outliers predicted as non-outliers', 'True Positives (Outliers)']))\r\n",
    "    print(report)\r\n",
    "    return [model, [max_depth, n_estimators, max_features], [accuracy, roc_auc, precision, recall, fscore], report] # model, parameters, metrics, report\r\n",
    "\r\n",
    "if \"Random Forest\" in run_models:\r\n",
    "    run_models_data['forest'] = run_forest()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "de34deb4-509a-46c9-820d-35cc88c0ff97"
   },
   "outputs": [],
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "37be9afc-437e-453a-b687-b707faa97359"
   },
   "outputs": [],
   "source": [
    "alpha = 1\r\n",
    "max_iter = 1000\r\n",
    "\r\n",
    "def run_mlp():\r\n",
    "    print(\"Running Neural Net\")\r\n",
    "    model = MLPClassifier(alpha=alpha, max_iter=max_iter)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    y_pred = model.predict(X_test)\r\n",
    "    accuracy = model.score(X_test, y_test)\r\n",
    "    roc_auc = roc_auc_score(y_test, model.predict(X_test))\r\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\r\n",
    "    report = classification_report(y_test, y_pred, target_names=['Non-outlier', 'Outlier'])\r\n",
    "    plot_roc_curve(model, X_test, y_test)\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\r\n",
    "    print(pd.Series([tn, fp, fn, tp], index = ['True Negatives (Non-outliers)', 'False Positives (Non-outliers predicted as outliers)', 'False Negatives (Outliers predicted as non-outliers', 'True Positives (Outliers)']))\r\n",
    "    print(report)\r\n",
    "    return [model, [alpha, max_iter], [accuracy, roc_auc, precision, recall, fscore], report] # model, parameters, metrics, report\r\n",
    "\r\n",
    "if \"Neural Net\" in run_models:\r\n",
    "    run_models_data['mlp'] = run_mlp()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "e761fc57-e430-4ccd-87eb-44632d3a3b87"
   },
   "outputs": [],
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "6bb0b037-a63f-4822-a65c-b0f7cfd66175"
   },
   "outputs": [],
   "source": [
    "def run_adaboost():\r\n",
    "    print(\"Running AdaBoost\")\r\n",
    "    model = AdaBoostClassifier()\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    y_pred = model.predict(X_test)\r\n",
    "    accuracy = model.score(X_test, y_test)\r\n",
    "    roc_auc = roc_auc_score(y_test, model.predict(X_test))\r\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\r\n",
    "    report = classification_report(y_test, y_pred, target_names=['Non-outlier', 'Outlier'])\r\n",
    "    plot_roc_curve(model, X_test, y_test)\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\r\n",
    "    print(pd.Series([tn, fp, fn, tp], index = ['True Negatives (Non-outliers)', 'False Positives (Non-outliers predicted as outliers)', 'False Negatives (Outliers predicted as non-outliers', 'True Positives (Outliers)']))\r\n",
    "    print(report)\r\n",
    "    return [model, [], [accuracy, roc_auc, precision, recall, fscore], report] # model, parameters, metrics, report\r\n",
    "\r\n",
    "if \"AdaBoost\" in run_models:\r\n",
    "    run_models_data['adaboost'] = run_adaboost()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "66781fae-4c00-4489-aefe-06532755b786"
   },
   "outputs": [],
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "035f3b5c-06b7-49c8-84c5-afd8b070fe82"
   },
   "outputs": [],
   "source": [
    "def run_nb():\r\n",
    "    print(\"Running Naive Bayes\")\r\n",
    "    model = GaussianNB()\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    y_pred = model.predict(X_test)\r\n",
    "    accuracy = model.score(X_test, y_test)\r\n",
    "    roc_auc = roc_auc_score(y_test, model.predict(X_test))\r\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\r\n",
    "    report = classification_report(y_test, y_pred, target_names=['Non-outlier', 'Outlier'])\r\n",
    "    plot_roc_curve(model, X_test, y_test)\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\r\n",
    "    print(pd.Series([tn, fp, fn, tp], index = ['True Negatives (Non-outliers)', 'False Positives (Non-outliers predicted as outliers)', 'False Negatives (Outliers predicted as non-outliers', 'True Positives (Outliers)']))\r\n",
    "    print(report)\r\n",
    "    return [model, [], [accuracy, roc_auc, precision, recall, fscore], report] # model, parameters, metrics, report\r\n",
    "\r\n",
    "if \"Naive Bayes\" in run_models:\r\n",
    "    run_models_data['nb'] = run_nb()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "591dbced-a022-444e-8d7c-fa46a89a5bd6"
   },
   "outputs": [],
   "source": [
    "## Quadratic Discriminant Analyisis"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "190547e5-c519-47cd-868d-34c49697f582"
   },
   "outputs": [],
   "source": [
    "def run_qda():\r\n",
    "    print(\"Running Quadratic Discriminant Analysis\")\r\n",
    "    model = QuadraticDiscriminantAnalysis()\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    y_pred = model.predict(X_test)\r\n",
    "    accuracy = model.score(X_test, y_test)\r\n",
    "    roc_auc = roc_auc_score(y_test, model.predict(X_test))\r\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average='macro')\r\n",
    "    report = classification_report(y_test, y_pred, target_names=['Non-outlier', 'Outlier'])\r\n",
    "    plot_roc_curve(model, X_test, y_test)\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\r\n",
    "    print(pd.Series([tn, fp, fn, tp], index = ['True Negatives (Non-outliers)', 'False Positives (Non-outliers predicted as outliers)', 'False Negatives (Outliers predicted as non-outliers', 'True Positives (Outliers)']))\r\n",
    "    print(report)\r\n",
    "    return [model, [], [accuracy, roc_auc, precision, recall, fscore], report] # model, parameters, metrics, report\r\n",
    "\r\n",
    "if \"QDA\" in run_models:\r\n",
    "    run_models_data['qda'] = run_qda()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "d0c4a294-b7c7-4f68-8d7a-35c9f26d9ef7"
   },
   "outputs": [],
   "source": [
    "# Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 3,
     "id": "de64e033-99c1-4f0f-b609-4db97b0c2acc",
     "startLine": 3
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "ad38f676-d265-40e7-85bc-446ec5a27043"
   },
   "outputs": [],
   "source": [
    "run_models_scores = {k:v[2] for (k, v) in run_models_data.items()}\r\n",
    "run_models_scores_df = pd.DataFrame(run_models_scores, index = ['accuracy', 'roc_auc', 'precision', 'recall', 'fscore'])\r\n",
    "run_models_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 2,
     "id": "de64e033-99c1-4f0f-b609-4db97b0c2acc",
     "startLine": 2
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "a53d33e9-a5ec-4ee6-ac08-282a4849ce66"
   },
   "outputs": [],
   "source": [
    "run_models_scores_df.plot(kind='bar', figsize=(12, 10))\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "d176e234-ce65-45dd-912f-c5f429a00a87"
   },
   "outputs": [],
   "source": [
    "## Outlier Prediction"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "bbbfea56-f12f-4a95-b666-97edbfe6f939"
   },
   "outputs": [],
   "source": [
    "show_model_prediction = \"knn\" # [\"knn\", \"linear_svm\", \"rbf_svm\", \"gaussian\", \"tree\", \"forest\", \"mlp\", \"adaboost\", \"nb\", \"qda\"]\r\n",
    "\r\n",
    "show_model = run_models_data[show_model_prediction][0]\r\n",
    "y_pred = show_model.predict(X_test)\r\n",
    "pred = pd.concat([X_test, pd.DataFrame(y_pred, columns=['outlier'])], axis=1)\r\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "10b07e2f-da4e-4d1f-b123-453d40e96dbf"
   },
   "outputs": [],
   "source": [
    "## Which metric to optimise"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "b88a7399-1f09-47b4-9952-3115d18f6569"
   },
   "outputs": [],
   "source": [
    "df_best = run_models_scores_df.idxmax(axis=1)\r\n",
    "df_best"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "b592f230-cf26-4a2b-8ed6-7d75a25895bd",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "094c8955-f764-4662-b607-c7d411f3fa84"
   },
   "outputs": [],
   "source": [
    "optimise_metric = 'accuracy' # ['accuracy', 'roc_auc', 'precision', 'recall', 'fscore']\r\n",
    "best = df_best[optimise_metric]\r\n",
    "print(run_models_data[best][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "bfedc640-a34b-4f6a-9f1c-2b54eda18fcc"
   },
   "outputs": [],
   "source": [
    "Export the data"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "30bbc977-152e-4801-af97-712c6208a02d"
   },
   "outputs": [],
   "source": [
    "dump([run_models_data[best], df, time_series, scaler], './../out/supervised_model.joblib')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
