{
 "cells": [
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "9707fad6-dfcc-4d25-bbf0-714b8824ad04"
   },
   "outputs": [],
   "source": [
    "# Unsupervised outlier detection\r\n",
    "This is a template notebook for unsupervised outlier detection.\r\n",
    "\r\n",
    "Author: {{ cookiecutter.author_name }}\r\n",
    "Created: {{ cookiecutter.timestamp }}"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "7a21e058-f1dc-4a3a-980d-3bc084baf53a"
   },
   "outputs": [],
   "source": [
    "## How to use the notebook\r\n",
    "\r\n",
    "The following cells:\r\n",
    "- specify objective, variables, and data types,\r\n",
    "- set up the outlier detection models,\r\n",
    "- read dataset,\r\n",
    "- present results from the models.\r\n",
    "\r\n",
    "By default, the notebook is set up to run with an example (wine quality). To see how it works, run the notebook without changing the code.\r\n",
    "\r\n",
    "For your project, adjust the code in the linked cells with your objectives, variables, dataset etc. and then execute all cells in order.\r\n",
    "\r\n",
    "Please refer to unsupervised.board for detailed instructions."
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "6455d496-825a-40e8-b359-960fcefb0bf1"
   },
   "outputs": [],
   "source": [
    "# Link to project experiments folder hypothesis_experiment_learnings.board (refresh and hit enter on this line to see the link)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "5a322b5d-a647-4b8c-a75f-d541fd057982"
   },
   "outputs": [],
   "source": [
    "# Imports and General Setup\r\n",
    "* Requires seaborn and statsmodels installation"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "f6278bd2-472f-4f87-a7fc-90e7bc076af3"
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import shutil\r\n",
    "from distutils.dir_util import copy_tree\r\n",
    "\r\n",
    "import time\r\n",
    "from datetime import datetime\r\n",
    "\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy import stats\r\n",
    "\r\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\r\n",
    "from statsmodels.tsa.arima.model import ARIMA\r\n",
    "\r\n",
    "from sklearn.covariance import EllipticEnvelope\r\n",
    "from sklearn.svm import OneClassSVM\r\n",
    "from sklearn.linear_model import SGDOneClassSVM\r\n",
    "from sklearn.neighbors import LocalOutlierFactor\r\n",
    "from sklearn.ensemble import IsolationForest\r\n",
    "\r\n",
    "from sklearn.metrics import pairwise_distances\r\n",
    "from sklearn.metrics import silhouette_score\r\n",
    "from sklearn.metrics import calinski_harabasz_score\r\n",
    "from sklearn.metrics import davies_bouldin_score\r\n",
    "\r\n",
    "from warnings import simplefilter\r\n",
    "from sklearn.exceptions import ConvergenceWarning\r\n",
    "simplefilter(\"ignore\", category=UserWarning)\r\n",
    "\r\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "00eec885-7da6-4747-a288-788e6162ef39"
   },
   "outputs": [],
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "1d5e423b-5e6d-469a-befd-88613c1d94cf",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "75aa8e85-5e1e-45c7-882f-f02068b4e7aa"
   },
   "outputs": [],
   "source": [
    "experiment_name = '{{cookiecutter.use_case_name}}'  # please provide a name for the outlier detection experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "9973aa03-e28e-46d4-8ccd-0e3bd429f606"
   },
   "outputs": [],
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 2,
     "id": "0e9343d5-c4f5-428b-bbf8-156102aa5c90",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "fbce5419-5284-445c-b89c-72806d8d6588"
   },
   "outputs": [],
   "source": [
    "time_series = False # Specify if the data is time series\n",
    "path = '{{cookiecutter.data_path}}' # Specify the path of the data\n",
    "\n",
    "project_data_prefix = './../../../../data/' #Prefix to relative path of data folder in Halerium projects\n",
    "# Uncomment line below if you are working in Halerium project experiments and data folders\n",
    "#path = project_data_prefix + path\n",
    "\n",
    "if path == 'default example':\n",
    "    path = 'https://raw.githubusercontent.com/erium/halerium-example-data/main/outlier_detection/WineQT.csv'\n",
    "\n",
    "if time_series:\n",
    "    df = pd.read_csv(path, parse_dates=['date'], index_col = 'date')\n",
    "else:\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "out_path = './../out'\n",
    "isExist = os.path.exists(out_path)\n",
    "if isExist:\n",
    "  for root, dirs, files in os.walk(out_path):\n",
    "      for f in files:\n",
    "          os.unlink(os.path.join(root, f))\n",
    "      for d in dirs:\n",
    "          shutil.rmtree(os.path.join(root, d))\n",
    "else:\n",
    "  os.makedirs(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "8954bd1a-49a6-4b28-b0ef-706c990454c3"
   },
   "outputs": [],
   "source": [
    "## Visualising the dataset"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "4ae7398c-740f-478a-9467-8e52b56a2129"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "2d32638e-e2ec-4eb6-af2f-b40f0b7b9bbd"
   },
   "outputs": [],
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "71d11ec0-857c-4018-aad9-7f3159d630e9",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "80d07e03-16b7-4459-ac85-237f112e737f"
   },
   "outputs": [],
   "source": [
    "features_to_consider = 'all' # Specify features in list ['x', 'y'] or 'all' to identify outliers\n",
    "\n",
    "if features_to_consider != 'all':\n",
    "    df = df[features_to_consider]\n",
    "num_col = len(df.columns)\n",
    "df_uni = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "f2799f8a-8832-4cd2-b3e5-443083985d51"
   },
   "outputs": [],
   "source": [
    "n_bins = 50\r\n",
    "plt_v = 3\r\n",
    "plt_h = 5\r\n",
    "if time_series:\r\n",
    "    suptitle = 'Time Series, Frequency, and Box plots of features'\r\n",
    "    plt_row = 3\r\n",
    "    plt_v *= 3\r\n",
    "else:\r\n",
    "    suptitle = 'Frequency and Box plots of features'\r\n",
    "    plt_row = 2\r\n",
    "    plt_v *= 2\r\n",
    "\r\n",
    "\r\n",
    "if num_col == 1:\r\n",
    "    fig, axs = plt.subplots(plt_row, num_col, figsize=(plt_h*num_col, plt_v))\r\n",
    "    fig.suptitle(suptitle)\r\n",
    "    axs[0].hist(df[df.columns[0]], bins = n_bins)\r\n",
    "    axs[0].set_ylabel('Frequency')\r\n",
    "    axs[1].boxplot(df[df.columns[0]], vert=False)\r\n",
    "    axs[1].set_xlabel(df.columns[0])\r\n",
    "    if time_series:\r\n",
    "        axs[2].plot(df)\r\n",
    "        axs[2].set_xlabel('time')\r\n",
    "        axs[2].set_ylabel(df.columns[0])\r\n",
    "elif num_col > 1:\r\n",
    "    fig, axs = plt.subplots(plt_row, num_col, figsize=(plt_h*num_col, plt_v))\r\n",
    "    fig.suptitle(suptitle)\r\n",
    "    for i in range(num_col):\r\n",
    "        axs[0][i].hist(df[df.columns[i]], bins = n_bins)\r\n",
    "        axs[0][i].set_ylabel('Frequency')\r\n",
    "        axs[1][i].boxplot(df[df.columns[i]], vert=False)\r\n",
    "        axs[1][i].set_xlabel(df.columns[i])\r\n",
    "        if time_series:\r\n",
    "            axs[2][i].plot(df[df.columns[i]])\r\n",
    "            axs[2][i].set_xlabel('time')\r\n",
    "            axs[2][i].set_ylabel(df.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "30e07301-822d-4b37-ac13-c0ece4033645"
   },
   "outputs": [],
   "source": [
    "pairplot_hue = None # If you would like to pairplot a discrete variable (may be useful to visually pinpoint collective outliers)\r\n",
    "if pairplot_hue:\r\n",
    "    sns.pairplot(df, hue = pairplot_hue, palette='hls')\r\n",
    "else:\r\n",
    "    sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "ac63152d-b8e8-4bde-9e34-5f29905a486e"
   },
   "outputs": [],
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "0bc5f0ec-5288-4467-8caa-d96a5cc9ffe2",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "42c5bc56-00e7-4d54-856e-336a5d2da8a9"
   },
   "outputs": [],
   "source": [
    "run_models = ['z_score', 'iqr', 'percentile', 'elliptic', 'svm', 'sgd_svm', 'iso', 'lof'] # Select the outlier detection models to run, note certain models have restrictions on data\r\n",
    "run_models_data = {}\r\n",
    "num_models = len(run_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "81ca1a0a-a35c-4435-8e1c-db9d4273b203"
   },
   "outputs": [],
   "source": [
    "# Univariate approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "26382057-f72b-4d2f-83ac-87e2e773e5b3"
   },
   "outputs": [],
   "source": [
    "Test for normality"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "2fadab59-5375-4882-b3aa-0d5a53165b20"
   },
   "outputs": [],
   "source": [
    "alpha = 1e-3 # You may change this alpha to adjust the strictness of the normal test\r\n",
    "normal_variables = []\r\n",
    "for column in df_uni.columns:\r\n",
    "    k2, p = stats.normaltest(df[column].values)\r\n",
    "    if p < alpha:\r\n",
    "        normal_variables.append(column)\r\n",
    "\r\n",
    "print(normal_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "443d4cd1-592b-4d94-94df-58d062d398b6"
   },
   "outputs": [],
   "source": [
    "## Z-score\r\n",
    "For normally distributed data (only runs on features determined to be sufficiently normally distributed)"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "9e6dc3c9-b29e-482a-af94-93614299120e",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "e2055872-b83f-4985-b603-600662748695"
   },
   "outputs": [],
   "source": [
    "num_std = 3 # The number of standard deviations from mean to flag as outlier, 99.7% of data occurs within 3 std of mean in normal distribution\r\n",
    "\r\n",
    "def run_z_score():\r\n",
    "    print('Running Z-score')\r\n",
    "    print('Threshold std: ' + str(num_std))\r\n",
    "    outliers = []\r\n",
    "    prediction = list(range(df.shape[0]))\r\n",
    "    for variable in normal_variables:\r\n",
    "        mean = df[variable].mean()\r\n",
    "        std = df[variable].std()\r\n",
    "        upper = mean + num_std * std\r\n",
    "        lower = mean - num_std * std\r\n",
    "        outlier = list(df.index[df[variable] < lower]) + list(df.index[df[variable] > upper])\r\n",
    "        outliers += outlier\r\n",
    "    outliers = list(set(outliers))\r\n",
    "    outliers.sort()\r\n",
    "    outliers_index = []\r\n",
    "    for outlier in outliers:\r\n",
    "        outliers_index.append(df.index.get_loc(outlier))\r\n",
    "    outliers = outliers_index\r\n",
    "\r\n",
    "    for p in prediction:\r\n",
    "        if p in outliers:\r\n",
    "            prediction[p] = -1\r\n",
    "        else:\r\n",
    "            prediction[p] = 1\r\n",
    "\r\n",
    "    if prediction.count(prediction[0]) == len(prediction): # No outliers detected\r\n",
    "        sil = None\r\n",
    "        ch = None\r\n",
    "        db = None\r\n",
    "    else:\r\n",
    "        sil = silhouette_score(df, prediction, metric='euclidean')\r\n",
    "        ch = calinski_harabasz_score(df, prediction)\r\n",
    "        db = davies_bouldin_score(df, prediction)\r\n",
    "\r\n",
    "    print(str(len(outliers)) + ' outliers found')\r\n",
    "    return outliers, num_std, [sil, ch, db]\r\n",
    "\r\n",
    "if 'z_score' in run_models:\r\n",
    "    run_models_data['z_score'] = [list(run_z_score())]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "e79c8453-7c55-40e6-bc1c-c74ce87010da"
   },
   "outputs": [],
   "source": [
    "## Interquartile Range (IQR)\r\n",
    "For skewed data"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "9e6dc3c9-b29e-482a-af94-93614299120e",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "25e5919c-65c2-493d-beb1-e07837cc2b75"
   },
   "outputs": [],
   "source": [
    "num_iqr = 1.5 # The number of interquartile ranges from first and third quantile to flag as outlier, this actually corresponds to a std in normal distribution\r\n",
    "#iqr of 1.7 for std 3\r\n",
    "\r\n",
    "def run_iqr():\r\n",
    "    print('Running IQR')\r\n",
    "    print('Threshold IQR: ' + str(num_iqr))\r\n",
    "    print('Corresponds to std of: ' + str(0.675 + num_iqr * 1.35))\r\n",
    "    outliers = []\r\n",
    "    prediction = list(range(df.shape[0]))\r\n",
    "    for column in df_uni.columns:\r\n",
    "        percentile25 = df[column].quantile(0.25)\r\n",
    "        percentile75 = df[column].quantile(0.75)\r\n",
    "        iqr = percentile75 - percentile25\r\n",
    "        upper = percentile75 + num_iqr * iqr\r\n",
    "        lower = percentile25 - num_iqr * iqr\r\n",
    "        outlier = list(df.index[df[column] < lower]) + list(df.index[df[column] > upper])\r\n",
    "        outliers += outlier\r\n",
    "    outliers = list(set(outliers))\r\n",
    "    outliers.sort()\r\n",
    "    outliers_index = []\r\n",
    "    for outlier in outliers:\r\n",
    "        outliers_index.append(df.index.get_loc(outlier))\r\n",
    "    outliers = outliers_index\r\n",
    "\r\n",
    "    for p in prediction:\r\n",
    "        if p in outliers:\r\n",
    "            prediction[p] = -1\r\n",
    "        else:\r\n",
    "            prediction[p] = 1\r\n",
    "    \r\n",
    "    if prediction.count(prediction[0]) == len(prediction): # No outliers detected\r\n",
    "        sil = None\r\n",
    "        ch = None\r\n",
    "        db = None\r\n",
    "    else:\r\n",
    "        sil = silhouette_score(df, prediction, metric='euclidean')\r\n",
    "        ch = calinski_harabasz_score(df, prediction)\r\n",
    "        db = davies_bouldin_score(df, prediction)\r\n",
    "\r\n",
    "    print(str(len(outliers)) + ' outliers found')\r\n",
    "    return outliers, num_iqr, [sil, ch, db]\r\n",
    "\r\n",
    "if 'iqr' in run_models:\r\n",
    "    run_models_data['iqr'] = [list(run_iqr())]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "07b58046-153d-4ab3-b702-cc91b5991128"
   },
   "outputs": [],
   "source": [
    "## Percentile\r\n",
    "For other distributions"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "9e6dc3c9-b29e-482a-af94-93614299120e",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "43a73236-e354-4c2b-aff5-582b01e50820"
   },
   "outputs": [],
   "source": [
    "percentile = 0.99\r\n",
    "\r\n",
    "def run_percentile():\r\n",
    "    print('Running percentile')\r\n",
    "    print('Threshold percentile: ' + str(percentile))\r\n",
    "    outliers = []\r\n",
    "    prediction = list(range(df.shape[0]))\r\n",
    "    for column in df_uni.columns:\r\n",
    "        upper = df[column].quantile(percentile)\r\n",
    "        lower = df[column].quantile(1 - percentile)\r\n",
    "        outlier = list(df.index[df[column] < lower]) + list(df.index[df[column] > upper])\r\n",
    "        outliers += outlier\r\n",
    "    outliers = list(set(outliers))\r\n",
    "    outliers.sort()\r\n",
    "    outliers_index = []\r\n",
    "    for outlier in outliers:\r\n",
    "        outliers_index.append(df.index.get_loc(outlier))\r\n",
    "    outliers = outliers_index\r\n",
    "\r\n",
    "    for p in prediction:\r\n",
    "        if p in outliers:\r\n",
    "            prediction[p] = -1\r\n",
    "        else:\r\n",
    "            prediction[p] = 1\r\n",
    "\r\n",
    "    if prediction.count(prediction[0]) == len(prediction): # No outliers detected\r\n",
    "        sil = None\r\n",
    "        ch = None\r\n",
    "        db = None\r\n",
    "    else:\r\n",
    "        sil = silhouette_score(df, prediction, metric='euclidean')\r\n",
    "        ch = calinski_harabasz_score(df, prediction)\r\n",
    "        db = davies_bouldin_score(df, prediction)\r\n",
    "\r\n",
    "    print(str(len(outliers)) + ' outliers found')\r\n",
    "    return outliers, percentile, [sil, ch, db]\r\n",
    "\r\n",
    "if 'percentile' in run_models:\r\n",
    "    run_models_data['percentile'] = [list(run_percentile())]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "7eaaf358-1eb6-41e2-8b64-737ebe024ed4"
   },
   "outputs": [],
   "source": [
    "## STL\r\n",
    "For Time Series"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "9e6dc3c9-b29e-482a-af94-93614299120e",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "fbc3bd8a-0496-4929-b7cd-81ee2aaa7232"
   },
   "outputs": [],
   "source": [
    "num_std = 3 # Using std to determine residual outliers\r\n",
    "\r\n",
    "def run_stl():\r\n",
    "    print('Running STL')\r\n",
    "    print('Thresholds: ' + str(num_std))\r\n",
    "    outliers = []\r\n",
    "    prediction = list(range(df.shape[0]))\r\n",
    "    for column in df_uni.columns:\r\n",
    "        result = seasonal_decompose(df[column], model='additive') # additive or multiplicative\r\n",
    "        fig = result.plot()\r\n",
    "        resid = result.resid\r\n",
    "        resid = resid.dropna()\r\n",
    "        mean = resid.values.mean()\r\n",
    "        std = resid.values.std()\r\n",
    "        upper = mean + num_std * std\r\n",
    "        lower = mean - num_std * std\r\n",
    "        outlier = list(resid.index[resid.values < lower]) + list(resid.index[resid.values > upper])\r\n",
    "        outliers += outlier\r\n",
    "    outliers = list(set(outliers))\r\n",
    "    outliers.sort()\r\n",
    "    outliers_index = []\r\n",
    "    for outlier in outliers:\r\n",
    "        outliers_index.append(df.index.get_loc(outlier))\r\n",
    "    outliers = outliers_index\r\n",
    "\r\n",
    "    for p in prediction:\r\n",
    "        if p in outliers:\r\n",
    "            prediction[p] = -1\r\n",
    "        else:\r\n",
    "            prediction[p] = 1\r\n",
    "\r\n",
    "    if prediction.count(prediction[0]) == len(prediction): # No outliers detected\r\n",
    "        sil = None\r\n",
    "        ch = None\r\n",
    "        db = None\r\n",
    "    else:\r\n",
    "        sil = silhouette_score(df, prediction, metric='euclidean')\r\n",
    "        ch = calinski_harabasz_score(df, prediction)\r\n",
    "        db = davies_bouldin_score(df, prediction)\r\n",
    "\r\n",
    "    print(str(len(outliers)) + ' outliers found')\r\n",
    "    return outliers, num_std, [sil, ch, db]\r\n",
    "\r\n",
    "if time_series and 'stl' in run_models:\r\n",
    "    run_models_data['stl'] = [list(run_stl())]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "29dd8876-0d90-442e-86af-0b33d171af46"
   },
   "outputs": [],
   "source": [
    "## ARIMA\r\n",
    "For Time Series"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 4,
     "id": "9e6dc3c9-b29e-482a-af94-93614299120e",
     "startLine": 2
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "8ec5715a-4ef0-4b2b-9ba2-afa185223f8c"
   },
   "outputs": [],
   "source": [
    "def run_arima():\r\n",
    "    p = 1 # Lag order: number of lag observations included in the model\r\n",
    "    d = 1 # Degree of differencing: Number of times the raw observations are differenced\r\n",
    "    q = 1 # Order of moving average: Size of moving average window\r\n",
    "    print('Running ARIMA')\r\n",
    "    print('Parameters: ' + str({'p': p, 'd':d, 'q': q}))\r\n",
    "    outliers = []\r\n",
    "    prediction = list(range(df.shape[0]))\r\n",
    "    for column in df_uni.columns:\r\n",
    "        model = ARIMA(df[column], order=(p, d, q))\r\n",
    "        res = model.fit()\r\n",
    "        print(res.summary())\r\n",
    "        resid = res.resid\r\n",
    "        resid_df = pd.DataFrame(resid)\r\n",
    "        resid_df.plot()\r\n",
    "        mean = resid.values.mean()\r\n",
    "        std = resid.values.std()\r\n",
    "        upper = mean + num_std * std\r\n",
    "        lower = mean - num_std * std\r\n",
    "        outlier = list(resid.index[resid.values < lower]) + list(resid.index[resid.values > upper])\r\n",
    "        outliers += outlier\r\n",
    "    outliers = list(set(outliers))\r\n",
    "    outliers.sort()\r\n",
    "    outliers_index = []\r\n",
    "    for outlier in outliers:\r\n",
    "        outliers_index.append(df.index.get_loc(outlier))\r\n",
    "    outliers = outliers_index\r\n",
    "\r\n",
    "    for p in prediction:\r\n",
    "        if p in outliers:\r\n",
    "            prediction[p] = -1\r\n",
    "        else:\r\n",
    "            prediction[p] = 1\r\n",
    "\r\n",
    "    if prediction.count(prediction[0]) == len(prediction): # No outliers detected\r\n",
    "        sil = None\r\n",
    "        ch = None\r\n",
    "        db = None\r\n",
    "    else:\r\n",
    "        sil = silhouette_score(df, prediction, metric='euclidean')\r\n",
    "        ch = calinski_harabasz_score(df, prediction)\r\n",
    "        db = davies_bouldin_score(df, prediction)\r\n",
    "\r\n",
    "    print(str(len(outliers)) + ' outliers found')\r\n",
    "    return outliers, (p, d, q), [sil, ch, db]\r\n",
    "\r\n",
    "if time_series and 'arima' in run_models:\r\n",
    "    run_models_data['arima'] = [list(run_arima())]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "96b0a929-ca87-480e-8d6e-21497b27fccd"
   },
   "outputs": [],
   "source": [
    "## Univariate approaches results\r\n",
    "Note that a point will be classified as an outlier if ANY specified feature is identified as an outlier"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "d66ae3d9-54e7-45c3-8e6c-3dabf73ead94"
   },
   "outputs": [],
   "source": [
    "rows = 3\r\n",
    "run_models_data = {k:v[0] for (k, v) in run_models_data.items()}\r\n",
    "z_score_outliers = run_models_data['z_score'][0]\r\n",
    "iqr_outliers = run_models_data['iqr'][0]\r\n",
    "percentile_outliers = run_models_data['percentile'][0]\r\n",
    "univariate_approaches = ['z_score', 'iqr', 'percentile']\r\n",
    "univariate_outliers = [z_score_outliers, iqr_outliers, percentile_outliers]\r\n",
    "if time_series:\r\n",
    "    stl_outliers = run_models_data['stl'][0]\r\n",
    "    arima_outliers = run_models_data['arima'][0]\r\n",
    "    univariate_approaches = ['z_score', 'iqr', 'percentile'].extend(['stl', 'arima'])\r\n",
    "    univariate_outliers.extend([stl_outliers, arima_outliers])\r\n",
    "    rows = 5\r\n",
    "\r\n",
    "print('features labeled: ' + str(features_to_consider))\r\n",
    "print('z_score outliers: ' + str(len(z_score_outliers)))\r\n",
    "print('z_score threshold: ' + str(run_models_data['z_score'][1]))\r\n",
    "print('iqr outliers: ' + str(len(iqr_outliers)))\r\n",
    "print('iqr threshold: ' + str(run_models_data['iqr'][1]))\r\n",
    "print('percentile outliers: ' + str(len(percentile_outliers)))\r\n",
    "print('percentile threshold: ' + str(run_models_data['percentile'][1]))\r\n",
    "if time_series:\r\n",
    "    print('stl outliers: ' + str(len(stl_outliers)))\r\n",
    "    print('stl threshold: ' + str(run_models_data['stl'][1]))\r\n",
    "    print('stl outliers: ' + str(len(arima_outliers)))\r\n",
    "    print('stl threshold: ' + str(run_models_data['arima'][1]))\r\n",
    "\r\n",
    "if num_col == 1:\r\n",
    "    fig, axs = plt.subplots(rows, num_col, figsize=(plt_h*num_col, plt_v))\r\n",
    "    fig.suptitle(\"Univariate approaches results\")\r\n",
    "    axs[0].hist(df.iloc[z_score_outliers][df.columns[0]], color='r', bins = n_bins, zorder=2, label='outlier')\r\n",
    "    axs[0].hist(df[df.columns[0]], bins = n_bins, zorder=1)\r\n",
    "    axs[0].set_ylabel('Frequency')\r\n",
    "    axs[0].set_title('z-score outliers')\r\n",
    "    axs[1].hist(df.iloc[iqr_outliers][df.columns[0]], color='r', bins = n_bins, zorder=2)\r\n",
    "    axs[1].hist(df[df.columns[0]], bins = n_bins, zorder=1)\r\n",
    "    axs[1].set_ylabel('Frequency')\r\n",
    "    axs[1].set_title('iqr outliers')\r\n",
    "    axs[2].hist(df.iloc[percentile_outliers][df.columns[0]], color='r', bins = n_bins, zorder=2)\r\n",
    "    axs[2].hist(df[df.columns[0]], bins = n_bins, zorder=1)\r\n",
    "    axs[2].set_ylabel('Frequency')\r\n",
    "    axs[2].set_xlabel(df.columns[0])\r\n",
    "    axs[2].set_title('percentile outliers')\r\n",
    "    if time_series:\r\n",
    "        axs[3].hist(df.iloc[stl_outliers][df.columns[0]], color='r', bins = n_bins, zorder=2)\r\n",
    "        axs[3].hist(df[df.columns[0]], bins = n_bins, zorder=1)\r\n",
    "        axs[3].set_ylabel('Frequency')\r\n",
    "        axs[3].set_xlabel(df.columns[0])\r\n",
    "        axs[3].set_title('stl outliers')\r\n",
    "        axs[4].hist(df.iloc[arima_outliers][df.columns[0]], color='r', bins = n_bins, zorder=2)\r\n",
    "        axs[4].hist(df[df.columns[0]], bins = n_bins, zorder=1)\r\n",
    "        axs[4].set_ylabel('Frequency')\r\n",
    "        axs[4].set_xlabel(df.columns[0])\r\n",
    "        axs[4].set_title('arima outliers')\r\n",
    "elif num_col > 1:\r\n",
    "    fig, axs = plt.subplots(rows, num_col, figsize=(plt_h*num_col, 2 * plt_v))\r\n",
    "    fig.suptitle(\"Univariate approaches results\")\r\n",
    "    for i in range(num_col):\r\n",
    "        axs[0][i].hist(df.iloc[z_score_outliers][df.columns[i]], color='r', bins = n_bins, zorder=2, label='outlier')\r\n",
    "        axs[0][i].hist(df[df.columns[i]], bins = n_bins, zorder=1)\r\n",
    "        axs[0][i].set_ylabel('Frequency')\r\n",
    "        axs[0][i].set_title('z-score outliers')\r\n",
    "        axs[1][i].hist(df.iloc[iqr_outliers][df.columns[i]], color='r', bins = n_bins, zorder=2)\r\n",
    "        axs[1][i].hist(df[df.columns[i]], bins = n_bins, zorder=1)\r\n",
    "        axs[1][i].set_ylabel('Frequency')\r\n",
    "        axs[1][i].set_title('iqr outliers')\r\n",
    "        axs[2][i].hist(df.iloc[percentile_outliers][df.columns[i]], color='r', bins = n_bins, zorder=2)\r\n",
    "        axs[2][i].hist(df[df.columns[i]], bins = n_bins, zorder=1)\r\n",
    "        axs[2][i].set_ylabel('Frequency')\r\n",
    "        axs[2][i].set_xlabel(df.columns[i])\r\n",
    "        axs[2][i].set_title('percentile outliers')\r\n",
    "        if time_series:\r\n",
    "            axs[3][i].hist(df.iloc[stl_outliers][df.columns[i]], color='r', bins = n_bins, zorder=2)\r\n",
    "            axs[3][i].hist(df[df.columns[0]], bins = n_bins, zorder=1)\r\n",
    "            axs[3][i].set_ylabel('Frequency')\r\n",
    "            axs[3][i].set_xlabel(df.columns[0])\r\n",
    "            axs[3][i].set_title('stl outliers')\r\n",
    "            axs[4][i].hist(df.iloc[arima_outliers][df.columns[i]], color='r', bins = n_bins, zorder=2)\r\n",
    "            axs[4][i].hist(df[df.columns[0]], bins = n_bins, zorder=1)\r\n",
    "            axs[4][i].set_ylabel('Frequency')\r\n",
    "            axs[4][i].set_xlabel(df.columns[0])\r\n",
    "            axs[4][i].set_title('arima outliers')\r\n",
    "        handles, labels = axs[0][i].get_legend_handles_labels()\r\n",
    "    fig.legend(handles, labels)"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "8a524a62-16e8-422d-9551-8419454fce86"
   },
   "outputs": [],
   "source": [
    "uni_approach_visual = 'z_score' # 'z_score', 'iqr', 'percentile', 'stl', or 'arima'\r\n",
    "if uni_approach_visual == 'z_score':\r\n",
    "    out = z_score_outliers\r\n",
    "elif uni_approach_visual == 'iqr':\r\n",
    "    out = iqr_outliers\r\n",
    "elif uni_approach_visual == 'percentile':\r\n",
    "    out = percentile_outliers\r\n",
    "elif uni_approach_visual == 'stl':\r\n",
    "    out = stl_outliers\r\n",
    "elif uni_approach_visual == 'arima':\r\n",
    "    out = arima_outliers\r\n",
    "\r\n",
    "print(uni_approach_visual + ' approach')\r\n",
    "df_uni_outlier = df.copy()\r\n",
    "df_uni_outlier['outlier'] = 'Non Outlier'\r\n",
    "df_uni_outlier.loc[df.index[out], 'outlier'] = 'Outlier'\r\n",
    "palette ={\"Non Outlier\": \"C0\", \"Outlier\": \"C3\"}\r\n",
    "sns.pairplot(df_uni_outlier, hue = 'outlier', palette=palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "b2db55fb-2c17-480a-97d4-2bbc6201475c"
   },
   "outputs": [],
   "source": [
    "# Multivariate approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "d003cd04-aa15-4203-b092-44cf94b043f0"
   },
   "outputs": [],
   "source": [
    "## Elliptic Envelope Covariance"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "9e6dc3c9-b29e-482a-af94-93614299120e",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "8b9df6ca-9fa5-4b30-b7eb-641d6d368f32"
   },
   "outputs": [],
   "source": [
    "contamination = 0.1 # Proportion of outliers in the dataset (range from (0,0.5]), 0.1 default\r\n",
    "\r\n",
    "def run_elliptic():\r\n",
    "    print('Running Elliptic Envelope Covariance')\r\n",
    "    outliers = []\r\n",
    "    cov = EllipticEnvelope(contamination=contamination).fit(df)\r\n",
    "    prediction = cov.predict(df)\r\n",
    "\r\n",
    "    if list(prediction).count(prediction[0]) == len(prediction): # No outliers detected\r\n",
    "        sil = None\r\n",
    "        ch = None\r\n",
    "        db = None\r\n",
    "    else:\r\n",
    "        sil = silhouette_score(df, prediction, metric='euclidean')\r\n",
    "        ch = calinski_harabasz_score(df, prediction)\r\n",
    "        db = davies_bouldin_score(df, prediction)\r\n",
    "\r\n",
    "    for i in range(len(prediction)):\r\n",
    "        if prediction[i] == -1:\r\n",
    "            outliers.append(i)\r\n",
    "    print(str(len(outliers)) + ' outliers found')\r\n",
    "    return outliers, cov, [sil, ch, db]\r\n",
    "\r\n",
    "if 'elliptic' in run_models:\r\n",
    "    run_models_data['elliptic'] = list(run_elliptic()) + [contamination]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "6946243b-3997-44af-83d3-0ac21ffb79f8"
   },
   "outputs": [],
   "source": [
    "## One Class SVM\r\n",
    "Using Gaussian kernel by default"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "9e6dc3c9-b29e-482a-af94-93614299120e",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "c65b4f56-d4ac-4ee1-9b84-c183cb4a3e73"
   },
   "outputs": [],
   "source": [
    "nu = 0.1 # Proportion of outliers in the dataset (range from (0,1]), 0.5 default\r\n",
    "\r\n",
    "def run_oc_svm():\r\n",
    "    print('Running One Class SVM')\r\n",
    "    outliers = []\r\n",
    "    clf = OneClassSVM(nu = nu).fit(df)\r\n",
    "    prediction = clf.predict(df)\r\n",
    "\r\n",
    "    if list(prediction).count(prediction[0]) == len(prediction): # No outliers detected\r\n",
    "        sil = None\r\n",
    "        ch = None\r\n",
    "        db = None\r\n",
    "    else:\r\n",
    "        sil = silhouette_score(df, prediction, metric='euclidean')\r\n",
    "        ch = calinski_harabasz_score(df, prediction)\r\n",
    "        db = davies_bouldin_score(df, prediction)\r\n",
    "\r\n",
    "    for i in range(len(prediction)):\r\n",
    "        if prediction[i] == -1:\r\n",
    "            outliers.append(i)\r\n",
    "    print(str(len(outliers)) + ' outliers found')\r\n",
    "    return outliers, clf, [sil, ch, db]\r\n",
    "\r\n",
    "if 'svm' in run_models:\r\n",
    "    run_models_data['svm'] = list(run_oc_svm()) + [nu]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "ce5360b1-a374-4115-b79b-921cd1162a69"
   },
   "outputs": [],
   "source": [
    "## One Class SVM with Stochastic Gradient Descent\r\n",
    "With kernel approximation"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "9e6dc3c9-b29e-482a-af94-93614299120e",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "54dbe50d-10c1-4d5e-a151-7c52d20e4592"
   },
   "outputs": [],
   "source": [
    "nu = 0.1 # Upper bound on the fraction of training errors and lower bound of the fraction of support vectors (range from (0,1]), 0.5 default\r\n",
    "\r\n",
    "def run_oc_sgd_svm():\r\n",
    "    print('Running One Class SVM with SGD')\r\n",
    "    outliers = []\r\n",
    "    clf = SGDOneClassSVM(nu = nu).fit(df)\r\n",
    "    prediction = clf.predict(df)\r\n",
    "    if list(prediction).count(prediction[0]) == len(prediction): # No outliers detected\r\n",
    "        sil = None\r\n",
    "        ch = None\r\n",
    "        db = None\r\n",
    "    else:\r\n",
    "        sil = silhouette_score(df, prediction, metric='euclidean')\r\n",
    "        ch = calinski_harabasz_score(df, prediction)\r\n",
    "        db = davies_bouldin_score(df, prediction)\r\n",
    "\r\n",
    "    for i in range(len(prediction)):\r\n",
    "        if prediction[i] == -1:\r\n",
    "            outliers.append(i)\r\n",
    "    print(str(len(outliers)) + ' outliers found')\r\n",
    "    return outliers, clf, [sil, ch, db]\r\n",
    "\r\n",
    "if 'sgd_svm' in run_models:\r\n",
    "    run_models_data['sgd_svm'] = list(run_oc_sgd_svm()) + [nu]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "8edf53c8-8975-4f02-93c1-6096319858ef"
   },
   "outputs": [],
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 2,
     "id": "9e6dc3c9-b29e-482a-af94-93614299120e",
     "startLine": 2
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "f92fb7f7-c0d4-444f-b757-f69a1903003c"
   },
   "outputs": [],
   "source": [
    "n_estimators = 100 # Number of base estimators in the ensemble\r\n",
    "contamination = 0.1 # The proportion of outliers in the dataset (range from (0,0.5]), 0.1 default\r\n",
    "\r\n",
    "def run_iso():\r\n",
    "    print('Running Isolation Forest')\r\n",
    "    outliers = []\r\n",
    "    clf = IsolationForest(n_estimators=n_estimators, contamination=contamination).fit(df)\r\n",
    "    prediction = clf.predict(df)\r\n",
    "\r\n",
    "    if list(prediction).count(prediction[0]) == len(prediction): # No outliers detected\r\n",
    "        sil = None\r\n",
    "        ch = None\r\n",
    "        db = None\r\n",
    "    else:\r\n",
    "        sil = silhouette_score(df, prediction, metric='euclidean')\r\n",
    "        ch = calinski_harabasz_score(df, prediction)\r\n",
    "        db = davies_bouldin_score(df, prediction)\r\n",
    "\r\n",
    "    for i in range(len(prediction)):\r\n",
    "        if prediction[i] == -1:\r\n",
    "            outliers.append(i)\r\n",
    "    print(str(len(outliers)) + ' outliers found')\r\n",
    "    return outliers, clf, [sil, ch, db]\r\n",
    "\r\n",
    "if 'iso' in run_models:\r\n",
    "    run_models_data['iso'] = list(run_iso()) + [n_estimators, contamination]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "14a30924-f608-4b3d-86c8-53abbb664b61"
   },
   "outputs": [],
   "source": [
    "## Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 3,
     "id": "9e6dc3c9-b29e-482a-af94-93614299120e",
     "startLine": 3
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "6e94b158-2ad4-4a7d-8595-5b9f1fa82cee"
   },
   "outputs": [],
   "source": [
    "n_neighbors = 20 # Number of neighbors for kneighbors queries. 20 default\r\n",
    "leaf_size = 30 # Affects the speed of construction and query. 30 default\r\n",
    "contamination = 0.1 # The proportion of outliers in the dataset (range from (0,0.5]), 0.1 default\r\n",
    "\r\n",
    "def run_lof():\r\n",
    "    print('Running Local Outlier Factor')\r\n",
    "    outliers = []\r\n",
    "    clf = LocalOutlierFactor(n_neighbors=n_neighbors, leaf_size=leaf_size, contamination=contamination)\r\n",
    "    clf_predict = LocalOutlierFactor(n_neighbors=n_neighbors, leaf_size=leaf_size, contamination=contamination, novelty=True)\r\n",
    "    prediction = clf.fit_predict(df)\r\n",
    "    clf_predict.fit(df)\r\n",
    "\r\n",
    "    if list(prediction).count(prediction[0]) == len(prediction): # No outliers detected\r\n",
    "        sil = None\r\n",
    "        ch = None\r\n",
    "        db = None\r\n",
    "    else:\r\n",
    "        sil = silhouette_score(df, prediction, metric='euclidean')\r\n",
    "        ch = calinski_harabasz_score(df, prediction)\r\n",
    "        db = davies_bouldin_score(df, prediction)\r\n",
    "\r\n",
    "    for i in range(len(prediction)):\r\n",
    "        if prediction[i] == -1:\r\n",
    "            outliers.append(i)\r\n",
    "    print(str(len(outliers)) + ' outliers found')\r\n",
    "    return outliers, prediction, [sil, ch, db], clf_predict\r\n",
    "\r\n",
    "if 'lof' in run_models:\r\n",
    "    run_models_data['lof'] = list(run_lof()) + [n_neighbors, leaf_size, contamination]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "8a31e978-317f-4274-a1d7-c3e399e7ffc9"
   },
   "outputs": [],
   "source": [
    "# Multivariate approaches result"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "3927214c-422c-44c5-9ffc-1575e2646d12"
   },
   "outputs": [],
   "source": [
    "print('models used: ' + str(run_models))\r\n",
    "for model in run_models:\r\n",
    "    print(model + ' outliers: ' + str(len(run_models_data[model][0])))\r\n",
    "\r\n",
    "if num_col == 1:\r\n",
    "    fig, axs = plt.subplots(num_models, num_col, figsize=(plt_h*num_col, 2 * plt_v * num_models))\r\n",
    "    fig.suptitle(\"Multivariate approaches results\")\r\n",
    "    for i, model in enumerate(run_models):\r\n",
    "        model_outliers = run_models_data[model][0]\r\n",
    "        axs[i].hist(df.iloc[model_outliers][df.columns[0]], color='r', bins = n_bins, zorder=2, label='outlier')\r\n",
    "        axs[i].hist(df[df.columns[0]], bins = n_bins, zorder=1)\r\n",
    "        axs[i].set_ylabel('Frequency')\r\n",
    "        axs[i].set_title(model + ' outliers')\r\n",
    "        axs[i].set_xlabel(df.columns[0])\r\n",
    "elif num_col > 1:\r\n",
    "    fig, axs = plt.subplots(num_models, num_col, figsize=(plt_h*num_col, plt_v * num_models))\r\n",
    "    fig.suptitle(\"Multivariate approaches results\")\r\n",
    "    for i, model in enumerate(run_models):\r\n",
    "        model_outliers = run_models_data[model][0]\r\n",
    "        for j in range(num_col):\r\n",
    "            axs[i][j].hist(df.iloc[model_outliers][df.columns[j]], color='r', bins = n_bins, zorder=2, label='outlier')\r\n",
    "            axs[i][j].hist(df[df.columns[j]], bins = n_bins, zorder=1)\r\n",
    "            axs[i][j].set_ylabel('Frequency')\r\n",
    "            axs[i][j].set_title(model + ' outliers')\r\n",
    "            axs[i][j].set_xlabel(df.columns[j])\r\n",
    "        handles, labels = axs[0][0].get_legend_handles_labels()\r\n",
    "    fig.legend(handles, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "f4e7802b-56e0-46a3-9bba-56a761b7fdcb"
   },
   "outputs": [],
   "source": [
    "## Outlier prediction"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "0b6522de-5048-47e8-9dfe-cf3cf9b85fc4"
   },
   "outputs": [],
   "source": [
    "show_model = 'elliptic' # ['z_score', 'iqr', 'percentile', 'elliptic', 'svm', 'sgd_svm', 'iso', 'lof']\r\n",
    "\r\n",
    "df_show = df.copy()\r\n",
    "df_show['outlier'] = 0\r\n",
    "outliers_show = run_models_data[show_model][0]\r\n",
    "df_show.loc[df_show.index[outliers_show], 'outlier'] = 1\r\n",
    "df_show"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "75f27bcd-83bc-4bdc-a252-f9bc165c99a6"
   },
   "outputs": [],
   "source": [
    "## Decision Boundary Visualisation\r\n",
    "Only available for data with 2 features"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "978e26a6-f08a-4474-8ce2-8dd214b70025"
   },
   "outputs": [],
   "source": [
    "if num_col == 2:\r\n",
    "    multi_models = [model for model in run_models if model not in ['z_score', 'iqr', 'percentile', 'stl', 'arima']]\r\n",
    "    num_multi_models = len(multi_models)\r\n",
    "\r\n",
    "    xx_min = min(df[df.columns[0]])\r\n",
    "    xx_max = max(df[df.columns[0]])\r\n",
    "    xx_range = xx_max - xx_min\r\n",
    "    yy_min = min(df[df.columns[1]])\r\n",
    "    yy_max = max(df[df.columns[1]])\r\n",
    "    yy_range = yy_max - yy_min\r\n",
    "    xx, yy = np.meshgrid(np.linspace(xx_min - (yy_range), xx_max + (yy_range), 200), np.linspace(yy_min - (yy_range//2 + 1), yy_max + (yy_range//2 + 1), 200))\r\n",
    "        \r\n",
    "    fig, axs = plt.subplots(1, num_multi_models, figsize=(plt_h*num_multi_models, plt_v), sharex=True, sharey=True)\r\n",
    "    fig.suptitle('Outlier Decision Boundaries')\r\n",
    "    for i, model in enumerate(multi_models):\r\n",
    "        if model != 'lof':\r\n",
    "            Z = run_models_data[model][1].predict(np.c_[xx.ravel(), yy.ravel()])\r\n",
    "            Z = Z.reshape(xx.shape)\r\n",
    "            axs[i].contour(xx, yy, Z, levels=[0], linewidths=2, colors=\"red\")\r\n",
    "            y_pred = run_models_data[model][1].predict(df)\r\n",
    "        else:\r\n",
    "            Z = run_models_data[model][3].decision_function(np.c_[xx.ravel(), yy.ravel()])\r\n",
    "            Z = Z.reshape(xx.shape)\r\n",
    "            axs[i].contour(xx, yy, Z, levels=[0], linewidths=2, colors=\"red\")\r\n",
    "            y_pred = run_models_data[model][1]\r\n",
    "        colors = np.array([\"#377eb8\", \"#ff7f00\"])\r\n",
    "        axs[i].scatter(df[df.columns[0]], df[df.columns[1]], s=10, color=colors[(y_pred + 1) // 2])\r\n",
    "        axs[i].set_xlabel(df.columns[0])\r\n",
    "        axs[i].set_ylabel(df.columns[1])\r\n",
    "        axs[i].set_title(model + ' outliers')"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "ee182389-9c46-4f0a-8090-13ca54334cab"
   },
   "outputs": [],
   "source": [
    "multi_approach_visual = 'elliptic' # 'elliptic', 'svm', 'sgd_svm', 'iso', or 'lof'\r\n",
    "if multi_approach_visual == 'elliptic':\r\n",
    "    out = run_models_data['elliptic'][0]\r\n",
    "elif multi_approach_visual == 'svm':\r\n",
    "    out = run_models_data['svm'][0]\r\n",
    "elif multi_approach_visual == 'sgd_svm':\r\n",
    "    out = run_models_data['sgd_svm'][0]\r\n",
    "elif multi_approach_visual == 'iso':\r\n",
    "    out = run_models_data['iso'][0]\r\n",
    "elif multi_approach_visual == 'lof':\r\n",
    "    out = run_models_data['lof'][0]\r\n",
    "\r\n",
    "print(multi_approach_visual + ' approach')\r\n",
    "df_multi_outlier = df.copy()\r\n",
    "df_multi_outlier['outlier'] = 'Non Outlier'\r\n",
    "df_multi_outlier.loc[df.index[out], 'outlier'] = 'Outlier'\r\n",
    "palette ={\"Non Outlier\": \"C0\", \"Outlier\": \"C3\"}\r\n",
    "sns.pairplot(df_multi_outlier, hue = 'outlier', palette=palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "656f9365-d39a-4ec0-bfb2-44bdf0b80838"
   },
   "outputs": [],
   "source": [
    "## Evaluation Metrics\r\n",
    "### Clustering approaches\r\n",
    "Silhouette Coefficient: Higher means better defined clusters. \r\n",
    "Calinski-Harabasz Index: Higher means better defined clusters.\r\n",
    "Davies-Bouldin Index: Lower means better separation between clusters.\r\n",
    "\r\n",
    "Note that clustering outlier detection evaluation may not reflect your use case. Eg if abnormal data is hidden in the clusters. "
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 3,
     "id": "4fdde096-5ef5-4884-ac9c-132796937e91",
     "startLine": 3
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "571eb09f-8ff4-4b80-b05b-402a330b8d82"
   },
   "outputs": [],
   "source": [
    "multi_model_scores = {k:v[2] for (k, v) in run_models_data.items() if k not in ['z_score, iqr, percentile']}\r\n",
    "multi_model_scores_df = pd.DataFrame(multi_model_scores, index = ['silhouette', 'calinski-harabasz', 'davies-bouldin'])\r\n",
    "multi_model_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 10,
     "id": "4fdde096-5ef5-4884-ac9c-132796937e91",
     "startLine": 10
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "98ef83db-ab1c-4e35-9712-dbeb1c318b77"
   },
   "outputs": [],
   "source": [
    "multi_model_scores = {k:v for (k, v) in multi_model_scores.items() if None not in v}\r\n",
    "fig, axs = plt.subplots(1, 3, figsize=(plt_h*5, plt_v))\r\n",
    "fig.suptitle('Unsupervised Clustering Metrics')\r\n",
    "axs[0].bar([k for (k, v) in multi_model_scores.items()], [v[0] for (k, v) in multi_model_scores.items()])\r\n",
    "axs[0].set_title('Silhouette - Higher: Better Defined Clusters')\r\n",
    "axs[1].bar([k for (k, v) in multi_model_scores.items()], [v[1] for (k, v) in multi_model_scores.items()])\r\n",
    "axs[1].set_title('Calinski-Harabasz - Higher: Better Defined Clusters')\r\n",
    "axs[2].bar([k for (k, v) in multi_model_scores.items()], [v[2] for (k, v) in multi_model_scores.items()])\r\n",
    "axs[2].set_title('Davies-Bouldin - Lower: Better Separated Clusters')\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "fb52d2c9-4d1d-4211-af68-9b74aaaaea36"
   },
   "outputs": [],
   "source": [
    "def export_outlier(df, model, export_path):\r\n",
    "    df['outlier'] = 0\r\n",
    "    outliers = run_models_data[model][0]\r\n",
    "    df.loc[df.index[outliers], 'outlier'] = 1\r\n",
    "    df.to_csv(export_path)\r\n",
    "\r\n",
    "\r\n",
    "export_outlier(df, 'z_score', './../out/labeled_data')"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "a9b120c8-6964-4ec9-91cc-4707c5116c63"
   },
   "outputs": [],
   "source": [
    "# Exports the data\r\n",
    "dump([run_models_data, df, time_series], './../out/unsupervised_model_data.joblib')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
