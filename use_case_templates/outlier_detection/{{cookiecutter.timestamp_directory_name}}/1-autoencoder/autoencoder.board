{
  "nodes": [
    {
      "id": "e06cb8d7-2163-4526-acca-939e1fb33482",
      "title": "0. HOW TO USE THE BOARD",
      "type_specific": {
        "message": "{\"ops\":[{\"insert\":\"Go through through the yellow cards in order. Follow the instructions on each of these cards. These will instruct you to adjust and/or run code in the associated notebook, fill in information on the corresponding green card, and provide more information regarding the process at each step.\\n\"}]}"
      },
      "edge_connections": [
        {
          "id": "3a710e71-3ba4-440e-b51e-da8df811e84c",
          "connector": "right"
        }
      ],
      "type": "note",
      "position": {
        "x": 49.1875,
        "y": 167
      },
      "size": {
        "width": 215,
        "height": 259
      },
      "color": "#51455b"
    },
    {
      "id": "d3f724fa-f5a8-4854-acaa-7c16f3e29225",
      "title": "1. DESCRIBE THE PROJECT",
      "type_specific": {
        "message": "{\"ops\":[{\"insert\":\"It is useful to provide an overview of the use case, objective and general procedure of this autoencoder outlier detection project. This would provide a documented summary for the entire project.\\n\\nIn the card \\\"Project\\\",\\ndescribe the use case,\"},{\"attributes\":{\"list\":\"bullet\"},\"insert\":\"\\n\"},{\"insert\":\"describe the objective of the outlier detection,\"},{\"attributes\":{\"list\":\"bullet\"},\"insert\":\"\\n\"},{\"insert\":\"describe the general procedure of the project.\"},{\"attributes\":{\"list\":\"bullet\"},\"insert\":\"\\n\"},{\"insert\":\"\\n\"}]}"
      },
      "edge_connections": [
        {
          "id": "3a710e71-3ba4-440e-b51e-da8df811e84c",
          "connector": "left"
        },
        {
          "id": "a95c7bd7-c98c-4fc9-8828-6656222c8590",
          "connector": "right"
        },
        {
          "id": "b30c61ab-fa2f-49e0-a78f-b173d136f7e7",
          "connector": "bottom"
        }
      ],
      "type": "note",
      "position": {
        "x": 365.9375,
        "y": 163.5
      },
      "size": {
        "width": 235,
        "height": 262
      },
      "color": "#51455b"
    },
    {
      "id": "4f2e9c89-3562-4d59-8883-28bd4be9eea7",
      "title": "2. Import the dataset",
      "type_specific": {
        "message": "{\"ops\":[{\"insert\":\"We would need to import our dataset for training the models. It is important to understand the size, properties, and features of our dataset such that we can decide on if and how much preprocessing and feature engineering/selection would be needed.\\n\\nNote that autoencoders need to be trained on a 'clean' dataset consisting of only non-outlier data points.\\n\\nIt is not required to divide the data set into sets for training and testing as unsupervised outlier detection algorithms would process and detect outliers in the existing data. Performance of models improve with more data if existing dataset is small.\\n\\nIn the card \\\"Dataset\\\",\\ndescribe the dataset,\"},{\"attributes\":{\"list\":\"bullet\"},\"insert\":\"\\n\"},{\"insert\":\"\\n\"}]}"
      },
      "edge_connections": [
        {
          "id": "a95c7bd7-c98c-4fc9-8828-6656222c8590",
          "connector": "left"
        },
        {
          "id": "221fcfaa-1e76-4447-8f65-07b96dbbc89f",
          "connector": "right"
        },
        {
          "id": "cc797318-e943-4173-9678-08bb3e2f5146",
          "connector": "bottom"
        }
      ],
      "type": "note",
      "position": {
        "x": 706.4375,
        "y": 162.5
      },
      "size": {
        "width": 245,
        "height": 264
      },
      "color": "#51455b"
    },
    {
      "id": "762e39b3-1d0e-4f0e-b724-350c095d200d",
      "title": "3. RUN THE MODELS",
      "type_specific": {
        "message": "{\"ops\":[{\"insert\":\"With the set up complete, you may now run the notebook. You can choose specific models to run (refer to outlier_detection.board for a description of the models) or run all the models available.\\n\\nYou may also adjust the parameters for the models in the corresponding cell to adjust thresholds and the autoencoder architecture.\\n\\nThe notebook will run a sequential convolutional neural network as well as a LSTM autoencoder for time-series data.\\n\\nIn the card \\\"Models\\\",\\nspecify the model parameters and architecture\"},{\"attributes\":{\"list\":\"bullet\"},\"insert\":\"\\n\"},{\"insert\":\"\\n\"}]}"
      },
      "edge_connections": [
        {
          "id": "221fcfaa-1e76-4447-8f65-07b96dbbc89f",
          "connector": "left"
        },
        {
          "id": "aab255c5-026b-47d9-8389-60d5024eb453",
          "connector": "right"
        },
        {
          "id": "bf8e80b8-47aa-4a32-b02f-d4f399287f82",
          "connector": "bottom"
        }
      ],
      "type": "note",
      "position": {
        "x": 1043.0625,
        "y": 160.6875
      },
      "size": {
        "width": 251,
        "height": 267
      },
      "color": "#51455b"
    },
    {
      "id": "9b703f26-e334-401b-b6fb-280ada141058",
      "title": "4. GET THE RESULTS",
      "type_specific": {
        "message": "{\"ops\":[{\"insert\":\"After the notebook has completed running, you can view the final results of all the models.\\n\\nNote that the model with the least total MAE will be selected and exported\\n\\nIn the card \\\"Final Results\\\",\\nreport the best parameters and results reported by the outlier detection models.\"},{\"attributes\":{\"list\":\"bullet\"},\"insert\":\"\\n\"},{\"insert\":\"\\n\"}]}"
      },
      "edge_connections": [
        {
          "id": "aab255c5-026b-47d9-8389-60d5024eb453",
          "connector": "left"
        },
        {
          "id": "f632590a-14fc-4b50-8adb-9b6454ce8d95",
          "connector": "right"
        },
        {
          "id": "76696f53-b255-47b3-bf85-e630aa705c7e",
          "connector": "bottom"
        }
      ],
      "type": "note",
      "position": {
        "x": 1397.4375,
        "y": 163.125
      },
      "size": {
        "width": 247,
        "height": 263
      },
      "color": "#51455b"
    },
    {
      "id": "ff9d0c41-8923-4419-956f-3aed5b4186ff",
      "title": "5. Interpret the Results",
      "type_specific": {
        "message": "{\"ops\":[{\"insert\":\"Unlike with supervised metrics, there is no ground truth for a confusion matrix to be constructed. \\n\\nThe notebook will report the mean absolute error (MAE) of the reconstructed data, and set the highest error as the threshold. When new data is passed through the autoencoder, any reconstruction with a larger MAE than this threshold would be considered an outlier.\\n\\nOften, we would require external validation of the identified outliers to determine if the models can predict the outliers accurately.\\n\\nIn the card \\\"Interpret and Improve\\\",\\nreport and compare the model training and validation loss to a benchmark (if available)\"},{\"attributes\":{\"list\":\"bullet\"},\"insert\":\"\\n\"},{\"insert\":\"specify possible ways to improve results if not satisfactory\"},{\"attributes\":{\"list\":\"bullet\"},\"insert\":\"\\n\"},{\"insert\":\"\\n\"}]}"
      },
      "edge_connections": [
        {
          "id": "f632590a-14fc-4b50-8adb-9b6454ce8d95",
          "connector": "left"
        },
        {
          "id": "d476f21f-d72d-45bf-9428-8558a43e5287",
          "connector": "right"
        },
        {
          "id": "115ed813-391e-4c36-bbfa-8f0ab38d2266",
          "connector": "bottom"
        }
      ],
      "type": "note",
      "position": {
        "x": 1772.9999809265132,
        "y": 161.43751144409177
      },
      "size": {
        "width": 235.93749999999997,
        "height": 272.1875
      },
      "color": "#51455b"
    },
    {
      "id": "4bea62af-3989-4ce1-856f-c949197ccab9",
      "title": "6. EXPORT AND USE TRAINED MODEL ON STREAMLIT APP",
      "type_specific": {
        "message": "{\"ops\":[{\"insert\":\"After the notebook runs, a joblib file containing the data is exported to the ./out folder.\\n\\nProceed to 'detect_outliers.ipynb' and run it. Copy the link to a new tab from the first cell and change the last few digits (port) to the corresponding port in the second cell. This will open a streamlit web app that will import the trained models and data, and allow you to make outlier predictions with new inputs based on the trained models.\\n\"}]}"
      },
      "edge_connections": [
        {
          "id": "d476f21f-d72d-45bf-9428-8558a43e5287",
          "connector": "left"
        }
      ],
      "type": "note",
      "position": {
        "x": 2135.7249908447257,
        "y": 158.98750305175776
      },
      "size": {
        "width": 246.24999999999994,
        "height": 274.99999999999994
      },
      "color": "#51455b"
    },
    {
      "id": "4cde7c67-901e-4362-834f-981bcd931e9c",
      "title": "PRoject",
      "type_specific": {
        "message": "{\"ops\":[{\"insert\":\"Use Case\"},{\"attributes\":{\"header\":1},\"insert\":\"\\n\"},{\"insert\":\"Given the a 'clean' dataset of ... , we would like to predict in new data the cases of abnormal...\\n\\nObjective\"},{\"attributes\":{\"header\":1},\"insert\":\"\\n\"},{\"insert\":\"eg. To train an autoencoder to detect outliers in new datasets.\\n\\nGeneral Procedure\"},{\"attributes\":{\"header\":1},\"insert\":\"\\n\"},{\"insert\":\"Import data - Normalise data - Set up model architecture - Interpret and validate results\\n\\n_________________________________\\nIn the notebook \\\"unsupervised.ipynb\\\", adjust the respective lines (linked to the card) to\\nspecify the name of the outlier detection project.\"},{\"attributes\":{\"list\":\"bullet\"},\"insert\":\"\\n\"},{\"insert\":\"\\n\"}]}"
      },
      "edge_connections": [
        {
          "id": "b30c61ab-fa2f-49e0-a78f-b173d136f7e7",
          "connector": "top"
        }
      ],
      "type": "note",
      "position": {
        "x": 367.3655395507811,
        "y": 504.37810897827126
      },
      "size": {
        "width": 232.81249999999994,
        "height": 306.56249999999994
      },
      "color": "#125059"
    },
    {
      "id": "8fd668c2-42ab-4ef2-94ce-5dcc20ef21f7",
      "title": "Dataset",
      "type_specific": {
        "message": "{\"ops\":[{\"insert\":\"Dataset\"},{\"attributes\":{\"header\":1},\"insert\":\"\\n\"},{\"insert\":\"Name: eg. Diabetes\\nSamples: eg. 442\\nDimensions: eg 11\\n\\n_________________________________\\nIn the notebook \\\"unsupervised.ipynb\\\", adjust the respective lines (linked to the card) to\\nspecify the paths of the dataset file\"},{\"attributes\":{\"list\":\"bullet\"},\"insert\":\"\\n\"},{\"insert\":\"specify if the data is time-series\"},{\"attributes\":{\"list\":\"bullet\"},\"insert\":\"\\n\"},{\"insert\":\"\\n\"}]}"
      },
      "edge_connections": [
        {
          "id": "cc797318-e943-4173-9678-08bb3e2f5146",
          "connector": "top"
        }
      ],
      "type": "note",
      "position": {
        "x": 703.3031349182127,
        "y": 504.37810897827126
      },
      "size": {
        "width": 254.68749999999994,
        "height": 319.06249999999994
      },
      "color": "#125059"
    },
    {
      "id": "21061b72-a690-4b45-b72e-965c4e098082",
      "title": "Models",
      "type_specific": {
        "message": "{\"ops\":[{\"insert\":\"Model Architecture\"},{\"attributes\":{\"header\":1},\"insert\":\"\\n\"},{\"insert\":\"Sequential Convolutional\\n_________________________________________________________________\\nLayer (type)                 Output Shape              Param #   \\n=================================================================\\nconv1d_4 (Conv1D)            (None, 16, 32)            2944      \\n_________________________________________________________________\\ndropout_8 (Dropout)          (None, 16, 32)            0         \\n_________________________________________________________________\\nconv1d_5 (Conv1D)            (None, 8, 16)             3600      \\n_________________________________________________________________\\nconv1d_transpose_6 (Conv1DTr (None, 16, 16)            1808      \\n_________________________________________________________________\\ndropout_9 (Dropout)          (None, 16, 16)            0         \\n_________________________________________________________________\\nconv1d_transpose_7 (Conv1DTr (None, 32, 32)            3616      \\n_________________________________________________________________\\nconv1d_transpose_8 (Conv1DTr (None, 32, 1)             225       \\n=================================================================\\nTotal params: 12,193\\nTrainable params: 12,193\\nNon-trainable params: 0\\n_________________________________________________________________\\n\\n_________________________________\\n\\n\\n\\nRun the trials with the help of the notebook \\\"unsupervised.ipynb\\\":\\n\\nSelect which models to run.\\nTo start, execute all the notebook cells in order (e.g. click the play icon at the top of the notebook)\u00a0\\n\"}]}"
      },
      "edge_connections": [
        {
          "id": "bf8e80b8-47aa-4a32-b02f-d4f399287f82",
          "connector": "top"
        }
      ],
      "type": "note",
      "position": {
        "x": 1034.5531349182124,
        "y": 507.50310897827126
      },
      "size": {
        "width": 274.99999999999994,
        "height": 319.06249999999994
      },
      "color": "#125059"
    },
    {
      "id": "71a425ed-b8d4-4877-9fe3-d6efc56866ec",
      "title": "Final Results",
      "type_specific": {
        "message": "{\"ops\":[{\"insert\":\"Model:\\n\\nReconstruction error threshold:\\n\\n\\n_________________________________\\nIn the notebook \\\"unsupervised.ipynb\\\",\\ngo to the linked cell that displays the results\\n\"}]}"
      },
      "edge_connections": [
        {
          "id": "76696f53-b255-47b3-bf85-e630aa705c7e",
          "connector": "top"
        }
      ],
      "type": "note",
      "position": {
        "x": 1392.3656349182124,
        "y": 516.8781089782713
      },
      "size": {
        "width": 259.37499999999994,
        "height": 314.37499999999994
      },
      "color": "#125059"
    },
    {
      "id": "caef2200-2457-4b12-8b95-4f08606cc20b",
      "title": "Interpret and improve",
      "type_specific": {
        "message": "{\"ops\":[{\"insert\":\"Does the autoencoder train well enough?\"},{\"attributes\":{\"header\":2},\"insert\":\"\\n\"},{\"insert\":\"Benchmark loss:\\nResult: \\n\\nAre the reconstruction thresholds low?\"},{\"attributes\":{\"header\":2},\"insert\":\"\\n\"},{\"insert\":\"\\n\"}]}"
      },
      "edge_connections": [
        {
          "id": "115ed813-391e-4c36-bbfa-8f0ab38d2266",
          "connector": "top"
        }
      ],
      "type": "note",
      "position": {
        "x": 1762.6781349182122,
        "y": 520.0031089782713
      },
      "size": {
        "width": 265.62499999999994,
        "height": 308.12499999999994
      },
      "color": "#125059"
    }
  ],
  "edges": [
    {
      "id": "3a710e71-3ba4-440e-b51e-da8df811e84c",
      "type": "solid_arrow",
      "node_connections": [
        "e06cb8d7-2163-4526-acca-939e1fb33482",
        "d3f724fa-f5a8-4854-acaa-7c16f3e29225"
      ],
      "type_specific": {
        "annotation": ""
      }
    },
    {
      "id": "a95c7bd7-c98c-4fc9-8828-6656222c8590",
      "type": "solid_arrow",
      "node_connections": [
        "d3f724fa-f5a8-4854-acaa-7c16f3e29225",
        "4f2e9c89-3562-4d59-8883-28bd4be9eea7"
      ],
      "type_specific": {
        "annotation": ""
      }
    },
    {
      "id": "221fcfaa-1e76-4447-8f65-07b96dbbc89f",
      "type": "solid_arrow",
      "node_connections": [
        "4f2e9c89-3562-4d59-8883-28bd4be9eea7",
        "762e39b3-1d0e-4f0e-b724-350c095d200d"
      ],
      "type_specific": {
        "annotation": ""
      }
    },
    {
      "id": "aab255c5-026b-47d9-8389-60d5024eb453",
      "type": "solid_arrow",
      "node_connections": [
        "762e39b3-1d0e-4f0e-b724-350c095d200d",
        "9b703f26-e334-401b-b6fb-280ada141058"
      ],
      "type_specific": {
        "annotation": ""
      }
    },
    {
      "id": "f632590a-14fc-4b50-8adb-9b6454ce8d95",
      "type": "solid_arrow",
      "node_connections": [
        "9b703f26-e334-401b-b6fb-280ada141058",
        "ff9d0c41-8923-4419-956f-3aed5b4186ff"
      ],
      "type_specific": {
        "annotation": ""
      }
    },
    {
      "id": "d476f21f-d72d-45bf-9428-8558a43e5287",
      "type": "solid_arrow",
      "node_connections": [
        "ff9d0c41-8923-4419-956f-3aed5b4186ff",
        "4bea62af-3989-4ce1-856f-c949197ccab9"
      ],
      "type_specific": {
        "annotation": ""
      }
    },
    {
      "id": "b30c61ab-fa2f-49e0-a78f-b173d136f7e7",
      "type": "dashed_arrow",
      "node_connections": [
        "d3f724fa-f5a8-4854-acaa-7c16f3e29225",
        "4cde7c67-901e-4362-834f-981bcd931e9c"
      ],
      "type_specific": {
        "annotation": ""
      }
    },
    {
      "id": "cc797318-e943-4173-9678-08bb3e2f5146",
      "type": "dashed_arrow",
      "node_connections": [
        "4f2e9c89-3562-4d59-8883-28bd4be9eea7",
        "8fd668c2-42ab-4ef2-94ce-5dcc20ef21f7"
      ],
      "type_specific": {
        "annotation": ""
      }
    },
    {
      "id": "bf8e80b8-47aa-4a32-b02f-d4f399287f82",
      "type": "dashed_arrow",
      "node_connections": [
        "762e39b3-1d0e-4f0e-b724-350c095d200d",
        "21061b72-a690-4b45-b72e-965c4e098082"
      ],
      "type_specific": {
        "annotation": ""
      }
    },
    {
      "id": "76696f53-b255-47b3-bf85-e630aa705c7e",
      "type": "dashed_arrow",
      "node_connections": [
        "9b703f26-e334-401b-b6fb-280ada141058",
        "71a425ed-b8d4-4877-9fe3-d6efc56866ec"
      ],
      "type_specific": {
        "annotation": ""
      }
    },
    {
      "id": "115ed813-391e-4c36-bbfa-8f0ab38d2266",
      "type": "dashed_arrow",
      "node_connections": [
        "ff9d0c41-8923-4419-956f-3aed5b4186ff",
        "caef2200-2457-4b12-8b95-4f08606cc20b"
      ],
      "type_specific": {
        "annotation": ""
      }
    }
  ]
}