{"cells": [{"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "8782724a-4360-4f93-abd9-d543a3a1fe75"}, "outputs": [], "source": ["# Regression\r\n", "\r\n", "This is a template notebook for regression modelling.\r\n", "\r\n", "Author: {{ cookiecutter.author_name }}\r\n", "Created: {{ cookiecutter.timestamp }}\r\n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "48b0cab2-2c62-4d8c-ae63-0f314b853865"}, "outputs": [], "source": ["# Link to project experiments folder hypothesis_experiment_learnings.board (refresh and hit enter on this line to see the link)"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "1f4cc870-9da7-4624-90bb-04617664fab1"}, "outputs": [], "source": ["## How to use the notebook\r\n", "\r\n", "The following cells:\r\n", "- specify objective, variables, and variable types,\r\n", "- set up the regression models,\r\n", "- read dataset,\r\n", "- present results from the model,\r\n", "- provide the model with the best performance.\r\n", "\r\n", "By default, the notebook is set up to run with an example (sklearn diabetes). To see how it works, run the notebook without changing the code.\r\n", "\r\n", "For your project, adjust the code in the linked cells with your objectives, variables, dataset etc. and then execute all cells in order.\r\n", "\r\n", "Please refer to regression.board for detailed instructions. The headers in this notebook follow the cards on the board."]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "6c133105-6a04-447b-9121-7ca8649106f2"}, "outputs": [], "source": ["# <halerium id=\"39b22147-b458-47ca-b7a6-6e198f0d285f\">\n", "# Link to regression.board\n", "# </halerium id=\"39b22147-b458-47ca-b7a6-6e198f0d285f\">\n"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "583b45a0-9006-4257-af22-9002dfbe94e2"}, "outputs": [], "source": ["## Imports"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "3cbc689b-5a80-45ee-9e6d-7de90f4837cb"}, "outputs": [], "source": ["import os\r\n", "import shutil\r\n", "from distutils.dir_util import copy_tree\r\n", "\r\n", "import time\r\n", "from datetime import datetime\r\n", "\r\n", "import numpy as np\r\n", "import pandas as pd\r\n", "\r\n", "import matplotlib.pyplot as plt\r\n", "\r\n", "from sklearn import datasets, metrics\r\n", "from sklearn.model_selection import train_test_split\r\n", "\r\n", "from sklearn.linear_model import LinearRegression, Lasso, Ridge\r\n", "from sklearn.tree import DecisionTreeRegressor\r\n", "from sklearn.ensemble import RandomForestRegressor\r\n", "from sklearn.neural_network import MLPRegressor\r\n", "\r\n", "from warnings import simplefilter\r\n", "from sklearn.exceptions import ConvergenceWarning\r\n", "simplefilter(\"ignore\", category=ConvergenceWarning)\r\n", "\r\n", "from joblib import dump, load"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "52dec34e-2f1b-4037-962d-ffcc6e18fb60"}, "outputs": [], "source": ["## Parameter Setup\r\n", "The following parameters and variables should be adjusted based on your data and experimental objectives"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "4c39011a-6794-4f79-8f68-d61320ec8858"}, "outputs": [], "source": ["### 2. Import the Dataset"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "4c0614cb-2eda-4d24-966e-e745262cab79"}, "outputs": [], "source": ["# <halerium id=\"8595d578-e365-46d6-9b08-16e0569992e4\">\n", "path = 'default example' # Specify the filepath here\n", "test_size = 0.25 # You may adjust this value to change the train/test split ratio\n", "# </halerium id=\"8595d578-e365-46d6-9b08-16e0569992e4\">\n"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "257f45af-5b30-4b82-aaa1-08c89ff0931b"}, "outputs": [], "source": ["Importing the dataset"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "8b338ebd-95fa-4a7f-81d5-8ab17593b17e"}, "outputs": [], "source": ["example_df = datasets.load_diabetes(return_X_y=False, as_frame=True)['frame'] # The default example of the template - sklearn diabetes\r\n", "if path == 'default example':\r\n", "    df = example_df\r\n", "else:\r\n", "  df = pd.read_csv(path)"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "4b2b5d0c-1e6b-4198-bd0a-ad6f2ed95cab"}, "outputs": [], "source": ["Visualising the dataset"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "26338e32-7e49-40f1-a746-f9ec598d947d"}, "outputs": [], "source": ["df"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "defa4a15-0a91-471c-8113-bae8397090f7"}, "outputs": [], "source": ["Creating the /out folder for artifacts"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "a52d5bc0-0eab-49c7-9b0d-42d1b099bc97"}, "outputs": [], "source": ["path = 'out'\r\n", "isExist = os.path.exists(path)\r\n", "if isExist:\r\n", "  for root, dirs, files in os.walk(path):\r\n", "      for f in files:\r\n", "          os.unlink(os.path.join(root, f))\r\n", "      for d in dirs:\r\n", "          shutil.rmtree(os.path.join(root, d))\r\n", "else:\r\n", "  os.makedirs(path)\r\n", "\r\n", "df.to_csv(path + '/dataset.csv')"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "a7147c46-63e1-495a-b10e-2b7b88f999e7"}, "outputs": [], "source": ["### 3. Specify the Variables"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "4ac40434-c06d-4f78-a636-2fb308db65d9"}, "outputs": [], "source": ["# Specify exactly the names of the dependent variables (aka variables you wish to predict)\n", "# <halerium id=\"5c3a0d9f-05df-4ed7-8dd9-2f011bf9bb59\">\n", "target = ['target'] # eg. ['variable1', 'variable2']\n", "# </halerium id=\"5c3a0d9f-05df-4ed7-8dd9-2f011bf9bb59\">\n"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "d3323b71-e8b2-482a-ae98-58407dac3425"}, "outputs": [], "source": ["### 4. Normalise the data"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "6501a720-41f2-4a7c-b85d-27f3b5ce7d4b"}, "outputs": [], "source": ["# <halerium id=\"4f4ac754-14f7-4fd1-88cc-df724631601b\">\n", "normalisation_method = 'standard' # 'none', 'standard', 'minmax'\n", "# </halerium id=\"4f4ac754-14f7-4fd1-88cc-df724631601b\">\n"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "1da89b3e-8d64-4bdb-8f80-93c84ed0e436"}, "outputs": [], "source": ["### 5. Reduce Dimensionality"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "8f0e8dba-b914-4e15-a478-345a20dff3f3"}, "outputs": [], "source": ["Correlation Matrix"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "d17b0a55-685b-439f-bb4b-9b9c54c6ab6c"}, "outputs": [], "source": ["corr_target = abs(df.corr()[target])\r\n", "print(corr_target)"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "a3dbfeb9-ae92-49b4-97f9-ec87e7e16849"}, "outputs": [], "source": ["Reduction Method"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "ea5c1e27-50a1-4da6-bb05-702c0208ad94"}, "outputs": [], "source": ["# For manual reduction\n", "# <halerium id=\"9211d717-e939-4f69-b530-94c9d9a522d5\">\n", "variables_to_remove = ['sex'] # eg. ['variable1'] or empty list [] if none to remove\n", "# </halerium id=\"9211d717-e939-4f69-b530-94c9d9a522d5\">\n"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "230c197e-4a24-4805-aea9-b8c5040b3d79"}, "outputs": [], "source": ["### 6. Regularise the Model"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "330df2dd-d56c-453a-8bfa-c9ebf6c81b57"}, "outputs": [], "source": ["# <halerium id=\"72c52810-7bf8-4e6d-8143-76772ad199a1\">\n", "alpha_param = np.logspace(-4, 0, num=50) # default = np.logspace(-4, 0, num=50)\n", "# </halerium id=\"72c52810-7bf8-4e6d-8143-76772ad199a1\">\n"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "3028528b-b491-469d-b0e6-f2cbfa1b87b7"}, "outputs": [], "source": ["### 7. Limit Iterations"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "9d5c4244-27aa-46c0-9513-8d8386a604cf"}, "outputs": [], "source": ["# <halerium id=\"9ffe4933-c590-4333-8b90-397004481121\">\n", "poly_limit = 4 # Limit for polynomial degree, default = 4\n", "max_depth = None # Limit for decision tree/random forest depth, default = None\n", "# </halerium id=\"9ffe4933-c590-4333-8b90-397004481121\">\n"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "79a3d00c-ccb5-44ef-bf94-8d5e90a7c699"}, "outputs": [], "source": ["### 8. Run the Models"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "5aa7b936-bfcb-4336-acc7-a7cf21f9949a"}, "outputs": [], "source": ["# <halerium id=\"cf674127-a6f1-4624-aa9b-b89a768166ba\">\n", "run_models = ['linear', 'l1_linear', 'l2_linear', 'poly', 'tree'] # Specify the models you would like to run in the list\n", "# </halerium id=\"cf674127-a6f1-4624-aa9b-b89a768166ba\">\n", "# Possible models: ['linear', 'l1_linear', 'l2_linear', 'poly', 'tree', 'forest', 'mlp']\n", "\n", "if not run_models:\n", "    raise ValueError('You must pick at least 1 model to run')"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "fd8b3710-121d-4308-a2d2-78e6d9788071"}, "outputs": [], "source": ["There are no user inputs beyond this point. \r\n", "\r\n", "You may skip to the results section to view the results of the models."]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "8015973e-5967-4809-9952-9e8705d0bc05"}, "outputs": [], "source": ["Extracting the X (inputs) and y (outputs)"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "652a0e98-9be8-4800-ba85-8dfa8aae30a4"}, "outputs": [], "source": ["X = df.drop(columns=target)\r\n", "y = df[target]\r\n", "\r\n", "labels = list(X.columns)\r\n", "num_labels = len(labels)\r\n", "target_labels = list(y.columns)\r\n", "num_target_labels = len(target_labels)\r\n", "print(labels, target_labels)"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "a9d30bd9-b871-442b-b7fa-3804681415ab"}, "outputs": [], "source": ["Splitting the training and testing data"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "75393a2d-4cd1-4154-b899-5345a3adb301"}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\r\n", "\r\n", "if 'half' in globals() and half:\r\n", "    X_train, X_discard, y_train, y_discard = train_test_split(X_train, y_train, test_size = 0.5)"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "aa2aac72-af5c-46b1-b88d-57ceda9c91f5"}, "outputs": [], "source": ["Manual Dimensionality Reduction"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "e65c1841-8761-4cfd-ae3b-3c4a4fed38fd"}, "outputs": [], "source": ["if variables_to_remove:\r\n", "    X_train = X_train.drop(columns=variables_to_remove)\r\n", "    X_test = X_test.drop(columns=variables_to_remove)\r\n", "    \r\n", "    for x in variables_to_remove:\r\n", "        labels.remove(x)"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "2dc08eb1-a334-4344-a1f9-30bc7952a675"}, "outputs": [], "source": ["Scaling"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "d61ae077-5e84-45ee-9356-72f31966a69a"}, "outputs": [], "source": ["from functions.scale import scale\r\n", "\r\n", "if normalisation_method:\r\n", "    X_train, X_test, y_train, y_test = scale(X_train, X_test, y_train, y_test, normalisation_method, path)"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "a4030be8-eb66-4885-b10e-b74e1a30ef72"}, "outputs": [], "source": ["Setting up the models"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "8d7c75d7-bd5f-409b-a600-230501108e6c"}, "outputs": [], "source": ["models = {\r\n", "    'linear': LinearRegression(),\r\n", "    'l1_linear': Lasso(),\r\n", "    'l2_linear': Ridge(),\r\n", "    'poly': Ridge(),\r\n", "    'tree': DecisionTreeRegressor(max_depth=max_depth),\r\n", "    'forest': RandomForestRegressor(max_depth=max_depth),\r\n", "    'mlp': MLPRegressor()\r\n", "}"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "47a37138-b529-4d0b-8d1a-e2681b029fa6"}, "outputs": [], "source": ["# Parameter grids for each model\r\n", "linear_param_grid = {\r\n", "    \"pca__n_components\": np.linspace(1, len(labels), min(len(labels), 10), dtype=int),\r\n", "    \"model__fit_intercept\": [True, False]\r\n", "}\r\n", "\r\n", "lasso_param_grid = {\r\n", "    \"pca__n_components\": np.linspace(1, len(labels), min(len(labels), 10), dtype=int),\r\n", "    \"model__alpha\": alpha_param,\r\n", "    \"model__fit_intercept\": [True, False]\r\n", "}\r\n", "\r\n", "ridge_param_grid = {\r\n", "    \"pca__n_components\": np.linspace(1, len(labels), min(len(labels), 10), dtype=int),\r\n", "    \"model__alpha\": alpha_param,\r\n", "    \"model__fit_intercept\": [True, False]\r\n", "}\r\n", "\r\n", "poly_param_grid = {\r\n", "    \"pca__n_components\": np.linspace(1, len(labels), min(len(labels), 10), dtype=int),\r\n", "    \"model__alpha\": alpha_param,\r\n", "    \"model__fit_intercept\": [True, False],\r\n", "    \"poly__degree\": np.arange(2, poly_limit + 1, 1),\r\n", "    \"poly__include_bias\": [True, False]\r\n", "}\r\n", "\r\n", "tree_param_grid = {\r\n", "    \"pca__n_components\": np.linspace(1, len(labels), min(len(labels), 10), dtype=int),\r\n", "    \"model__criterion\": ['squared_error', 'friedman_mse', 'absolute_error'],\r\n", "    \"model__ccp_alpha\": alpha_param\r\n", "}\r\n", "\r\n", "forest_param_grid = {\r\n", "    \"pca__n_components\": np.linspace(1, len(labels), min(len(labels), 10), dtype=int),\r\n", "    \"model__criterion\": ['squared_error', 'absolute_error'],\r\n", "    \"model__ccp_alpha\": alpha_param,\r\n", "    \"model__n_estimators\": np.linspace(1, 1000, 21, dtype=int)\r\n", "}\r\n", "\r\n", "mlp_param_grid = {\r\n", "    \"pca__n_components\": np.linspace(1, len(labels), min(len(labels), 10), dtype=int),\r\n", "    \"model__activation\": ['identity', 'logistic', 'tanh', 'relu'],\r\n", "    \"model__solver\": ['lbfgs', 'sgd', 'adam'],\r\n", "    \"model__alpha\": alpha_param,\r\n", "    \"model__learning_rate\": ['constant', 'invscaling', 'adaptive']\r\n", "}"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "6b91ac0a-2819-40eb-96af-d8b7d3a4251c"}, "outputs": [], "source": ["models_param_grid = {\r\n", "    'linear': linear_param_grid,\r\n", "    'l1_linear': lasso_param_grid,\r\n", "    'l2_linear': ridge_param_grid,\r\n", "    'poly': poly_param_grid,\r\n", "    'tree': tree_param_grid,\r\n", "    'forest': forest_param_grid,\r\n", "    'mlp': mlp_param_grid\r\n", "}"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "7857e28d-630d-43e5-9f59-443181fdd8f2"}, "outputs": [], "source": ["Running the regression"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "9b2fee9f-4daf-4f65-92eb-f6922ed20e97"}, "outputs": [], "source": ["from functions.run_regression_pipeline import run_regression\r\n", "\r\n", "model_results = run_regression(X_train, X_test, y_train, y_test, run_models, models, models_param_grid, labels)"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "51a9323e-9b4a-4bce-b744-e7705e043c4e"}, "outputs": [], "source": ["### 9. Get the Results"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "321204dd-7743-4ef8-8757-b8ba08050db6"}, "outputs": [], "source": ["results = pd.DataFrame(model_results)\r\n", "results = results[:2]\r\n", "results.index = ['Testing Score', 'Time Taken']\r\n", "results[:2]"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "742e8e0e-88b8-47c1-bd89-2051a584a400"}, "outputs": [], "source": ["plt.title(\"Testing Score\")\r\n", "model = list(model_results.keys())\r\n", "final_time = [x[0] for x in list(model_results.values())]\r\n", "plt.bar(model, final_time)\r\n", "# <halerium id=\"2b2d88c0-4964-484f-aa20-12cd6974301f\">\n", "plt.show()\n", "# </halerium id=\"2b2d88c0-4964-484f-aa20-12cd6974301f\">\n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "b8b76529-003d-4998-891b-ddccba7eda8b"}, "outputs": [], "source": ["plt.title(\"Training Time\")\r\n", "model = list(model_results.keys())\r\n", "final_time = [x[1] for x in list(model_results.values())]\r\n", "plt.bar(model, final_time)\r\n", "# <halerium id=\"2b2d88c0-4964-484f-aa20-12cd6974301f\">\n", "plt.show()\n", "# </halerium id=\"2b2d88c0-4964-484f-aa20-12cd6974301f\">\n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "f5e5b5fa-a7bf-4fff-a80e-e7a38e65894a"}, "outputs": [], "source": ["best_model = max(model_results, key=(lambda key: model_results[key]))\r\n", "# <halerium id=\"2b2d88c0-4964-484f-aa20-12cd6974301f\">\n", "print(\"Best model:\", best_model)\r\n", "print(model_results[best_model][2])\n", "# </halerium id=\"2b2d88c0-4964-484f-aa20-12cd6974301f\">\n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "8b780a7a-ff52-4661-bc75-5a171696a6e1"}, "outputs": [], "source": ["dump([best_model, model_results[best_model], labels, target], path + '/model.joblib')"]}, {"cell_type": "markdown", "execution_count": 0, "metadata": {"id": "4d7a331e-7e2e-4fcf-92a8-f4350cdef8ce"}, "outputs": [], "source": ["### 10. Interpret and Improve"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"id": "9560154a-6187-4795-912e-766148f7eb95"}, "outputs": [], "source": ["# <halerium id=\"4f82ef15-a13e-49e5-8119-af8ecd3afd3a\">\n", "half=True\n", "# </halerium id=\"4f82ef15-a13e-49e5-8119-af8ecd3afd3a\">\n"]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 0}