{
 "cells": [
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "2ba17d09-b4ec-4df7-8a9c-12b7d1b96abb"
   },
   "outputs": [],
   "source": [
    "# Classical statistical hypothesis testing\r\n",
    "Approaches to determine correlation by analysing statistical probabilities purely in the data\r\n",
    "\r\n",
    "Author: {{ cookiecutter.author_name }}\r\n",
    "Created: {{ cookiecutter.timestamp }}"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "0557cfb3-8767-4ba5-8da4-1cf2fff9f63e"
   },
   "outputs": [],
   "source": [
    "## How to use the notebook\r\n",
    "\r\n",
    "The following cells:\r\n",
    "- specify objective, variables, and variable types,\r\n",
    "- set up the statistical tests,\r\n",
    "- read dataset,\r\n",
    "- present results from the tests,\r\n",
    "\r\n",
    "By default, the notebook is set up to run with an example (wine quality). To see how it works, run the notebook without changing the code.\r\n",
    "\r\n",
    "For your project, adjust the code in the linked cells with your objectives, variables, dataset etc. and then execute all cells in order.\r\n",
    "\r\n",
    "Please refer to classical_ht.board for detailed instructions."
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "metadata": {
    "id": "6ea86cb0-ce66-4b0f-9741-a74263753d21"
   },
   "outputs": [],
   "source": [
    "# Link to project experiments folder hypothesis_experiment_learnings.board (refresh and hit enter on this line to see the link)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "bdba24c1-46bb-4c1a-9c1f-41bfd6a3f116"
   },
   "outputs": [],
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "5339652b-984d-42cc-9a03-bf80abe0213c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import scipy.stats as stats\r\n",
    "import statsmodels.api as sm\r\n",
    "from statsmodels.tsa.stattools import adfuller\r\n",
    "from statsmodels.tsa.seasonal import STL\r\n",
    "\r\n",
    "from bioinfokit.analys import stat \r\n",
    "\r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "8fda1097-2abb-40bd-abc8-42019b812521"
   },
   "outputs": [],
   "source": [
    "### Project"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "eb228af2-23ad-4ba6-934b-1dd71c7b39ad",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "f6d0c4c4-d05c-41c1-978d-b01adbecaf63"
   },
   "outputs": [],
   "source": [
    "experiment_name = '{{cookiecutter.use_case_name}}'  # please provide a name for the hypothesis testing experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "be5cdf64-9489-4efb-843a-721c33373e04"
   },
   "outputs": [],
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 2,
     "id": "b3efd83e-8e68-4c0c-b19b-106a635fd8e7",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "3eea2fdc-805b-40fe-8b26-c3d430a3b9a3"
   },
   "outputs": [],
   "source": [
    "time_series = False\n",
    "path = '{{cookiecutter.data_path}}' # Specify the filepath of the data eg. './data/file.csv'\n",
    "project_data_folder_prefix = './../../../../data/'\n",
    "\n",
    "# If you are working in a Halerium project template folder, and the notebook is in the /experiments folder, and the data is in the /data folder\n",
    "# Uncomment the next line to append the prefix of the relative data path from the experiments folder. \n",
    "#path = project_data_folder_prefix + path\n",
    "\n",
    "if path =='default example':\n",
    "    # Wine quality example dataset\n",
    "    path = 'https://raw.githubusercontent.com/erium/halerium-example-data/main/hypothesis_testing/WineQT.csv'\n",
    "\n",
    "if time_series:\n",
    "    df = pd.read_csv(path, parse_dates=['Date'], index_col=\"Date\")\n",
    "else:\n",
    "    df = pd.read_csv(path, sep=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "46e37de1-1056-48d5-ae67-14236e263575"
   },
   "outputs": [],
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 3,
     "id": "52769062-0a39-4288-9eb3-b4d75d7b0224",
     "startLine": 2
    },
    {
     "endLine": 5,
     "id": "52769062-0a39-4288-9eb3-b4d75d7b0224",
     "startLine": 5
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "e892c0fa-fe65-485f-a586-261c8ebc2768"
   },
   "outputs": [],
   "source": [
    "# Array of ['feature name', 'type'] where type is 'continuous', 'binary_categorical', 'multi_categorical'\r\n",
    "x = [['residual sugar', 'continuous']]\r\n",
    "y = [['quality', 'multi_categorical']]\r\n",
    "\r\n",
    "time_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "bc299f0f-6b63-41d0-9a44-f52ba590965f"
   },
   "outputs": [],
   "source": [
    "### Level of Significance"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "c92e4730-01e4-4180-b9b3-bcfeb311360e",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "2e32a46e-eab0-43eb-8f49-b1b10e7ef653"
   },
   "outputs": [],
   "source": [
    "significance = 0.05 # Level of significance"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "81945591-0666-4d61-9ab9-5eaeb5eb7705"
   },
   "outputs": [],
   "source": [
    "x_cont = [feature[0] for feature in x if feature[1] == 'continuous']\r\n",
    "y_cont = [feature[0] for feature in y if feature[1] == 'continuous']\r\n",
    "x_binary = [feature[0] for feature in x if feature[1] == 'binary_categorical']\r\n",
    "y_binary = [feature[0] for feature in y if feature[1] == 'binary_categorical']\r\n",
    "x_multi = [feature[0] for feature in x if feature[1] == 'multi_categorical']\r\n",
    "y_multi = [feature[0] for feature in y if feature[1] == 'multi_categorical']"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "0fd246c2-23a4-4594-b3ca-3b39dc1c5ee2"
   },
   "outputs": [],
   "source": [
    "num_samples = df.shape[0]\r\n",
    "print('Number of samples:', num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "644a9546-71ab-4784-9f7d-86df01f0a603"
   },
   "outputs": [],
   "source": [
    "results_x = {x_para[0]:[] for x_para in x}\r\n",
    "results_y = {y_para[0]:[] for y_para in y}\r\n",
    "results = {'x': [], 'y': [], 'test': [], 'passed': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "07e8aa36-6984-4d27-beff-37835e566bb9"
   },
   "outputs": [],
   "source": [
    "## Statistical Tests\r\n",
    "Some tests may be skipped if there are no x-y pairs that correspond to the test"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "c7be73fe-f01f-475b-ba6f-73a711e58feb"
   },
   "outputs": [],
   "source": [
    "### Time series Hypothesis Test\r\n",
    "1. Check if stationary (Dickey-Fuller test)\r\n",
    "2. Look at residuals of the time series - check if they follow normal distribution (D'Agostino and Pearson's)"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "4c743736-24b8-4bd3-8407-0dad24bfa284",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "e2d64014-c773-4eeb-8fb2-1dc0a4ff6d98"
   },
   "outputs": [],
   "source": [
    "time_results = {'stationary': [], 'normal residuals': []}\r\n",
    "for time_feature in time_features:\r\n",
    "    df_time = df[time_feature]\r\n",
    "    plt.plot(df_time)\r\n",
    "    plt.xlabel('Time')\r\n",
    "    plt.ylabel(time_feature)\r\n",
    "    plt.show()\r\n",
    "    stationarity = adfuller(df_time)\r\n",
    "    pvalue = stationarity[1]\r\n",
    "    print(\"Stationarity pvalue:\", pvalue)\r\n",
    "\r\n",
    "    results['x'].append(time_feature)\r\n",
    "    results['y'].append('-Time Series-')\r\n",
    "    results['test'].append('stationarity')\r\n",
    "    if pvalue <= significance:\r\n",
    "        print(time_feature, \"is stationary at significance\", significance)\r\n",
    "        time_results['stationary'].append(True)\r\n",
    "        results['passed'].append(True)\r\n",
    "    else:\r\n",
    "        print(time_feature, \"is not stationary at significance\", significance)\r\n",
    "        time_results['stationary'].append(False)\r\n",
    "        results['passed'].append(False)\r\n",
    "    \r\n",
    "    stl = STL(df_time, period=7)\r\n",
    "    res = stl.fit()\r\n",
    "    fig = res.plot()\r\n",
    "    resid = res.resid\r\n",
    "    k2, p = stats.normaltest(resid)\r\n",
    "    print(\"Normal Residuals pvalue:\", p)\r\n",
    "\r\n",
    "    results['x'].append(time_feature)\r\n",
    "    results['y'].append('-Time Series-')\r\n",
    "    results['test'].append('normal residuals')\r\n",
    "    if p > significance:\r\n",
    "        print(time_feature, \"residuals follow a normal distribution at significance\", significance)\r\n",
    "        time_results['normal residuals'].append(True)\r\n",
    "        results['passed'].append(True)\r\n",
    "    else:\r\n",
    "        print(time_feature, \"residuals do not follow a normal distribution at significance\", significance)\r\n",
    "        time_results['normal residuals'].append(False)\r\n",
    "        results['passed'].append(False)"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "cea6e1d9-0ac0-4044-933e-8561099da88b"
   },
   "outputs": [],
   "source": [
    "if time_features:\r\n",
    "    time_df = pd.DataFrame(time_results, index=time_features)\r\n",
    "    time_df"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "cff62e99-95eb-4f7d-a776-5546e75c3d75"
   },
   "outputs": [],
   "source": [
    "## Linear Correlation\r\n",
    "For continuous-continuous features"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "5aa9dc77-efa9-4bc7-88a4-e50b47cdfbae",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "e69ddc48-548d-44eb-a379-edbfef60874c"
   },
   "outputs": [],
   "source": [
    "df_corr = df.corr()\r\n",
    "df_corr[y_cont].loc[x_cont]"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "32232018-d26b-4edc-9071-92a1d5a60381"
   },
   "outputs": [],
   "source": [
    "fig_h = 5\r\n",
    "fig_w = 8\r\n",
    "\r\n",
    "fig, ax = plt.subplots(len(x_cont), len(y_cont))\r\n",
    "fig.set_figheight(fig_h * len(x_cont))\r\n",
    "fig.set_figwidth(fig_w * len(y_cont))\r\n",
    "if len(x_cont) == 1:\r\n",
    "    for i in range(len(y)):\r\n",
    "        slope, intercept, r, p, stderr = stats.linregress(df[x_cont[0]], df[y_cont[i]])\r\n",
    "        ax[i].scatter(df[x_cont[0]], df[y_cont[i]])\r\n",
    "        ax[i].plot(df[x_cont[0]], intercept + slope * df[x_cont[0]], color='r')\r\n",
    "        ax[i].set_xlabel(x_cont[0])\r\n",
    "        ax[i].set_ylabel(y_cont[i])\r\n",
    "elif len(y_cont) == 1:\r\n",
    "    for i in range(len(x_cont)):\r\n",
    "        slope, intercept, r, p, stderr = stats.linregress(df[x_cont[i]], df[y_cont[0]])\r\n",
    "        ax[i].scatter(df[x_cont[i]], df[y_cont[0]])\r\n",
    "        ax[i].plot(df[x_cont[i]], intercept + slope * df[x_cont[i]], color='r')\r\n",
    "        ax[i].set_xlabel(x_cont[i])\r\n",
    "        ax[i].set_ylabel(y_cont[0])\r\n",
    "else:\r\n",
    "    for i in range(len(x_cont)):\r\n",
    "        for j in range(len(y_cont)):\r\n",
    "            slope, intercept, r, p, stderr = stats.linregress(df[x_cont[i]], df[y_cont[j]])\r\n",
    "            ax[i, j].scatter(df[x_cont[i]],df[y_cont[j]])\r\n",
    "            ax[i, j].plot(df[x_cont[i]], intercept + slope * df[x_cont[i]], color='r')\r\n",
    "            ax[i, j].set_xlabel(x_cont[i])\r\n",
    "            ax[i, j].set_ylabel(y_cont[j])\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "1277820a-d7a6-4fa1-869a-817485a00a30"
   },
   "outputs": [],
   "source": [
    "Univariate approach"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "c2f27246-7a33-48ca-8eea-02b9e2bbd00c"
   },
   "outputs": [],
   "source": [
    "# Univariate (open to selection bias)\r\n",
    "for i in range(len(x_cont)):\r\n",
    "    for j in range(len(y_cont)):\r\n",
    "        X = sm.add_constant(df[x_cont[i]])\r\n",
    "        result = sm.OLS(df[y_cont[j]], X).fit()\r\n",
    "        print('Feature:', x_cont[i], 'Compared to:', y_cont[j])\r\n",
    "        results_as_html = result.summary().tables[1].as_html()\r\n",
    "        results_df = pd.read_html(results_as_html, header=0, index_col=0)[0].iloc[1:]\r\n",
    "        #print(result.summary().tables[1])\r\n",
    "        significant_corr_features = results_df.loc[results_df['P>|t|'] <= significance]\r\n",
    "        results['x'].append(x_cont[i])\r\n",
    "        results['y'].append(y_cont[j])\r\n",
    "        results['test'].append('uni')\r\n",
    "        if not significant_corr_features.empty:\r\n",
    "            print(\"Correlated features at significance:\", significance)\r\n",
    "            print(significant_corr_features)\r\n",
    "            results['passed'].append(True)\r\n",
    "        else:\r\n",
    "            print(\"Features not correlated at significance level:\", significance)\r\n",
    "            results['passed'].append(False)\r\n",
    "        print(\"__________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "f488071c-e756-4527-b9b3-1890fed21af4"
   },
   "outputs": [],
   "source": [
    "Multivariate Approach"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "99d714e2-9124-4d12-b9b7-a5c80c6fe48d"
   },
   "outputs": [],
   "source": [
    "# Multivariate (open to confounding bias)\r\n",
    "for j in range(len(y_cont)):\r\n",
    "    X = sm.add_constant(df[x_cont])\r\n",
    "    result = sm.OLS(df[y_cont[j]], X).fit()\r\n",
    "    print('Feature:', y_cont[j])\r\n",
    "    results_as_html = result.summary().tables[1].as_html()\r\n",
    "    results_df = pd.read_html(results_as_html, header=0, index_col=0)[0].iloc[1:]\r\n",
    "    #print(result.summary().tables[1])\r\n",
    "    significant_corr_features = results_df.loc[results_df['P>|t|'] <= significance]\r\n",
    "    if not significant_corr_features.empty:\r\n",
    "        print(\"Correlated features at significance:\", significance)\r\n",
    "        print(significant_corr_features)\r\n",
    "        results_y[y_cont[j]].append([x_cont, 'multi', True])\r\n",
    "        for x_para in list(significant_corr_features.index):\r\n",
    "            results['x'].append(x_para)\r\n",
    "            results['y'].append(y_cont[j])\r\n",
    "            results['test'].append('multi')\r\n",
    "            results['passed'].append(True)\r\n",
    "        for x_para in list(results_df.loc[results_df['P>|t|'] > significance].index):\r\n",
    "            results['x'].append(x_para)\r\n",
    "            results['y'].append(y_cont[j])\r\n",
    "            results['test'].append('multi')\r\n",
    "            results['passed'].append(False)\r\n",
    "    else:\r\n",
    "        print(\"Features not correlated at significance level:\", significance)\r\n",
    "        for x_para in list(results_df.loc[results_df['P>|t|'] > significance].index):\r\n",
    "            results['x'].append(x_para)\r\n",
    "            results['y'].append(y_cont[j])\r\n",
    "            results['test'].append('multi')\r\n",
    "            results['passed'].append(False)\r\n",
    "        \r\n",
    "    print(\"__________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "b78fe4f4-b1d8-4d53-b173-48a5ff0d8e1e"
   },
   "outputs": [],
   "source": [
    "### ANOVA (Analysis of Variance)\r\n",
    "For continuous-non-binary discrete\r\n",
    "\r\n",
    "Null hypothesis: Group means are equal (No effect on the categorical variable)\r\n",
    "Alternative hypothesis: At least one group mean is different from other group means (Effect on the categorical variable)\r\n",
    "\r\n",
    "Note: Pairwise comparison using Tukey's honestly significantly differenced test to find which are the significant treatments (discrete)"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "d23b832f-a251-4a6c-8d89-f9e68f65c779",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "0089eab4-d553-4b1d-a1be-ff20a510f107"
   },
   "outputs": [],
   "source": [
    "# One way ANOVA\r\n",
    "for x in x_multi:\r\n",
    "    discrete_values = list(set(df[x]))\r\n",
    "    for y in y_cont:\r\n",
    "        discrete_sets = []\r\n",
    "        print(\"Feature:\", y, \"compared to discrete:\", x)\r\n",
    "        for value in discrete_values:\r\n",
    "            discrete_sets.append(df[y].loc[df[x] == value])\r\n",
    "        plt.boxplot(discrete_sets, labels=discrete_values)\r\n",
    "        plt.xlabel(x)\r\n",
    "        plt.ylabel(y)\r\n",
    "        plt.show()\r\n",
    "        fvalue, pvalue = stats.f_oneway(*discrete_sets)\r\n",
    "        print(\"fvalue:\", fvalue, \"pvalue:\", pvalue)\r\n",
    "        results['x'].append(x)\r\n",
    "        results['y'].append(y)\r\n",
    "        results['test'].append('anova')\r\n",
    "        if pvalue < significance:\r\n",
    "            print(\"Group mean of\" , y, \"affected at significance:\", significance)\r\n",
    "            df_discrete = pd.DataFrame(discrete_sets, index=discrete_values).T\r\n",
    "            df_discrete = pd.melt(df_discrete.reset_index(),id_vars=['index'], value_vars=discrete_values)\r\n",
    "            df_discrete.columns =['index', 'treatments', 'value']\r\n",
    "            res = stat()\r\n",
    "            res.tukey_hsd(df=df_discrete, res_var='value', xfac_var='treatments', anova_model='value ~ C(treatments)')\r\n",
    "            print(\"Pairwise comparison\")\r\n",
    "            print(res.tukey_summary)\r\n",
    "            results['passed'].append(True)\r\n",
    "        else:\r\n",
    "            print(\"Group mean of\", y, \"not affected at significance:\", significance)\r\n",
    "            results['passed'].append(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "7d769c74-1b79-4a81-9d76-fb05d497f9af"
   },
   "outputs": [],
   "source": [
    "## t-test\r\n",
    "For binary categorical - continuous"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "a20f2f0c-aeac-446b-bce8-b99de87a8804",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "89390581-7c21-4b82-bb66-4745ec34cb0e"
   },
   "outputs": [],
   "source": [
    "for x in x_binary:\r\n",
    "    discrete_values = list(set(df[x]))\r\n",
    "    for y in y_cont:\r\n",
    "        discrete_sets = []\r\n",
    "        print(\"Feature:\", y, \"compared to discrete:\", x)\r\n",
    "        for value in discrete_values:\r\n",
    "            discrete_sets.append(df[y].loc[df[x] == value])\r\n",
    "        plt.boxplot(discrete_sets, labels=discrete_values)\r\n",
    "        plt.xlabel(x)\r\n",
    "        plt.ylabel(y)\r\n",
    "        plt.show()\r\n",
    "        fvalue, pvalue = stats.ttest_ind(*discrete_sets)\r\n",
    "        print(\"fvalue:\", fvalue, \"pvalue:\", pvalue)\r\n",
    "        results['x'].append(x)\r\n",
    "        results['y'].append(y)\r\n",
    "        results['test'].append('t_test')\r\n",
    "        if pvalue < significance:\r\n",
    "            print(\"Group mean of\" , y, \"affected at significance:\", significance)\r\n",
    "            results['passed'].append(True)\r\n",
    "        else:\r\n",
    "            print(\"Group mean of\", y, \"not affected at significance:\", significance)\r\n",
    "            results['passed'].append(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "681b613f-4fce-4d0b-a57b-df7e53bf9409"
   },
   "outputs": [],
   "source": [
    "## Chi-square Test of independence\r\n",
    "For multi categorical with contingency table"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "01bf4ebf-742b-424c-bf9a-b86bb12254c0",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "70b67012-5aa2-41d2-a829-b9b356fa3485"
   },
   "outputs": [],
   "source": [
    "for x in x_multi:\r\n",
    "    discrete_values = list(set(df[x]))\r\n",
    "    for y in y_multi:\r\n",
    "        print(\"Feature:\", y, \"compared to:\", x)\r\n",
    "        contingency_table = pd.crosstab(index=df[x], columns=df[y], margins=True)\r\n",
    "        print(contingency_table)\r\n",
    "        chi2, pvalue, dof, ex = stats.chi2_contingency(contingency_table)\r\n",
    "        results['x'].append(x)\r\n",
    "        results['y'].append(y)\r\n",
    "        results['test'].append('chi2')\r\n",
    "        if pvalue < significance:\r\n",
    "            print(\"Group mean of\" , y, \"affected at significance:\", significance)\r\n",
    "            results['passed'].append(True)\r\n",
    "        else:\r\n",
    "            print(\"Group mean of\", y, \"not affected at significance:\", significance)\r\n",
    "            results['passed'].append(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "e127fc60-ab37-4356-bb71-31f04485f922"
   },
   "outputs": [],
   "source": [
    "### Results\r\n",
    "Note that both dataframes in 'sorted by x' and 'sorted by y' presents the SAME results with different sorting"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 2,
     "id": "1aba5ccb-a1b5-42c9-9615-267354b87fb7",
     "startLine": 2
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "2bc2650a-1dab-41c5-8c8c-7a6b6bc28b00"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\r\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "7c31ef21-a9ea-4642-84ff-f11472dfbe40"
   },
   "outputs": [],
   "source": [
    "Sorted by x"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 6,
     "id": "1aba5ccb-a1b5-42c9-9615-267354b87fb7",
     "startLine": 6
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "714a8d56-e3fb-4975-a0b1-570c6c1677e6"
   },
   "outputs": [],
   "source": [
    "results_sort_x = results_df.sort_values(by=['y'])\r\n",
    "results_sort_x = results_sort_x.sort_values(by=['x'])\r\n",
    "index = pd.MultiIndex.from_frame(results_sort_x[['x', 'y']])\r\n",
    "results_sort_x.index = index\r\n",
    "results_sort_x = results_sort_x[['test', 'passed']]\r\n",
    "results_sort_x"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "af6cf162-5f5c-476e-ad86-21f79580c1bf"
   },
   "outputs": [],
   "source": [
    "Sorted by y"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 6,
     "id": "1aba5ccb-a1b5-42c9-9615-267354b87fb7",
     "startLine": 6
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "5ad9195e-10d8-4eec-8d43-c5ea3fa8fd22"
   },
   "outputs": [],
   "source": [
    "results_sort_y = results_df.sort_values(by=['x'])\r\n",
    "results_sort_y = results_sort_y.sort_values(by=['y'])\r\n",
    "index = pd.MultiIndex.from_frame(results_sort_y[['y', 'x']])\r\n",
    "results_sort_y.index = index\r\n",
    "results_sort_y = results_sort_y[['test', 'passed']]\r\n",
    "results_sort_y"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
