{
 "cells": [
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "71685cce-887b-4711-a484-8668e4ff9e94"
   },
   "outputs": [],
   "source": [
    "# Causal Structures\r\n",
    "Using Halerium Causal Structures\r\n",
    "\r\n",
    "Author: {{ cookiecutter.author_name }}\r\n",
    "Created: {{ cookiecutter.timestamp }}"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "9ad815fd-d7fb-470f-8e14-48b52d6e911f"
   },
   "outputs": [],
   "source": [
    "# Link to experiments card (refresh and hit enter on this line to see the link)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "72392473-740a-4101-9bb2-d4012d5b37ed"
   },
   "outputs": [],
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "67f4c909-5bbc-4e07-adb4-3e2b1389bfb8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import halerium.core as hal\r\n",
    "\r\n",
    "import itertools\r\n",
    "from itertools import chain, combinations\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "import networkx as nx\r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "861e898e-57b1-4a2c-b7fd-e04b74efcebd"
   },
   "outputs": [],
   "source": [
    "### Project"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "4170e438-d49e-400e-b3d0-dd06dd392ae2",
     "path": "/Personal/zihan/gitlab2/welcome/use_case_templates/hypothesis_testing/{{ cookiecutter.use_case_folder }}/2-causal/causal_structure.ipynb",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "de131261-2e2a-4ecd-9a82-70e50470d059"
   },
   "outputs": [],
   "source": [
    "experiment_name = '{{cookiecutter.use_case_name}}'  # please provide a name for the hypothesis testing experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "42890df8-2d60-40f8-afe6-4bef8f21abc7"
   },
   "outputs": [],
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 3,
     "id": "ccef3dda-e5f3-490c-93d3-2f94259694ad",
     "path": "/Personal/zihan/gitlab2/welcome/use_case_templates/hypothesis_testing/{{ cookiecutter.use_case_folder }}/2-causal/causal_structure.ipynb",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "47e4d02c-95e0-48ce-944c-50e34436e888"
   },
   "outputs": [],
   "source": [
    "time_series = False\n",
    "test_size = 0.25\n",
    "path = '{{cookiecutter.data_path}}' # Specify the path of the data\n",
    "\n",
    "if path =='default example':\n",
    "    path = 'https://raw.githubusercontent.com/erium/halerium-example-data/main/hypothesis_testing/WineQT.csv'\n",
    "\n",
    "if time_series:\n",
    "    df = pd.read_csv(path, parse_dates=['date'])\n",
    "else:\n",
    "    df = pd.read_csv(path, delimiter=';')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "3448e8b2-0966-47d3-8c49-dacda51954af"
   },
   "outputs": [],
   "source": [
    "## Manual Modelling\r\n",
    "Manually specify the dependencies in the causal structure"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 4,
     "id": "28cca961-bd70-485f-8e01-56dc45d5e821",
     "path": "/Personal/zihan/hypothesis_testing/causal_inference/causal_structure.ipynb",
     "startLine": 2
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "e75a5978-36bd-4e72-b6ec-efa4a8c70625"
   },
   "outputs": [],
   "source": [
    "# Directed dependencies\r\n",
    "dependencies = [['fixed acidity', 'pH'], ['volatile acidity', 'pH']]\r\n",
    "features_input = ['fixed acidity', 'volatile acidity']\r\n",
    "features_output = ['pH']"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 19,
     "id": "66b970c9-85fd-49f7-b800-f2e9a02fb0c0",
     "path": "/Personal/zihan/hypothesis_testing/causal_inference/causal_structure.ipynb",
     "startLine": 19
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "f86a59a7-57d3-4d51-8725-e6b6b02a8ebb"
   },
   "outputs": [],
   "source": [
    "features = list(set([item for sublist in dependencies for item in sublist]))\n",
    "data = df[features]\n",
    "train, test = train_test_split(data, test_size = test_size)\n",
    "\n",
    "causal_structure = hal.CausalStructure(dependencies)\n",
    "causal_structure.train(train)\n",
    "test_input = test[features_input]\n",
    "test_output = test[features_output]\n",
    "test_input.reset_index(inplace=True)\n",
    "test_output.reset_index(inplace=True)\n",
    "\n",
    "influences = []\n",
    "for feature in features:\n",
    "    influence = causal_structure.evaluate_objective(hal.InfluenceEstimator, target=feature)\n",
    "    influences.append([feature, influence])\n",
    "evaluation = causal_structure.evaluate_objective(hal.Evaluator, data=test,\n",
    "                                    inputs=features_input, metric=\"r2\")\n",
    "prediction_mean, prediction_std = causal_structure.predict(data=test_input, return_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "f3520164-4dcf-4e7b-a3db-face6ec5a8c8"
   },
   "outputs": [],
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 37,
     "id": "66b970c9-85fd-49f7-b800-f2e9a02fb0c0",
     "path": "/Personal/zihan/hypothesis_testing/causal_inference/causal_structure.ipynb",
     "startLine": 37
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "f05cc776-7651-4018-b008-389e8bc0c98c"
   },
   "outputs": [],
   "source": [
    "for feature_out in features_output:\r\n",
    "    print(\"Output Feature:\", feature_out)\r\n",
    "    columns = features + [feature + ' std' for feature in features]\r\n",
    "    prediction = pd.concat([prediction_mean, prediction_std], axis=1)\r\n",
    "    prediction.columns = columns\r\n",
    "    print(\"r2:\", evaluation[feature_out])\r\n",
    "\r\n",
    "    for feature_in in features_input:\r\n",
    "        prediction.sort_values(by=[feature_in], inplace=True)\r\n",
    "        for feature_out in features_output:\r\n",
    "            prediction_mean = prediction[features]\r\n",
    "            prediction_std = prediction[[feature + ' std' for feature in features]]\r\n",
    "            plt.plot(prediction_mean[feature_in], prediction_mean[feature_out], color=\"red\")\r\n",
    "            plt.fill_between(prediction_mean[feature_in],\r\n",
    "                 (prediction_mean - prediction_std)[feature_out],\r\n",
    "                 (prediction_mean + prediction_std)[feature_out],\r\n",
    "                 color=\"red\", alpha=0.5)\r\n",
    "            plt.scatter(test[feature_in], test[feature_out])\r\n",
    "            plt.xlabel(feature_in)\r\n",
    "            plt.ylabel(feature_out)\r\n",
    "            plt.show()\r\n",
    "\r\n",
    "    # Building and displaying the Directed Graph\r\n",
    "    G = nx.MultiDiGraph()\r\n",
    "    for feature in features:\r\n",
    "        G.add_node(feature)\r\n",
    "    G.add_edges_from(dependencies)\r\n",
    "\r\n",
    "    color_map = []\r\n",
    "    for node in G:\r\n",
    "        if node in features_output:\r\n",
    "            color_map.append('red')\r\n",
    "        else: \r\n",
    "            color_map.append('green')  \r\n",
    "\r\n",
    "    nx.draw(G, node_color=color_map, with_labels = True)\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "19110139-8188-4290-9f57-081c992fb0d9"
   },
   "outputs": [],
   "source": [
    "## Automatic Modelling\r\n",
    "Generate all possible DAGs\r\n",
    "This becomes computationally slow with > 3 features"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 3,
     "id": "5d4e3103-3ca1-49ff-b27e-97e36cf90653",
     "path": "/Personal/zihan/hypothesis_testing/causal_inference/causal_structure.ipynb",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "7995d73a-31bd-489c-b280-e846d863b2df"
   },
   "outputs": [],
   "source": [
    "features = ['fixed acidity', 'volatile acidity', 'pH', 'residual sugar']\r\n",
    "features_input = ['fixed acidity', 'volatile acidity']\r\n",
    "features_output = ['pH', 'residual sugar']"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "8dfab1d9-eb82-41a4-9a54-50125da6ea08"
   },
   "outputs": [],
   "source": [
    "# Generate all possible dependencies\r\n",
    "dependencies = []\r\n",
    "for i in itertools.permutations(features, 2):\r\n",
    "    dependencies.append(list(i))\r\n",
    "print(\"Number of dependencies:\", len(dependencies))"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "54c1c0b7-ff2e-4445-962d-9f8a6f135ce0"
   },
   "outputs": [],
   "source": [
    "# Powerset of sets of dependencies of at least size of number of features\r\n",
    "def powerset(iterable):\r\n",
    "    s = list(iterable)\r\n",
    "    min_set_size = 1\r\n",
    "    max_set_size = len(s)\r\n",
    "    return chain.from_iterable(list(combinations(s, r)) for r in range(min_set_size, max_set_size))\r\n",
    "dependency_powerset = list(powerset(dependencies))\r\n",
    "print(\"Length of dependency powerset:\", len(dependency_powerset))"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "6f5240a2-ac5f-4ea4-a27c-8cd159483a41"
   },
   "outputs": [],
   "source": [
    "dag = []\r\n",
    "for dependency_set in dependency_powerset:\r\n",
    "    try:\r\n",
    "        hal.causal_structure.Dependencies(dependency_set)\r\n",
    "    except:\r\n",
    "        continue\r\n",
    "    else:\r\n",
    "        dependencies = list(dependency_set)\r\n",
    "        all_dependencies = list(set([item for sublist in dependencies for item in sublist]))\r\n",
    "        \r\n",
    "        # If it does not include all features specified\r\n",
    "        if set(all_dependencies) != set(features):\r\n",
    "            continue\r\n",
    "        dag.append(dependency_set)\r\n",
    "print(\"Number of DAGs that include all features:\", len(dag))"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "9766efef-24aa-491e-bd55-26cb0d46dc29"
   },
   "outputs": [],
   "source": [
    "results = []\r\n",
    "for dependencies in dag:\r\n",
    "    dependencies = list(dependencies)\r\n",
    "\r\n",
    "    data = df[features]\r\n",
    "    train, test = train_test_split(data, test_size = test_size)\r\n",
    "    causal_structure = hal.CausalStructure(dependencies)\r\n",
    "    causal_structure.train(train)\r\n",
    "    test_input = test[features_input]\r\n",
    "    test_output = test[features_output]\r\n",
    "    test_input.reset_index(inplace=True)\r\n",
    "    test_output.reset_index(inplace=True)\r\n",
    "\r\n",
    "    influences = []\r\n",
    "    for feature in features:\r\n",
    "        influence = causal_structure.evaluate_objective(hal.InfluenceEstimator, target=feature)\r\n",
    "        influences.append([feature, influence])\r\n",
    "    evaluation = causal_structure.evaluate_objective(hal.Evaluator, data=test,\r\n",
    "                                     inputs=features_input, metric=\"r2\")\r\n",
    "    prediction_mean, prediction_std = causal_structure.predict(data=test_input, return_std=True)\r\n",
    "    print(evaluation)\r\n",
    "\r\n",
    "    results.append([dependencies, causal_structure, influences, evaluation, prediction_mean, prediction_std])"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "e460403c-8e26-46a0-91a4-2dc72e930510"
   },
   "outputs": [],
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 39,
     "id": "66b970c9-85fd-49f7-b800-f2e9a02fb0c0",
     "path": "/Personal/zihan/hypothesis_testing/causal_inference/causal_structure.ipynb",
     "startLine": 39
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "403932ac-f8ec-4d27-8cc3-24fb17dca54f"
   },
   "outputs": [],
   "source": [
    "for feature_out in features_output:\r\n",
    "    print(\"Output Feature:\", feature_out)\r\n",
    "    best_r2 = max(results, key= lambda x: x[3][feature_out])\r\n",
    "    dependencies, causal_structure, influences, evaluation, prediction_mean, prediction_std = best_r2\r\n",
    "    columns = features + [feature + ' std' for feature in features]\r\n",
    "    prediction = pd.concat([prediction_mean, prediction_std], axis=1)\r\n",
    "    prediction.columns = columns\r\n",
    "    print(\"r2:\", evaluation[feature_out])\r\n",
    "\r\n",
    "    for feature_in in features_input:\r\n",
    "        prediction.sort_values(by=[feature_in], inplace=True)\r\n",
    "        for feature_out in features_output:\r\n",
    "            prediction_mean = prediction[features]\r\n",
    "            prediction_std = prediction[[feature + ' std' for feature in features]]\r\n",
    "            plt.plot(prediction_mean[feature_in], prediction_mean[feature_out], color=\"red\")\r\n",
    "            plt.fill_between(prediction_mean[feature_in],\r\n",
    "                 (prediction_mean - prediction_std)[feature_out],\r\n",
    "                 (prediction_mean + prediction_std)[feature_out],\r\n",
    "                 color=\"red\", alpha=0.5)\r\n",
    "            plt.scatter(test[feature_in], test[feature_out])\r\n",
    "            plt.xlabel(feature_in)\r\n",
    "            plt.ylabel(feature_out)\r\n",
    "            plt.show()\r\n",
    "\r\n",
    "    # Building and displaying the Directed Graph\r\n",
    "    G = nx.MultiDiGraph()\r\n",
    "    for feature in features:\r\n",
    "        G.add_node(feature)\r\n",
    "    G.add_edges_from(dependencies)\r\n",
    "\r\n",
    "    color_map = []\r\n",
    "    for node in G:\r\n",
    "        if node in features_output:\r\n",
    "            color_map.append('red')\r\n",
    "        else: \r\n",
    "            color_map.append('green')  \r\n",
    "\r\n",
    "    nx.draw(G, node_color=color_map, with_labels = True)\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "14b852a8-0e2f-413a-820f-06d7b561232d"
   },
   "outputs": [],
   "source": [
    "### Copy another template"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "2d611834-8f24-470f-8ff5-aec37e22cd1a"
   },
   "outputs": [],
   "source": [
    "from cookiecutter.main import cookiecutter\r\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 5,
     "id": "865bbe59-9a3c-46ad-9677-b79f1b920c5e",
     "path": "/Personal/zihan/gitlab/welcome/use_case_templates/hypothesis_testing/causal_inference/causal_structure.ipynb",
     "startLine": 5
    }
   ],
   "metadata": {
    "id": "0480b75b-daf2-4793-811a-962d77f6cb81"
   },
   "outputs": [],
   "source": [
    "# Copy a prediction template\n",
    "path = './..'\n",
    "repo = 'https://github.com/erium/welcome'\n",
    "directory = 'use_case_templates/prediction'\n",
    "#cookiecutter(repo, directory=directory, output_dir=path, extra_context={'timestamp': str(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))})"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
