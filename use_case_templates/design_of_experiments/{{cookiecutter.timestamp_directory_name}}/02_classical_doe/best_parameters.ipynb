{
 "cells": [
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "d59de1cb-e9d0-4222-8662-9132940809f6"
   },
   "outputs": [],
   "source": [
    "# Optimize system with parameters\r\n",
    "\r\n",
    "This is a template notebok for classical design of experiments for optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "22d03181-c327-49ee-bb70-746b38fcb932"
   },
   "outputs": [],
   "source": [
    "## How to use the notebook\r\n",
    "\r\n",
    "The following cells:\r\n",
    "- specify objective and other metrics, the parameter search space, and constraints,\r\n",
    "- set up the optimization algorithm,\r\n",
    "- read trial results,\r\n",
    "- provide the current best guess for optimal parameters.\r\n",
    "\r\n",
    "To just see how it works for a toy example,\r\n",
    "  1. run an unaltered version of the notebook \"classical_doe.ipynb\",\r\n",
    "  2. run this notebook as is.\r\n",
    "\r\n",
    "For your own project, adjust the details about objectives, parameters, etc. and then execute all cells in order.\r\n",
    "Make sure, the details about project, objective, etc. specified here match those in the notebook \"classical_doe.ipynb\"."
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "93f8db2f-57f2-497d-bfb8-cf5a2779fe88"
   },
   "outputs": [],
   "source": [
    "## Imports and general setup"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "f378f080-8ea4-4f34-947d-ba3881d310ae"
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "\r\n",
    "from datetime import datetime\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.cm as cm\r\n",
    "\r\n",
    "from ax.service.ax_client import AxClient\r\n",
    "from ax import RangeParameter, ChoiceParameter\r\n",
    "from ax.exceptions.core import DataRequiredError, SearchSpaceExhausted\r\n",
    "from ax.exceptions.generation_strategy import MaxParallelismReachedException\r\n",
    "from ax.core.base_trial import TrialStatus\r\n",
    "from ax.modelbridge.generation_strategy import GenerationStrategy, GenerationStep\r\n",
    "from ax.modelbridge.registry import Models, ModelRegistryBase\r\n",
    "\r\n",
    "import ax.plot as ax_plot\r\n",
    "\r\n",
    "plt.style.use(\"dark_background\")\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "2fc0ca89-445a-4e20-8a57-4a660a408fdc"
   },
   "outputs": [],
   "source": [
    "## Project"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "8111636a-6bd6-4cd4-a72e-b1cc952f8027"
   },
   "outputs": [],
   "source": [
    "experiment_name = \"test\"  # please provide a name for the optimization experiment\n",
    "data_dir = \"./\"           # please provide a name for saving the trial data for the experiment\n",
    "\n",
    "data_file_name = os.path.join(data_dir,  f\"data_{experiment_name}_running_trials.csv\")\n",
    "\n",
    "if os.path.exists(data_file_name):\n",
    "    print(f\"the trial data will be read from: {data_file_name}\")\n",
    "else:\n",
    "   print(f\"file for trial data not found: {data_file_name}\")\n",
    "   raise RuntimeError(\"No trial data found.\")\n",
    "\n",
    "best_parameters_file_name = os.path.join(data_dir,  f\"data_{experiment_name}_best_parameters.csv\")\n",
    "print(f\"the best parameters will be read from/stored in: {best_parameters_file_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "e921a720-58de-4640-a988-2a8dcf1a170c"
   },
   "outputs": [],
   "source": [
    "## Metrics and objective"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "967cbddd-7cf2-48b1-a81f-4bef3d799bf1"
   },
   "outputs": [],
   "source": [
    "metrics = [\"cost\", \"quality\"]   # please provide a list of metrics\n",
    "objective_name = \"cost\"         # please give the name for the objective to maximize or minimize (must be among provided metrics)\n",
    "minimize = True                 # set to True if minimize, and to False if maximize objective\n",
    "\n",
    "if objective_name not in metrics:\n",
    "    raise ValueError(f\"Objective must be among provided metrics. \"\n",
    "                     f\"Could not find objective_name={objective_name} in metrics={metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "238cc678-56a8-416f-9910-e58c00b52d81"
   },
   "outputs": [],
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "3594c13b-d4a6-48eb-b08c-a888fb4c5516"
   },
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    # please insert the information on the names and bound/values of the parameters to try:\n",
    "    {\n",
    "        \"name\": \"x1\",           # the name of the parameter\n",
    "        \"type\": \"range\",        # the type of parameter: \"range\" is for continuous parameters\n",
    "        \"bounds\": [0., 1.],     # the lower and upper bound of the parameter as a tuple for range parameters\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"x2\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0., 10.],\n",
    "    },  \n",
    "    {\n",
    "        \"name\": \"x3\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [-5., 5.],\n",
    "    },  \n",
    "#    {\n",
    "#       \"name\": \"x4\",\n",
    "#        \"type\": \"choice\",                    # the type of parameter: \"choice\" is for discrete parameters\n",
    "#        \"values\": [\"up\", \"down\", \"stange\"],  # the values to try from for parameter\n",
    "#        \"is_ordered\": False,                 # whether values are ordered\n",
    "#    },   \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "32943ac2-997e-4e53-832e-64e94ce4bd8f"
   },
   "outputs": [],
   "source": [
    "## Constraints"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "c1dd741e-4671-4575-aef2-1c42c35bb9b9"
   },
   "outputs": [],
   "source": [
    "parameter_constraints = []                     # provide any parameter constraints as inequalities\n",
    "outcome_constraints = [\"quality >= 1\"]         # provide any constraints on the metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "2b409cfb-d9c4-4336-b749-36e09ba18e3f"
   },
   "outputs": [],
   "source": [
    "## Best parameter estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "57aa9bf3-31fa-4ff1-b9da-4232ef5e95d5"
   },
   "outputs": [],
   "source": [
    "### Complete outstanding trials\r\n",
    "\r\n",
    "Note that the following cell contains code to invent trial results for demonstration purposes. \r\n",
    "\r\n",
    "For real applications, either\r\n",
    " - replace the cell with appropriate code for retrieving the actual trial results, or \r\n",
    " - remove the cell entirely, if you intend to add the trial results to the data files in a different way."
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "2e0417a8-f6f9-464b-bb03-e3a07e0cf739"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file_name, index_col=\"index\")\r\n",
    "\r\n",
    "cost_for = {\"up\": 1, \"down\": 2, \"strange\": 3}\r\n",
    "\r\n",
    "\r\n",
    "data[\"cost_mean\"] = (data[\"x1\"] - 0.6)**2 + 0.1 * (data[\"x2\"] - 7.)**2  + 0.3 *(data[\"x3\"] - 2.)**2 #  + data[\"x4\"].map(lambda x: cost_for.get(x, 4))\r\n",
    "data[\"cost_SEM\"] = 0.\r\n",
    "data[\"quality_mean\"] = 2./(1 + np.exp(-data[\"x2\"] + 2))\r\n",
    "data[\"quality_SEM\"] = 0.\r\n",
    "\r\n",
    "display(data)\r\n",
    "\r\n",
    "data.to_csv(data_file_name)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "c8e6961f-c2c1-412e-9a1a-57a5af38d9d0"
   },
   "outputs": [],
   "source": [
    "### Read trial  data"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "57477f42-80e3-4e94-b4d0-425dd7df69fb"
   },
   "outputs": [],
   "source": [
    "parameter_columns = [parameter[\"name\"] for parameter in parameters ] \n",
    "result_columns    = [metric + suffix for metric in metrics for suffix in (\"_mean\", \"_SEM\")]\n",
    "data_columns      = parameter_columns + result_columns\n",
    "\n",
    "n_trials = 0\n",
    "n_completed_trials = 0\n",
    "n_outstanding_trials = 0\n",
    "prior_data = None\n",
    "\n",
    "if os.path.exists(data_file_name):\n",
    "    print(f\"reading prior data from {data_file_name}...\")\n",
    "    prior_data = pd.read_csv(data_file_name, index_col=\"index\")\n",
    "\n",
    "    missing_colums = set(data_columns) - set(prior_data.columns)\n",
    "    if missing_colums:\n",
    "        raise ValueError(f\"data file missing colums: {missing_colums}.\")\n",
    "    prior_data = prior_data[data_columns]   \n",
    "\n",
    "    n_trials = len(prior_data[parameter_columns].dropna(axis='index', how='any'))\n",
    "    n_completed_trials = len(prior_data.dropna(axis='index', how='any'))\n",
    "    n_outstanding_trials = n_trials - n_completed_trials\n",
    "\n",
    "else:\n",
    "    print(\"no prior data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "1974e322-c71d-450e-8ac6-0ad729a6ac3b"
   },
   "outputs": [],
   "source": [
    "### Set up client"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "41111545-b50e-4737-9cb5-02865e0a1ab7"
   },
   "outputs": [],
   "source": [
    "generation_strategy=GenerationStrategy([\r\n",
    "        # Bayesian optimization step (requires data obtained from previous phase and learns\r\n",
    "        # from all data available at the time of each new candidate generation call)\r\n",
    "        GenerationStep(\r\n",
    "            model=Models.GPEI,\r\n",
    "            num_trials=-1,  # No limitation on how many trials should be produced from this step\r\n",
    "            max_parallelism=3,  # Parallelism limit for this step, often lower than for Sobol\r\n",
    "        ),\r\n",
    "    ])\r\n",
    "\r\n",
    "ax_client = AxClient(generation_strategy=generation_strategy)\r\n",
    "\r\n",
    "ax_client.create_experiment(\r\n",
    "    name=experiment_name,\r\n",
    "    parameters=parameters,\r\n",
    "    objective_name=objective_name,\r\n",
    "    minimize=minimize,\r\n",
    "    parameter_constraints=parameter_constraints,\r\n",
    "    outcome_constraints=outcome_constraints,\r\n",
    ")\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "01706eab-4775-40cd-93a8-ed11e6b4b1cd"
   },
   "outputs": [],
   "source": [
    "### Feed data to client"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "2bbbf3e4-23c6-4007-ba8b-7454689ad2a4"
   },
   "outputs": [],
   "source": [
    "prior_trials = dict()\r\n",
    "if prior_data is not None:\r\n",
    "    for index, trial_data in prior_data.iterrows():\r\n",
    "\r\n",
    "        trial_parameters = trial_data[parameter_columns]\r\n",
    "        if any(trial_parameters.isna()):\r\n",
    "            missing_trial_parameters = \", \".join(trial_parameters[trial_parameters.isna()].index)\r\n",
    "            print(f\"row {index}: missing parameter values for: {missing_trial_parameters}.\")\r\n",
    "            continue\r\n",
    "\r\n",
    "        trial_parameters = trial_parameters.to_dict()\r\n",
    "        trial_parameters, trial_index = ax_client.attach_trial(parameters=trial_parameters)\r\n",
    "\r\n",
    "        trial_results = trial_data[result_columns]\r\n",
    "        if any(trial_results.isna()):\r\n",
    "            missing_results = \", \".join(trial_results[trial_results.isna()].index)\r\n",
    "            print(f\"row {index}: outstanding results for: {missing_results}.\")\r\n",
    "        else:\r\n",
    "            raw_data = dict()\r\n",
    "            for metric in metrics:\r\n",
    "                metric_mean = trial_results[metric + \"_mean\"]\r\n",
    "                metric_SEM  = trial_results[metric + \"_SEM\"]\r\n",
    "                raw_data[metric] = (metric_mean, metric_SEM)\r\n",
    "            ax_client.complete_trial(trial_index=trial_index, raw_data=raw_data)\r\n",
    "\r\n",
    "        trial_results = trial_results.to_dict()\r\n",
    "        prior_trials[trial_index] = {**trial_parameters, **trial_results}\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "8554baa6-2814-4a07-a21e-0ecf17418bce"
   },
   "outputs": [],
   "source": [
    "### Estimate best parameters"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "01474e8d-810e-4dff-8bef-85e4125bea0b"
   },
   "outputs": [],
   "source": [
    "ax_client.get_next_trial()\r\n",
    "\r\n",
    "if os.path.exists(best_parameters_file_name):\r\n",
    "    prior_best_parameters_data = pd.read_csv(best_parameters_file_name) \r\n",
    "else:\r\n",
    "    prior_best_parameters_data = pd.DataFrame(columns=[\"n_completed_trials\"] + parameter_columns + metrics)\r\n",
    "\r\n",
    "\r\n",
    "best_parameters_result = ax_client.get_best_parameters()\r\n",
    "if best_parameters_result is None:\r\n",
    "    best_parameters = None\r\n",
    "    means = None\r\n",
    "    covariances = None\r\n",
    "    new_best_parameters_data = pd.DataFrame(columns=[\"n_completed_trials\"] + parameter_columns + metrics)\r\n",
    "else:\r\n",
    "    best_parameters, (means, covariances) = best_parameters_result\r\n",
    "    new_best_parameters_data = pd.DataFrame.from_records(({\r\n",
    "        \"n_completed_trials\": n_completed_trials,\r\n",
    "        **best_parameters, **means\r\n",
    "    },))\r\n",
    "\r\n",
    "\r\n",
    "best_parameters_data = prior_best_parameters_data.append(new_best_parameters_data)\r\n",
    "if os.path.exists(best_parameters_file_name):\r\n",
    "    dt = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\r\n",
    "    os.rename(best_parameters_file_name, os.path.join(data_dir,  f\"data_{experiment_name}_best_parameters_{dt}.csv\"))\r\n",
    "best_parameters_data.to_csv(best_parameters_file_name, index=False)\r\n",
    "\r\n",
    "if len(best_parameters_data) > 0:\r\n",
    "    print(\"\\nbest parameters so far (from oldest to most recent):\")\r\n",
    "    display(best_parameters_data)\r\n",
    "else:\r\n",
    "    print(\"no best parameters yet.\")\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "91ccea8a-bac7-4dcd-9988-498c3bd7cf5c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
