{
 "cells": [
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "d59de1cb-e9d0-4222-8662-9132940809f6"
   },
   "outputs": [],
   "source": [
    "# Optimize system with parameters\r\n",
    "\r\n",
    "This is a template notebook for design of experiments for bayesian optimization.\r\n",
    "\r\n",
    "Author: {{ cookiecutter.author_name }}\r\n",
    "Created: {{ cookiecutter.timestamp }}"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "22d03181-c327-49ee-bb70-746b38fcb932"
   },
   "outputs": [],
   "source": [
    "## How to use the notebook\r\n",
    "\r\n",
    "The following cells:\r\n",
    "- specify objective and other metrics, the parameter search space, and constraints,\r\n",
    "- set up the optimization algorithm,\r\n",
    "- read prior results,\r\n",
    "- suggest new trials,\r\n",
    "- provide the current best guess for optimal parameters.\r\n",
    "\r\n",
    "Thereby, the library Ax is used, c.f. https://ax.dev/\r\n",
    "\r\n",
    "By default, the notebook is set up to run with an example. To see how it works, run the notebook (multiple times) without changing the code.\r\n",
    "\r\n",
    "For your project, adjust the code in the linked cells with your objectives, variables, dataset etc. and then execute all cells in order.\r\n",
    "\r\n",
    "Please refer to bayesian_optimization.board for detailed instructions."
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "3409d597-898a-4786-a5fe-184cc8356faf"
   },
   "outputs": [],
   "source": [
    "# Link to project experiments folder hypothesis_experiment_learnings.board (refresh and hit enter on this line to see the link)"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "93f8db2f-57f2-497d-bfb8-cf5a2779fe88"
   },
   "outputs": [],
   "source": [
    "### Imports and general setup"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "f378f080-8ea4-4f34-947d-ba3881d310ae"
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "\r\n",
    "from datetime import datetime\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.cm as cm\r\n",
    "\r\n",
    "from ax.service.ax_client import AxClient\r\n",
    "from ax import RangeParameter, ChoiceParameter\r\n",
    "from ax.exceptions.core import DataRequiredError, SearchSpaceExhausted\r\n",
    "from ax.exceptions.generation_strategy import MaxParallelismReachedException\r\n",
    "from ax.core.base_trial import TrialStatus\r\n",
    "from ax.modelbridge.generation_strategy import GenerationStrategy, GenerationStep\r\n",
    "from ax.modelbridge.registry import Models, ModelRegistryBase\r\n",
    "\r\n",
    "import ax.plot as ax_plot\r\n",
    "\r\n",
    "plt.style.use(\"dark_background\")\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "2fc0ca89-445a-4e20-8a57-4a660a408fdc"
   },
   "outputs": [],
   "source": [
    "## Project"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 1,
     "id": "22ffb1c2-265d-48b1-96c9-18ac30e38a73",
     "startLine": 1
    },
    {
     "endLine": 2,
     "id": "1a7b6868-dc38-410b-b343-3085fa005b2c",
     "startLine": 2
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "8111636a-6bd6-4cd4-a72e-b1cc952f8027"
   },
   "outputs": [],
   "source": [
    "experiment_name = '{{cookiecutter.use_case_name}}'  # please provide a name for the optimization experiment\n",
    "data_dir = \"./\"           # please provide a name for saving the trial data for the experiment\n",
    "\n",
    "data_file_name = os.path.join(data_dir,  f\"data_{experiment_name}_running_trials.csv\")\n",
    "print(f\"the trial data will be read from/stored in: {data_file_name}\")\n",
    "\n",
    "best_parameters_file_name = os.path.join(data_dir,  f\"data_{experiment_name}_best_parameters.csv\")\n",
    "print(f\"the best parameters will be read from/stored in: {best_parameters_file_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "e921a720-58de-4640-a988-2a8dcf1a170c"
   },
   "outputs": [],
   "source": [
    "## Metrics and objective"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 3,
     "id": "c1a853f4-9c82-4b74-b6ab-4a93a9981e84",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "967cbddd-7cf2-48b1-a81f-4bef3d799bf1"
   },
   "outputs": [],
   "source": [
    "metrics = [\"cost\", \"quality\"]   # please provide a list of metrics\n",
    "objective_name = \"cost\"         # please give the name for the objective to maximize or minimize (must be among provided metrics)\n",
    "minimize = True                 # set to True if minimize, and to False if maximize objective\n",
    "\n",
    "if objective_name not in metrics:\n",
    "    raise ValueError(f\"Objective must be among provided metrics. \"\n",
    "                     f\"Could not find objective_name={objective_name} in metrics={metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "238cc678-56a8-416f-9910-e58c00b52d81"
   },
   "outputs": [],
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 21,
     "id": "20dc4ade-a3f4-468a-be5c-13bd1f2569ed",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "3594c13b-d4a6-48eb-b08c-a888fb4c5516"
   },
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    # please insert information on parameters, their names, types, bounds, etc.\n",
    "    {\"name\": \"x1\",   \n",
    "     \"type\": \"range\",\n",
    "     \"bounds\": [-1.0, 1.0],\n",
    "     \"value_type\": \"float\",  # Optional, defaults to inference from type of \"bounds\".\n",
    "     \"log_scale\": False,  # Optional, defaults to False.\n",
    "    },\n",
    "    {\"name\": \"x2\",   \n",
    "     \"type\": \"range\",\n",
    "     \"bounds\": [-1.0, 1.0],\n",
    "     \"value_type\": \"float\",  # Optional, defaults to inference from type of \"bounds\".\n",
    "     \"log_scale\": False,  # Optional, defaults to False.\n",
    "    },\n",
    "    {\"name\": \"x3\",   \n",
    "     \"type\": \"range\",\n",
    "     \"bounds\": [-1.0, 1.0],\n",
    "     \"value_type\": \"float\",  # Optional, defaults to inference from type of \"bounds\".\n",
    "     \"log_scale\": False,  # Optional, defaults to False.\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "32943ac2-997e-4e53-832e-64e94ce4bd8f"
   },
   "outputs": [],
   "source": [
    "## Constraints"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 2,
     "id": "f02ba1a1-150c-458b-8422-af735fab8595",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "c1dd741e-4671-4575-aef2-1c42c35bb9b9"
   },
   "outputs": [],
   "source": [
    "parameter_constraints = [\"x1 + x2 <= 10\"]      # provide any parameter constraints as inequalities\n",
    "outcome_constraints = [\"quality >= 1\"]         # provide any constraints on the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "530ac622-7a1e-4d41-b208-95fc537be4d9"
   },
   "outputs": [],
   "source": [
    "## Schedule"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 9,
     "id": "361f7d6d-a7f9-4ecd-8fc0-5199285ee90a",
     "startLine": 5
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "ae3bc1a0-cadb-4e8f-bdd5-42c7e748cdcb"
   },
   "outputs": [],
   "source": [
    "suggest_new_trials = True         # set to `True` if you want new trials suggested, \n",
    "                                  # set to `False` if you just want to use existing results to estimate best parameters \n",
    "\n",
    "\n",
    "max_batch_size = 10               # please provide the max. number of trials in a batch\n",
    "always_max_batch_size = True      # whether to force full batch size for suggested new trials\n",
    "suggest_when_outstanding = False  # whether to suggest when trials are still outstanding\n",
    "\n",
    "initial_n_trials = 5              # how many initial trials before Baysian optimization steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "2b409cfb-d9c4-4336-b749-36e09ba18e3f"
   },
   "outputs": [],
   "source": [
    "## Trial generation and best parameter estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "57aa9bf3-31fa-4ff1-b9da-4232ef5e95d5"
   },
   "outputs": [],
   "source": [
    "### Complete outstanding trials\r\n",
    "\r\n",
    "Note that the following cell contains code to invent results of any outstanding trials for demonstration purposes. \r\n",
    "\r\n",
    "For real applications, either\r\n",
    " - replace the cell with appropriate code for retrieving the actual trial results, or \r\n",
    " - remove the cell entirely, if you intend to add the trial results to the data files in a different way."
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 11,
     "id": "a5ba624b-73d5-409a-b355-d09c60649574",
     "startLine": 1
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "2e0417a8-f6f9-464b-bb03-e3a07e0cf739"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(data_file_name):\r\n",
    "    data = pd.read_csv(data_file_name, index_col=\"index\")\r\n",
    "\r\n",
    "    data[\"cost_mean\"] = data[\"x1\"]**2 + data[\"x2\"]**2 + data[\"x3\"]**2\r\n",
    "    data[\"cost_SEM\"] = 0.1\r\n",
    "    data[\"quality_mean\"] = 2./(1 + np.exp(-data[\"x3\"] + 0.2))\r\n",
    "    data[\"quality_SEM\"] = 0.01\r\n",
    "\r\n",
    "    display(data)\r\n",
    "\r\n",
    "    data.to_csv(data_file_name)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "c8e6961f-c2c1-412e-9a1a-57a5af38d9d0"
   },
   "outputs": [],
   "source": [
    "### Read any existing data"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "57477f42-80e3-4e94-b4d0-425dd7df69fb"
   },
   "outputs": [],
   "source": [
    "parameter_columns = [parameter[\"name\"] for parameter in parameters ] \n",
    "result_columns    = [metric + suffix for metric in metrics for suffix in (\"_mean\", \"_SEM\")]\n",
    "data_columns      = parameter_columns + result_columns\n",
    "\n",
    "n_trials = 0\n",
    "n_completed_trials = 0\n",
    "n_outstanding_trials = 0\n",
    "prior_data = None\n",
    "\n",
    "if os.path.exists(data_file_name):\n",
    "    print(f\"reading prior data from {data_file_name}...\")\n",
    "    prior_data = pd.read_csv(data_file_name, index_col=\"index\")\n",
    "\n",
    "    missing_colums = set(data_columns) - set(prior_data.columns)\n",
    "    if missing_colums:\n",
    "        raise ValueError(f\"data file missing colums: {missing_colums}.\")\n",
    "    prior_data = prior_data[data_columns]   \n",
    "\n",
    "    n_trials = len(prior_data[parameter_columns].dropna(axis='index', how='any'))\n",
    "    n_completed_trials = len(prior_data.dropna(axis='index', how='any'))\n",
    "    n_outstanding_trials = n_trials - n_completed_trials\n",
    "\n",
    "else:\n",
    "    print(\"no prior data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "1974e322-c71d-450e-8ac6-0ad729a6ac3b"
   },
   "outputs": [],
   "source": [
    "### Set up client"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "41111545-b50e-4737-9cb5-02865e0a1ab7"
   },
   "outputs": [],
   "source": [
    "\r\n",
    "\r\n",
    "generation_strategy_steps=[\r\n",
    "        # 1. Initialization step (does not require pre-existing data and is well-suited for \r\n",
    "        # initial sampling of the search space)\r\n",
    "        GenerationStep(\r\n",
    "            model=Models.SOBOL,\r\n",
    "            num_trials=max(max_batch_size, initial_n_trials) if always_max_batch_size else initial_n_trials,  # How many trials should be produced from this generation step\r\n",
    "            min_trials_observed=3, # How many trials need to be completed to move to next model\r\n",
    "            max_parallelism=max(max_batch_size, 5) if always_max_batch_size else 5,  # Max parallelism for this step\r\n",
    "            model_kwargs={\"seed\": 999},  # Any kwargs you want passed into the model\r\n",
    "            model_gen_kwargs={},  # Any kwargs you want passed to `modelbridge.gen`\r\n",
    "        ),\r\n",
    "        # 2. Bayesian optimization step (requires data obtained from previous phase and learns\r\n",
    "        # from all data available at the time of each new candidate generation call)\r\n",
    "        GenerationStep(\r\n",
    "            model=Models.GPEI,\r\n",
    "            num_trials=-1,  # No limitation on how many trials should be produced from this step\r\n",
    "            max_parallelism=max(3, max_batch_size) if always_max_batch_size else 3,  # Parallelism limit for this step, often lower than for Sobol\r\n",
    "        ),\r\n",
    "    ]\r\n",
    "\r\n",
    "\r\n",
    "if n_trials >= initial_n_trials:\r\n",
    "    generation_strategy = GenerationStrategy(generation_strategy_steps[1:])\r\n",
    "else:\r\n",
    "    generation_strategy = GenerationStrategy(generation_strategy_steps)\r\n",
    "\r\n",
    "\r\n",
    "ax_client = AxClient(\r\n",
    "    generation_strategy=generation_strategy,\r\n",
    "    enforce_sequential_optimization=not always_max_batch_size, )\r\n",
    "\r\n",
    "ax_client.create_experiment(\r\n",
    "    name=experiment_name,\r\n",
    "    parameters=parameters,\r\n",
    "    objective_name=objective_name,\r\n",
    "    minimize=minimize,\r\n",
    "    parameter_constraints=parameter_constraints,\r\n",
    "    outcome_constraints=outcome_constraints,\r\n",
    ")\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "01706eab-4775-40cd-93a8-ed11e6b4b1cd"
   },
   "outputs": [],
   "source": [
    "### Feed existing data to client"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "2bbbf3e4-23c6-4007-ba8b-7454689ad2a4"
   },
   "outputs": [],
   "source": [
    "prior_trials = dict()\r\n",
    "if prior_data is not None:\r\n",
    "    for index, trial_data in prior_data.iterrows():\r\n",
    "\r\n",
    "        trial_parameters = trial_data[parameter_columns]\r\n",
    "        if any(trial_parameters.isna()):\r\n",
    "            missing_trial_parameters = \", \".join(trial_parameters[trial_parameters.isna()].index)\r\n",
    "            print(f\"row {index}: missing parameter values for: {missing_trial_parameters}.\")\r\n",
    "            continue\r\n",
    "\r\n",
    "        trial_parameters = trial_parameters.to_dict()\r\n",
    "        trial_parameters, trial_index = ax_client.attach_trial(parameters=trial_parameters)\r\n",
    "\r\n",
    "        trial_results = trial_data[result_columns]\r\n",
    "        if any(trial_results.isna()):\r\n",
    "            missing_results = \", \".join(trial_results[trial_results.isna()].index)\r\n",
    "            print(f\"row {index}: outstanding results for: {missing_results}.\")\r\n",
    "        else:\r\n",
    "            raw_data = dict()\r\n",
    "            for metric in metrics:\r\n",
    "                metric_mean = trial_results[metric + \"_mean\"]\r\n",
    "                metric_SEM  = trial_results[metric + \"_SEM\"]\r\n",
    "                raw_data[metric] = (metric_mean, metric_SEM)\r\n",
    "            ax_client.complete_trial(trial_index=trial_index, raw_data=raw_data)\r\n",
    "\r\n",
    "        trial_results = trial_results.to_dict()\r\n",
    "        prior_trials[trial_index] = {**trial_parameters, **trial_results}\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "477f08e9-0f99-4e94-9eb6-199707030ed8"
   },
   "outputs": [],
   "source": [
    "### Suggest new trials"
   ]
  },
  {
   "cell_type": "code",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "8351e3cd-84e4-4322-b60e-fc4337648daa"
   },
   "outputs": [],
   "source": [
    "if (n_outstanding_trials > 0) and not suggest_when_outstanding:\r\n",
    "    print(f\"There are {n_outstanding_trials} outstanding trials. Will not suggest new trials.\")\r\n",
    "    suggest_new_trials = False\r\n",
    "\r\n",
    "\r\n",
    "if suggest_new_trials and max_batch_size > 0:\r\n",
    "\r\n",
    "    new_trials = dict()\r\n",
    "    exhausted = False\r\n",
    "\r\n",
    "    try:\r\n",
    "        if always_max_batch_size:\r\n",
    "            for _ in range(max_batch_size):\r\n",
    "                trial_parameters, trial_index = ax_client.get_next_trial()\r\n",
    "                trial_results = {c: None for c in result_columns}\r\n",
    "                trial_data = {**trial_parameters, **trial_results}\r\n",
    "                new_trials[trial_index] = trial_data\r\n",
    "        else:\r\n",
    "            # workaround (get_next_trials won't generate new trials sometimes if loaded from disk unless get_next_trial was called)\r\n",
    "            trial_parameters, trial_index = ax_client.get_next_trial()\r\n",
    "            trial_results = {c: None for c in result_columns}\r\n",
    "            trial_data = {**trial_parameters, **trial_results}\r\n",
    "            new_trials[trial_index] = trial_data\r\n",
    "            if max_batch_size > 1:\r\n",
    "                more_trials, exhausted = ax_client.get_next_trials(max_trials=max_batch_size - 1)\r\n",
    "                new_trials.update(more_trials)\r\n",
    "    except (DataRequiredError, SearchSpaceExhausted, MaxParallelismReachedException) as exception:\r\n",
    "        print(f\"no more trials because {type(exception).__name__}: {exception}\")\r\n",
    "        pass\r\n",
    "        \r\n",
    "    _, exhausted = ax_client.get_current_trial_generation_limit()\r\n",
    "\r\n",
    "    batch_size = len(new_trials)\r\n",
    "\r\n",
    "    if (batch_size <= 0) and exhausted:\r\n",
    "        print(\"exhausted the search. no more trials to suggest.\")\r\n",
    "\r\n",
    "    elif batch_size <= 0:\r\n",
    "        print(\"no new trials to suggest. maybe you have to complete outstanding trials first.\")\r\n",
    "\r\n",
    "    else:\r\n",
    "        print(f\"got {batch_size} new trials.\")\r\n",
    "\r\n",
    "        if os.path.exists(data_file_name):\r\n",
    "            dt = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\r\n",
    "            os.rename(data_file_name, os.path.join(data_dir,  f\"data_{experiment_name}_running_trials_{dt}.csv\"))\r\n",
    "\r\n",
    "        data = {**prior_trials, **new_trials}\r\n",
    "        data = pd.DataFrame.from_dict(data, orient='index')\r\n",
    "        data = data[data_columns]\r\n",
    "        data.index.name = \"index\"\r\n",
    "        data.to_csv(data_file_name)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "8554baa6-2814-4a07-a21e-0ecf17418bce"
   },
   "outputs": [],
   "source": [
    "### Estimate best parameters"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 31,
     "id": "a5ba624b-73d5-409a-b355-d09c60649574",
     "startLine": 27
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "01474e8d-810e-4dff-8bef-85e4125bea0b"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(best_parameters_file_name):\r\n",
    "    prior_best_parameters_data = pd.read_csv(best_parameters_file_name) \r\n",
    "else:\r\n",
    "    prior_best_parameters_data = pd.DataFrame(columns=[\"n_completed_trials\"] + parameter_columns + metrics)\r\n",
    "\r\n",
    "\r\n",
    "best_parameters_result = ax_client.get_best_parameters()\r\n",
    "if best_parameters_result is None:\r\n",
    "    best_parameters = None\r\n",
    "    means = None\r\n",
    "    covariances = None\r\n",
    "    new_best_parameters_data = pd.DataFrame(columns=[\"n_completed_trials\"] + parameter_columns + metrics)\r\n",
    "else:\r\n",
    "    best_parameters, (means, covariances) = best_parameters_result\r\n",
    "    new_best_parameters_data = pd.DataFrame.from_records(({\r\n",
    "        \"n_completed_trials\": n_completed_trials,\r\n",
    "        **best_parameters, **means\r\n",
    "    },))\r\n",
    "\r\n",
    "\r\n",
    "best_parameters_data = prior_best_parameters_data.append(new_best_parameters_data)\r\n",
    "if os.path.exists(best_parameters_file_name):\r\n",
    "    dt = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\r\n",
    "    os.rename(best_parameters_file_name, os.path.join(data_dir,  f\"data_{experiment_name}_best_parameters_{dt}.csv\"))\r\n",
    "best_parameters_data.to_csv(best_parameters_file_name, index=False)\r\n",
    "\r\n",
    "if len(best_parameters_data) > 0:\r\n",
    "    print(\"\\nbest parameters so far (from oldest to most recent):\")\r\n",
    "    display(best_parameters_data)\r\n",
    "else:\r\n",
    "    print(\"no best parameters yet.\")\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "connections": [],
   "execution_count": 0,
   "metadata": {
    "id": "53bcab25-ba38-47eb-b018-4576a6e53e99"
   },
   "outputs": [],
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "connections": [
    {
     "endLine": 25,
     "id": "cd470dcc-ec35-4ae6-8fb6-fbf8f98d98a5",
     "startLine": 11
    }
   ],
   "execution_count": 0,
   "metadata": {
    "id": "4e62fae8-7655-48b8-b87d-3ed299165406"
   },
   "outputs": [],
   "source": [
    "experiment = ax_client.experiment\r\n",
    "\r\n",
    "ob_trials =  {i: t.objective_mean for i,t in experiment.trials.items() if t.completed_successfully}\r\n",
    "ob_trials = [ob_trials[i] for i in sorted(ob_trials.keys())]\r\n",
    "\r\n",
    "if minimize:\r\n",
    "    best_ob_trials = np.minimum.accumulate(ob_trials)\r\n",
    "else:\r\n",
    "    best_ob_trials = np.maximum.accumulate(ob_trials)\r\n",
    "\r\n",
    "fig, axs = plt.subplots(1, 2, figsize=(6 * 2, 4))\r\n",
    "\r\n",
    "\r\n",
    "ax = axs[0]\r\n",
    "ax.plot(ob_trials, '.r');\r\n",
    "ax.set_xlabel('trial number')\r\n",
    "ax.set_ylabel(objective_name)\r\n",
    "\r\n",
    "\r\n",
    "ax = axs[1]\r\n",
    "ax.plot(best_parameters_data[\"n_completed_trials\"], best_parameters_data[objective_name], '.r');\r\n",
    "ax.set_xlabel('number of completed trials');\r\n",
    "ax.set_ylabel('best estimated ' + objective_name);\r\n",
    "xmax = best_parameters_data[\"n_completed_trials\"].max() if (len(best_parameters_data[\"n_completed_trials\"]) > 0) else 0.\r\n",
    "ax.set_xlim(-0.5, xmax + 0.5);\r\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
